# Exponential Random Graph Models (ERGMs)

So far, the models we’ve considered have treated tie formation as mostly random or locally constrained: ties are formed with fixed probabilities ($G(n, p)$), rewired at random (small-world), or arranged to match node degrees (configuration model). However, real-world networks are shaped by richer and more structured processes. People don’t form ties independently or at random, they’re influenced by patterns like mutual friendships, popularity, shared group membership, and social norms like reciprocity and transitivity. For example, two people who share a common friend may be more likely to form a tie themselves (triadic closure), or individuals may be more likely to reciprocate a connection that is initiated by someone else. These kinds of dependencies are central to many social theories, and they give rise to complex patterns of self-organization in networks.

To capture these processes, we need a more flexible modeling framework—one that allows for:

- Multiple network features to be modeled simultaneously
- Direct specification of tie dependencies
- Testing of competing social mechanisms

This leads us to models that are built around network configurations, i.e. small, interpretable patterns of ties (such as mutual ties, stars, and triangles) that collectively describe the structure of the network. These configurations are often nested, meaning they build on one another hierarchically, and they can represent competing explanations for the observed structure. For instance, both reciprocity and popularity could explain why a node has many incoming tie, but these explanations imply different underlying processes.

**Exponential Random Graph Models (ERGMs)** provide a flexible way to model these kinds of patterns. Instead of assuming each edge forms independently, ERGMs allow the probability of a tie to depend on what else is happening in the network. For example, the likelihood of a tie forming between two nodes may increase if they share mutual connections (triadic closure), or decrease if one node is already connected to many others (crowding out).

By explicitly modeling such configurations, we gain not only better empirical fit but also the ability to test theoretical hypotheses about the generative processes that shape real-world networks.


## Packages Needed for this Chapter
```{r}
#| message: false
library(statnet)
library(intergraph)
library(igraph)
library(ggraph)
library(graphlayouts)
library(networkdata)
library(tidyverse)
```

## ERGM Modeling Outline
Exponential Random Graph Models (ERGMs) are a powerful family of statistical models for analyzing and simulating social networks. Unlike simpler random graph models, ERGMs are designed to capture the complex dependencies that often characterize real-world networks, such as reciprocity, transitivity, or clustering—by explicitly modeling how the presence of one tie can affect the likelihood of others.

The core idea is as follows. ERGMs specify a probability distribution over the set of all possible networks with a given number of nodes. The probability of observing a particular graph $G$ is defined as:

$$
P(G) = \frac{1}{\kappa} \exp\left( \sum_{i=1}^{p} \theta_i \cdot s_i(G) \right)
$$
where

- $s_i(G)$ is a network statistic that counts a specific configuration (e.g., number of edges, mutual ties, triangles).
- $\theta_i$ is the parameter associated with statistic $s_i(G)$; it tells us how strongly that configuration influences tie formation.
- $\kappa$ is a normalizing constant ensuring that all possible graphs sum to a probability of 1:
  $$
  \kappa = \sum_{G'} \exp\left( \sum_{i=1}^{p} \theta_i \cdot s_i(G') \right)
  $$

This formulation makes clear that networks with more of the structures positively weighted by $\theta$ are more probable. For instance, a large positive $\theta_{\text{mutual}}$ implies that the observed network contains more reciprocated ties than expected by chance.

In general, we interpret the parameters as follows:

- A positive $\theta_i$ means that the corresponding configuration (e.g., triangles) is overrepresented in the observed network than what is expected by pure chance.
- A negative $\theta_i$ indicates that the configuration is underrepresented than what is expected by pure chance.
- A zero value implies that the configuration occurs at chance levels.


The statistics $s_i$  are network configurations. As mentioned, ERGMs rely on small, interpretable network configurations to explain structure. These include:

- **Edges**: baseline tendency for tie formation (controls overall density)
- **Mutual**: reciprocity in directed networks
- **Triangles**: clustering or transitivity (friends of friends)
- **Stars**: centralization or popularity (many ties to a node)
- **Homophily**: ties between nodes with similar attributes

Each of these configurations reflects a hypothesized mechanism that may drive the evolution of network structure. We formalize some of the standard statistics in the following but for a full list of available statistics in the `ergm` package you can check:

```{r}
?ergmTerm
```



## 1. Model Specification  {.unnumbered}

### Dyadic Independence: Edges {.unnumbered}

To begin working with exponential random graph models (ERGMs), we first need to understand how models are specified and what kinds of network structures they describe. In this section, we introduce the simplest possible ERGM, one that assumes Bernoulli dependence, and show how it connects to the familiar $G(n, p)$ model. This first step lays the foundation for more complex ERGMs that incorporate structural dependencies.

The Bernoulli ERGM assumes that all possible edges form independently of one another. In other words, the probability that a tie exists between nodes $u$ and $v$ is unrelated to whether other ties are present elsewhere in the network. This is a very strong assumption—and one that is often unrealistic in practice—but it is useful as a baseline.

Let $Y_{uv}$ be a binary random variable indicating the presence ($1$) or absence ($0$) of a tie between nodes $u$ and $v$. The full graph $G$ can then be represented by its adjacency matrix $Y$, where $Y_{uv}$ encodes the tie between $u$ and $v$.

In the general formulation of an exponential random graph model, one could imagine assigning a different parameter $\theta_{uv}$ to every possible tie $(u, v)$ in the network. This would allow the model to express highly specific tendencies for each dyad. The probability of observing a network $G$ under this formulation would be:

$$
P(G) = \frac{1}{\kappa} \exp\left( \sum_{u<v} \theta_{uv} y_{uv} \right)
$$

However, this model quickly becomes infeasible because it would require estimating a separate parameter for every possible edge—a number that grows quadratically with the number of nodes.

To make the model estimable and interpretable, ERGMs rely on the **homogeneity assumption**: the effect of a given configuration (such as an edge, triangle, or mutual tie) is the same wherever it appears in the network. That is, all instances of the same configuration share a single global parameter. For the Bernoulli ERGM, this means:

$$
\theta_{uv} = \theta \quad \text{for all } (u, v)
$$

Applying this assumption simplifies the model considerably:

$$
P(G) = \frac{1}{\kappa} \exp\left( \theta \sum_{u<v} y_{uv} \right) = \frac{1}{\kappa} \exp(\theta \cdot L)
$$

Here, $L$ is the total number of edges in the network, $\theta$ is a single parameter that governs the overall probability of tie formation, and $\kappa$ is the normalizing constant ensuring all probabilities sum to 1.


This structure implies that each potential tie forms independently with the same probability, much like in a $G(n, p)$ random graph. Here, the parameter $\theta$ governs the log-odds of a tie between any two nodes. More formally, the relationship between $\theta$ and the tie probability $p$ (i.e., the density of the network) is:

$$
\theta = \log\left( \frac{p}{1 - p} \right) \quad \Leftrightarrow \quad p = \frac{e^\theta}{1 + e^\theta}
$$

This means that:

- When $\theta = 0$, the expected density is $p$ = 0.5
- When $\theta < 0$, the expected density is less than 0.5 (a sparse network)
- When $\theta > 0$, the expected density is greater than 0.5

So, the edge parameter directly controls the overall density of the network. In practice, real-world social networks tend to be sparse, so $\theta$ is typically negative. This relationship also means that if you estimate a Bernoulli ERGM and obtain an edge coefficient $\hat{\theta}$, you can compute the implied expected density using:

$$
\hat{p} = \frac{e^{\hat{\theta}}}{1 + e^{\hat{\theta}}}
$$

This makes the edge parameter easy to interpret: it is just the logit-transformed density.

::: {.callout-note}
## Note: $G(n, p)$ as a Special Case of ERGM
The Bernoulli ERGM is structurally identical to the $G(n, p)$ model, with the relationship:

- $\theta = 0$ → expected density $p = 0.5$
- $\theta > 0$ → expected density $p > 0.5$
- $\theta < 0$ → expected density $p < 0.5$

However, this does not hold in general (if the ERGM contains other statistics).

Put differently, the $G(n, p)$ random graph model is actually a special case of an ERGM. It includes only one term: the number of edges. 
:::


In ERGMs, a parameter estimate is considered statistically significant (by convention) if the absolute value of the estimate is greater than approximately twice its standard error (i.e., $|\hat{\theta}| > 2 \cdot \text{SE}$). This rule of thumb suggests that the corresponding network feature (such as homophily or reciprocity) is unlikely to have arisen by chance, and is therefore meaningfully associated with the observed pattern of tie formation.

### Example: Coleman Friendship {.unnumbered}

To demonstrate the Bernoulli ERGM, we fit the model to the Coleman high school friendship network used in @sec-nonparam. However, here we convert ther graph object into an adjacency matrix since the `ergm` response argument needs to be a network object or a matrix that can be coerced to a network object. 

```{r}
#| message: false

# Load data as graph object from networkdata and extract the fall network
coleman_g <- networkdata::coleman[[1]]

# Convert to adjacency matrix
coleman_mat <- as_adjacency_matrix(coleman_g, sparse = FALSE)

# Fit Bernoulli ERGM with only the edge term
model_bern <- ergm(coleman_mat ~ edges)
summary(model_bern)
```
The output provides the estimated $\theta$ parameter for the edge term. A strongly negative value suggests that the probability of a tie between any two students is low, which is typical of real-world social networks that are sparse.

The estimated edge parameter from the Bernoulli ERGM is:
$$
\hat{\theta}_{\text{edges}} = -3.02673
$$

This value reflects the log-odds of a tie forming between any two nodes in the network. To convert this into an expected tie probability (i.e., network density), we apply the inverse logit function:

$$
p = \frac{e^{\hat{\theta}}}{1 + e^{\hat{\theta}}}
$$

Substituting the estimated value:

$$
p = \frac{e^{-3.02673}}{1 + e^{-3.02673}} \approx 0.046
$$

This result implies that the expected density of the network under this model is approximately 4.6%. This is in fact the density of the observed network which you can verify:
```{r}
edge_density(coleman_g)
```


### Dyadic Independence: Homophily {.unnumbered}

Another class of network statistics in ERGMs captures **homophily**: the tendency of individuals to form ties with others who are similar to themselves in a particular attribute, such as gender, age, race, or occupation.

Let each node in the network have a categorical attribute, denoted:

$$
a : V \rightarrow \{1, \dots, c\}
$$

This maps each actor to one of $c$ categories. To model homophily, we define a statistic that counts the number of ties between actors who share the same attribute value:

$$
m_a(G) = \left| \left\{ \{u, v\} \in E : a(u) = a(v) \right\} \right|
$$

That is, $m_a(G)$ is the number of edges where both endpoints belong to the same category. Adding this statistic to the ERGM, the model becomes:

$$
P(G) = \frac{1}{\kappa} \exp\left( \theta_1 \cdot L + \theta_2 \cdot m_a(G) \right)
$$

We interpret the homophily parameter as follows:

- $\theta_2 > 0$: Ties between similar nodes are more likely (homophily)
- $\theta_2 < 0$: Ties between dissimilar nodes are more likely (heterophily)
- $\theta_2 = 0$: No effect of similarity

This formulation assumes that the tendency for similarity-based tie formation is uniform across all dyads, consistent with the homogeneity assumption discussed earlier. Moreover, since the statistic depends only on the attributes of the two actors in a dyad and not on any other ties in the network, it also maintains dyadic independence. That is, the presence or absence of one tie does not influence the probability of others, unless additional structural terms (like triangles or mutual ties) are included in the model.

Thus, including a homophily term allows us to model nodal covariate effects; how actor characteristics affect tie formation—while keeping the model simple and tractable.


### Example: Teenage Friends and Lifestyle Study data {.unnumbered}
For an example including the homophily statistic, we use the the Teenage Friends and Lifestyle Study data called `s50` in the `networkdata` package. The `s50` dataset is a subset of 50 girls over a three-year panel study of adolescent friendship networks and health behaviors conducted in a school in the West of Scotland [@west1996s50]. This excerpt was created for illustrative purposes and includes dynamic friendship data over three waves, capturing changes in social ties alongside attributes like gender, sport participation, and substance use. We will focus on the homophily based on smoking behavior.

We only consider cross-sectional network data here so we only focus on the third wave network (we will in later chapters look at modeling longitudinal network data). Let's prepare the data for the `ergm` specification. Note that we here instead convert the graph object inot a network one using the package `integraph` in order to preserve the node attribute of interest

```{r}
#| message: false

# Load data as graph object from networkdata and extract the third wave network
s50_g <- networkdata::s50[[3]]

# Convert to network object using intergraph
s50_net <- asNetwork(s50_g)

# check netowrk obejct and stored attributes
s50_net
```

We now test whether students tend to form friendships with others who have the same smoking behavior. The `s50` dataset includes a categorical node attribute called `smoke`, with three levels: non-smoker (1), occasional smoker (2), and regular smoker (3). To test for smoking-based homophily, we fit an ERGM that includes an edge term and a `nodematch("smoke")` term.

```{r}
#| message: false
# Fit ERGM with homophily on smoking status
model_smoke <- ergm(s50_net ~ edges + nodematch("smoke"))
summary(model_smoke)
```
The model includes two terms:

- `edges`: controls for the overall density of the network (should always be included)
- `nodematch("smoke")`: counts the number of ties where both nodes have the same smoking status.

This specification assumes that the tendency to form ties is homogeneous across dyads, and the homophily term preserves dyadic independence, as it depends only on the attributes of the two individuals involved in each potential tie.

We interpret the output as follows. The `edges` term gives the baseline log-odds of a tie between two students, regardless of smoking behavior. The `nodematch(“smoke”)` term estimates the additional log-odds of a tie when two students share the same smoking status.

Since the coefficient for `nodematch("smoke")` is positive and significant, we see that students tend to form ties with peers who have similar smoking habits (homophily).

::: {.callout-note}
#  Note on `nodematch()`
Note that `nodematch("smoke")` adds one statistic to the model: the total number of edges connecting nodes that share the same value of the smoke attribute. It does not distinguish between which category is shared, it treats all matches equally.
So in our case, it would count:

- Ties between two non-smokers
- Ties between two occasional smokers
- Ties between two regular smokers

All of those contribute to the same term. It does not tell you whether one group is more homophilous than another. If we want more detail, we can instead use `nodemix("smoke")` as it can separate estimates for each combination of categories (e.g., smoker-smoker, smoker-non-smoker, etc.), that is you get detailed between-group dynamics.
:::

### Dyadic Dependence: Reciprocity {.unnumbered}


### Markov Dependence: Triangles and Stars {.unnumbered}


### Social Circuit Dependence: GWESP{.unnumbered}

## 2. Model Estimation and Simulation {.unnumbered}
Estimating the parameters of an ERGM involves finding values for $\boldsymbol{\theta}$ that make the observed network most likely under the specified model. This is done using **maximum likelihood estimation (MLE)**. The goal is to find the parameter vector $\hat{\boldsymbol{\theta}}$ that maximizes the probability of the observed network $G_{\text{obs}}$:

$$
\hat{\boldsymbol{\theta}} = \arg\max_{\boldsymbol{\theta}} \, P(G_{\text{obs}} \mid \boldsymbol{\theta}) = \frac{\exp\left( \boldsymbol{\theta}^\top \mathbf{s}(G_{\text{obs}}) \right)}{\kappa(\boldsymbol{\theta})}
$$

Here, $\mathbf{s}(G)$ is the vector of network statistics (e.g., number of edges, mutual ties, triangles), and $\kappa(\boldsymbol{\theta})$ is the normalizing constant that sums the exponential term over all possible networks:

$$
\kappa(\boldsymbol{\theta}) = \sum_{G'} \exp\left( \boldsymbol{\theta}^\top \mathbf{s}(G') \right)
$$
The main difficulty in estimating ERGMs lies in the fact that $\kappa(\boldsymbol{\theta})$ involves a sum over all possible networks with the same number of nodes; an astronomically large space. This makes direct likelihood maximization intractable for any network of realistic size.

To overcome this, ERGMs use **Markov Chain Monte Carlo Maximum Likelihood Estimation (MCMCMLE)**. The idea is to simulate many networks from the current estimate of the model and compare their statistics to those of the observed network. The process iteratively updates the parameter estimates so that the simulated statistics converge toward the observed ones.

This simulation-based procedure involves two key steps:

1. **MCMC Sampling**: Generate random networks from the current parameter estimates using a Markov chain.
2. **Score Updating**: Adjust the parameter values to reduce the difference between simulated and observed network statistics.

This process continues until convergence is achieved, when the model parameters yield simulations whose average statistics closely match those of the observed network.

Because ERGMs rely on MCMC simulation to estimate model parameters, it is crucial to check whether the estimation process has properly converged. **MCMC diagnostics** help assess whether the Markov chain has explored the space of possible networks sufficiently and whether the simulated networks reflect a stable distribution. Poor convergence can lead to unreliable parameter estimates and misleading inferences. Key diagnostics include trace plots (to check stability of simulated statistics over time), autocorrelation plots (to assess dependence between samples), and comparisons between observed and simulated statistics. A well-fitting model should not only reproduce the observed statistics on average but also generate networks with similar variability and structure. Running these diagnostics ensures that conclusions drawn from the model are based on a valid and stable estimation process. 

While MCMC diagnostics are useful in general, they are especially critical when estimating dyad-dependent ERGMs; models in which the probability of a tie depends on the presence or absence of other ties in the network. This includes models with terms like triangles, $k$-stars, or other structural dependencies. In these cases, the network space becomes highly constrained and interdependent, making it more challenging for the Markov chain to explore effectively. As a result, convergence issues are more common, and MCMC diagnostics play a key role in ensuring that the simulation-based estimation has produced reliable parameter values. 

For dyad-independent models (e.g., those using only nodal covariates like homophily), estimation is generally simpler and may not require full MCMC sampling or diagnostics. Thus, careful diagnostic checks are particularly essential when modeling endogenous network structure.

## References {.unnumbered}
