[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Social Network Analysis",
    "section": "",
    "text": "Welcome\nThis book is work in progress. See the announcement post for more details.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "What you will learn",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#how-this-book-is-organized",
    "href": "intro.html#how-this-book-is-organized",
    "title": "Introduction",
    "section": "How this book is organized",
    "text": "How this book is organized",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#what-you-wont-learn",
    "href": "intro.html#what-you-wont-learn",
    "title": "Introduction",
    "section": "What you won’t learn",
    "text": "What you won’t learn",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "Introduction",
    "section": "Prerequisites",
    "text": "Prerequisites\n(This section is taken and slightly adapted from R for Data Science 2e)\nWe’ve made a few assumptions about what you already know to get the most out of this book. You should be generally numerically literate, and it’s helpful if you have some basic programming experience already. If you’ve never programmed before, you might find Hands on Programming with R by Garrett to be a valuable adjunct to this book.\nYou need four things to run the code in this book: R, an IDE, a collection of “base” R packages, and a handful of other packages. Packages are the fundamental units of reproducible R code. They include reusable functions, documentation that describes how to use them, and sample data.\n\nR\nTo download R, go to CRAN, the comprehensive R archive network, https://cloud.r-project.org. A new major version of R comes out once a year, and there are 2-3 minor releases each year. It’s a good idea to update regularly. Upgrading can be a bit of a hassle, especially for major versions that require you to re-install all your packages, but putting it off only makes it worse. We recommend R 4.3.0 or later for this book.\n\n\nIDE\nWe make no assumption about your integrated development environment. RStudio is a popular choice for R programming, which you can download from https://posit.co/download/rstudio-desktop/. RStudio is updated a couple of times a year, and it will automatically let you know when a new version is out, so there’s no need to check back. It’s a good idea to upgrade regularly to take advantage of the latest and greatest features. For this book, make sure you have at least RStudio 2022.02.0.\nBut nothing will stop you to use other environments, such as vscode, emacs, or vi if you are already used to them.\n\n\nThe “base” Packages\nWhen it comes to performing data science tasks with R, there are many excellent packages (or even package ecosystems) to choose from. There is for instance the tidyverse, data.table, or rpolars. All have there advantages and disadvantages but ultimately, they allow to do similar tasks with varying syntax.\nIn the R world for networks, there are far less choices and for the most basic network analytic tasks, there are essentially two packages: igraph and sna.\nWe will discuss these packages here and motivate why we would recommend igraph as the goto package for standard network analytic tasks. But that does not render sna and its companion network void. On the contrary, there are some essential modelling tasks which can only be done within the realm of network.\nBoth igraph and network also provide data structures which facilitate to store and process network data. There also once existed the package graph but that is not available on CRAN anymore, only via Bioconductor.\nThe figure below shows how many packages on CRAN rely on those three packages (i.e. they are mentioned in Depends, Imports, or Suggests).\n\n\n\n\n\n\n\n\n\nThe figure was produced with the help of the cranet package. igraph seems to be clearly favored by the R community. So if you install a package for, say, signed network analysis, changes are high that it depends on the graph structures provided by igraph. Besides the data structures, the package offers a large variety of network analytic methods which are all implemented in C. The methods are well optimized and also work nicely for large graphs.\nThe network package historically shares some commonalities with igraphs data structures. The package itself, though is really only providing the data structure and no analytic methods. The sna package (link) implements network analytic tools using the data structures of network. Overall, the syntax and provided methods are very much comparable between igraph and sna and they are almost interchangeable in this regard. The advantage of igraph is its speed. I have run several benchmark tasks and igraph usually comes out on top. That being said, there is no real case to be made against network/sna. If you are into statistical modelling of networks, then that should actually be the preferred choice since the ergm package is build on top of network. In this case you probably also want to look at the meta package statnet (link) which includes network, sna, and ergm (among other packages).\nNote that the package intergraph (link) can be used to quickly switch representations between igraph and network.\nThe igraph package will play a major role in the Part on Descripitve Network Analysis, while network will be more prominent for Inferential Network Analysis.\n\n\nOther packages\n[LIST USED PACKAGES WITH DESCRIPTION]",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "network-data.html",
    "href": "network-data.html",
    "title": "Network Data",
    "section": "",
    "text": "Introduction\nThis introductory chapter will give a short explanation of key terminology and how network data can be represented. The larger part of the chapter is concerned with representing networks in R using igraph and how to construct or read network data.\nAfter reading this chapter, you should have a basic understanding of what networks and network data is and how to create network objects in R using igraph.",
    "crumbs": [
      "Network Data"
    ]
  },
  {
    "objectID": "network-data.html#what-is-a-network",
    "href": "network-data.html#what-is-a-network",
    "title": "Network Data",
    "section": "What is a network?",
    "text": "What is a network?\nIn the context of social network analysis, a network is a conceptual and analytical constrcut to understand, visualize, and examine the (social) relationships and structures that emerge from the interactions among individuals, groups, organizations, or even entire societies. At its core, a network consists of nodes (which represent the actors, whether individuals or organizations) and edges (which signify the relationships or connections between these actors). These relationships can embody various types of interactions such as communication, friendship, professional ties, or social influence, among others.\nNetworks in the social sciences are tools for mapping and quantifying the patterns of social connections, helping to reveal the underlying dynamics of social cohesion, influence, and information flow within a community or society. Through the lens of network theory, analysts can explore how social structures influence behaviors, opportunities, and outcomes for individuals and groups, making it an invaluable approach in sociology, anthropology, political science, and many other disciplines that study social systems and interactions.",
    "crumbs": [
      "Network Data"
    ]
  },
  {
    "objectID": "network-data.html#network-representations",
    "href": "network-data.html#network-representations",
    "title": "Network Data",
    "section": "Network representations",
    "text": "Network representations\nThere are several possible ways to express network data. All come with a set of advantages and disadvantages.\n\nAdjacency Matrix\nAn adjacency matrix is a square matrix where the elements indicate whether pairs of vertices in the graph are adjacent or not—meaning, whether they are directly connected by an edge. If the graph has \\(n\\) vertices, the matrix \\(A\\) will be an \\(n \\times n\\) matrix where the entry \\(A_{ij}\\) is \\(1\\) if there is an edge from vertex \\(i\\) to vertex \\(j\\), and \\(0\\) if there is no edge. In the case of weighted graphs the weight of the edge is used. This matrix is symmetric for undirected graphs, indicating that an edge is bidirectional.\nPros:\n\nSimple Representation: It provides a straightforward and compact way to represent graphs, especially useful for dense graphs where many or most pairs of vertices are connected.\nEfficient for Edge Lookups: Checking whether an edge exists between two vertices can be done in constant time, making it efficient for operations that require frequent edge lookups.\nEasy Implementation of Algorithms: Many graph algorithms can be easily implemented using adjacency matrices, making it a preferred choice for certain computational tasks.\n\nCons:\n\nSpace Inefficiency: For sparse graphs, where the number of edges is much less than the square of the number of vertices, an adjacency matrix uses a lot of memory to represent a relatively small number of edges.\nPoor Scalability: As the number of vertices grows, the size of the matrix grows quadratically, which can quickly become impractical for large graphs.\n\n\n\nEdge List\nAn edge list is a matrix where each row indicates an edge. In an undirected graph, an edge is represented by a pair \\((i,j)\\), indicating a connection between vertices \\(i\\) and \\(j\\). For directed graphs, the order of the vertices in each pair denotes the direction of the edge, from the first vertex to the second. In weighted graphs, a third column can be added to each pair to represent the weight of the edge.\nPros:\n\nSpace Efficiency for Sparse Graphs: Edge lists are particularly space-efficient for representing sparse graphs where the number of edges is much lower than the square of the number of vertices, as they only store the existing edges.\nSimplicity: The structure is straightforward and easy to understand, making it suitable for simple graph operations and for initial graph representation before processing.\n\nCons:\n\nInefficient for Edge Lookups: Checking whether an edge exists between two specific vertices can be time-consuming, as it may require scanning through the entire list, leading to an operation that is linear in the number of edges.\nInefficiency in Graph Operations: Operations like finding all vertices adjacent to a given vertex or checking for connectivity between vertices can be inefficient compared to other representations like adjacency matrices or adjacency lists, especially for dense graphs.\nLess Suitable for Dense Graphs: As the number of edges grows, the edge list can become large and less efficient in terms of both space and operation time compared to an adjacency matrix for dense graphs, where the number of edges is close to the maximum possible number of edges.\n\n\n\nAdjacency List\nAn adjacency list is a collection of lists, with each list corresponding to the set of adjacent vertices of a given vertex. This means that for every vertex \\(i\\) in the graph, there is an associated list that contains all the vertices \\(j\\) to which \\(i\\) is directly connected.\nPros:\n\nSpace Efficiency: Adjacency lists are more space-efficient than adjacency matrices in sparse graphs, as they only store information about the actual connections.\nScalability: This representation scales better with the number of edges, especially for graphs where the number of edges is far less than the square of the number of vertices.\nEfficiency in Graph Traversal: For operations like graph traversal or finding all neighbors of a vertex, adjacency lists provide more efficient operations compared to adjacency matrices, particularly in sparse graphs.\n\nCons:\n\nEdge Lookups: Checking whether an edge exists between two specific vertices can be less efficient than with an adjacency matrix, as it may require traversing a list of neighbors.\nVariable Edge Access Time: The time to access a specific edge or to check for its existence can vary depending on the degree of the vertices involved, leading to potentially inefficient operations in certain scenarios.\nHigher Complexity for Dense Graphs: In very dense graphs, where the number of edges approaches the number of vertex pairs, adjacency lists can become less efficient in terms of space and time compared to adjacency matrices, due to the overhead of storing a list for each vertex.",
    "crumbs": [
      "Network Data"
    ]
  },
  {
    "objectID": "network-data.html#networks-in-igraph",
    "href": "network-data.html#networks-in-igraph",
    "title": "Network Data",
    "section": "Networks in igraph",
    "text": "Networks in igraph\nBelow, we represent friendship relations between Bob, Ann, and Steve as a matrix and an edgelist.\n\n# adjacency matrix\nA &lt;- matrix(\n    c(0, 1, 1, 1, 0, 1, 1, 1, 0),\n    nrow = 3, ncol = 3, byrow = TRUE\n)\n\nrownames(A) &lt;- colnames(A) &lt;- c(\"Bob\", \"Ann\", \"Steve\")\nA\n\n      Bob Ann Steve\nBob     0   1     1\nAnn     1   0     1\nSteve   1   1     0\n\n# edgelist\nel &lt;- matrix(c(\"Bob\", \"Ann\", \"Bob\", \"Steve\", \"Ann\", \"Steve\"),\n    nrow = 3, ncol = 2, byrow = TRUE\n)\nel\n\n     [,1]  [,2]   \n[1,] \"Bob\" \"Ann\"  \n[2,] \"Bob\" \"Steve\"\n[3,] \"Ann\" \"Steve\"\n\n\nOnce we have defined an edgelist or an adjacency matrix, we can turn them into igraph objects as follows.\n\ng1 &lt;- graph_from_adjacency_matrix(A, mode = \"undirected\", diag = FALSE)\n\ng2 &lt;- graph_from_edgelist(el, directed = FALSE)\n# g1 and g2 are the same graph so only printing g1\ng1\n\nIGRAPH 7e4bc37 UN-- 3 3 -- \n+ attr: name (v/c)\n+ edges from 7e4bc37 (vertex names):\n[1] Bob--Ann   Bob--Steve Ann--Steve\n\n\nThe printed summary shows some general descriptives of the graph. The string “UN–” in the first line indicates that the network is Undirected (D for directed graphs) and has a Name attribute (we named the nodes Bob, Ann, and Steve). The third and forth character are W, if there is a edge weight attribute, and B if the network is bipartite (there exists a node attribute “type”). The following number indicate the number of nodes and edges. The second line lists all graph, node and edge variables. Here, we only have a node attribute “name”.\nThe conversion from edgelist/adjacency matrix into an igraph object is quite straightforward. The only difficulty is setting the parameters correctly (Is the network directed or not?), especially for edgelists where it may not immediately be obvious if the network is directed or not.",
    "crumbs": [
      "Network Data"
    ]
  },
  {
    "objectID": "network-data.html#importing-network-data",
    "href": "network-data.html#importing-network-data",
    "title": "Network Data",
    "section": "Importing Network Data",
    "text": "Importing Network Data\n\nNodes and Edges\n\n\nAttributes\n\n\nImport via snahelper",
    "crumbs": [
      "Network Data"
    ]
  },
  {
    "objectID": "descriptives-basic.html",
    "href": "descriptives-basic.html",
    "title": "1  Basic Network Statistics",
    "section": "",
    "text": "1.1 Introduction",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Network Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-basic.html#simple-network-characteristics",
    "href": "descriptives-basic.html#simple-network-characteristics",
    "title": "1  Basic Network Statistics",
    "section": "1.2 Simple Network Characteristics",
    "text": "1.2 Simple Network Characteristics\nIn the following, we use a network from the networkdata package to introduce some basic network statistics.\n\ndata(\"greys\")\n\n\n\n\n\n\n\n\n\n\nThe “greys” network consists of characters from the show “Grey’s Anatomy” and links indicate who hooked up with whom (up to about 2022).\n\ngreys\n\nIGRAPH f7716f1 UN-- 54 57 -- \n+ attr: name (v/c), sex (v/c), race (v/c), birthyear (v/n), position\n| (v/c), season (v/n), sign (v/c)\n+ edges from f7716f1 (vertex names):\n [1] Arizona Robbins--Leah Murphy     Alex Karev     --Leah Murphy    \n [3] Arizona Robbins--Lauren Boswell  Arizona Robbins--Callie Torres  \n [5] Erica Hahn     --Callie Torres   Alex Karev     --Callie Torres  \n [7] Mark Sloan     --Callie Torres   George O'Malley--Callie Torres  \n [9] Izzie Stevens  --George O'Malley Meredith Grey  --George O'Malley\n[11] Denny Duqutte  --Izzie Stevens   Izzie Stevens  --Alex Karev     \n[13] Derek Sheperd  --Meredith Grey   Preston Burke  --Cristina Yang  \n+ ... omitted several edges\n\n\nThe density of a network is defined as the fraction of the potential edges in a network that are actually present.\n\nc(\n    edge_density(make_empty_graph(10)),\n    edge_density(greys),\n    edge_density(make_full_graph(10))\n)\n\n[1] 0.0000000 0.0398323 1.0000000\n\n\nThe density of an empty network is \\(0\\) and for the full network it is \\(1\\). The density of empirical network is somewhere in between but as the number of nodes increases, we’d expect the density to decrease and the network becomes quite sparse.\nA shortest path is a path that connects two nodes in a network with a minimal number of edges. The length of a shortest path is called the distance between two nodes.\n\nshortest_paths(greys,from = \"Alex Karev\",to = \"Owen Hunt\",output = \"vpath\")\n\n$vpath\n$vpath[[1]]\n+ 5/54 vertices, named, from f7716f1:\n[1] Alex Karev         Addison Montgomery Mark Sloan         Teddy Altman      \n[5] Owen Hunt         \n\n\n$epath\nNULL\n\n$predecessors\nNULL\n\n$inbound_edges\nNULL\n\n\n\n\n\n\n\n\n\n\n\n\ndistances(greys)[1:10, 1:10]\n\n                   Addison Montgomery Adele Webber Teddy Altman Amelia Shepherd\nAddison Montgomery                  0          Inf            2               2\nAdele Webber                      Inf            0          Inf             Inf\nTeddy Altman                        2          Inf            0               2\nAmelia Shepherd                     2          Inf            2               0\nArizona Robbins                     3          Inf            3               3\nRebecca Pope                        2          Inf            4               4\nJackson Avery                       3          Inf            3               3\nMiranda Bailey                    Inf          Inf          Inf             Inf\nBen Warren                        Inf          Inf          Inf             Inf\nHenry Burton                        3          Inf            1               3\n                   Arizona Robbins Rebecca Pope Jackson Avery Miranda Bailey\nAddison Montgomery               3            2             3            Inf\nAdele Webber                   Inf          Inf           Inf            Inf\nTeddy Altman                     3            4             3            Inf\nAmelia Shepherd                  3            4             3            Inf\nArizona Robbins                  0            3             4            Inf\nRebecca Pope                     3            0             3            Inf\nJackson Avery                    4            3             0            Inf\nMiranda Bailey                 Inf          Inf           Inf              0\nBen Warren                     Inf          Inf           Inf              1\nHenry Burton                     4            5             4            Inf\n                   Ben Warren Henry Burton\nAddison Montgomery        Inf            3\nAdele Webber              Inf          Inf\nTeddy Altman              Inf            1\nAmelia Shepherd           Inf            3\nArizona Robbins           Inf            4\nRebecca Pope              Inf            5\nJackson Avery             Inf            4\nMiranda Bailey              1          Inf\nBen Warren                  0          Inf\nHenry Burton              Inf            0\n\n\nThe Grey’s Anatomy network is disconnected and consists of \\(4\\) connected components. There are no shortest paths between components, which means that the distance is not measurable and set to infinity.\nThe length of the longest shortest path is called the diameter of the network.\n\ndiameter(greys)\n\n[1] 8\n\n\n\n\n\n\n\n\n\n\n\nTransitivity measures the probability that the neighbors of a node are also connected. This is also called the clustering coefficient.\n\ntransitivity(greys, type = \"global\")\n\n[1] 0\n\ntransitivity(greys, type = \"local\", isolates = \"zero\")\n\nAddison Montgomery       Adele Webber       Teddy Altman    Amelia Shepherd \n                 0                  0                  0                  0 \n   Arizona Robbins       Rebecca Pope      Jackson Avery     Miranda Bailey \n                 0                  0                  0                  0 \n        Ben Warren       Henry Burton    Catherine Avery       Colin Marlow \n                 0                  0                  0                  0 \n     Denny Duqutte      Derek Sheperd         Ellis Grey     Finn Dandridge \n                 0                  0                  0                  0 \n     Meredith Grey         Erica Hahn               Hank      Izzie Stevens \n                 0                  0                  0                  0 \n        Alex Karev       April Kepner         Lexie Grey              Lloyd \n                 0                  0                  0                  0 \n       Lucy Fields      Megan Nowland       Steve Mostow       Dana Seabury \n                 0                  0                  0                  0 \n     Nancy Shepard       Nurse Olivia    George O'Malley          Owen Hunt \n                 0                  0                  0                  0 \n    Andrew Perkins      Pierce Halley      Preston Burke       Reed Adamson \n                 0                  0                  0                  0 \n        Mark Sloan       Steve Murphy         Susan Grey      Thatcher Grey \n                 0                  0                  0                  0 \n     Callie Torres       Tucker Jones      Cristina Yang     Heather Brooks \n                 0                  0                  0                  0 \n         Jo Wilson     Lauren Boswell        Leah Murphy          Eli James \n                 0                  0                  0                  0 \n              Emma  Stephanie Edwards         Shane Ross     Richard Webber \n                 0                  0                  0                  0 \n              Rose       Nathan Riggs \n                 0                  0 \n\n\nThe global transitivity of an undirected network is the ratio of the triangles and the connected triples in the network. Local transitivity of a node is the ratio of the triangles connected to the node and the triples centered on the node itself. In social networks, we generally assume that the transitivity is quite high (“the friend of my friend is also my friend”). In our example, we have zero for all values. This is due to the fact that a triangle would require a same sex hook-up which did not occur (Disclaimer: I never watched the show and gathered the hook ups from various internet resources. So this may well be wrong.).\nFor directed networks, a measure of importance is reciprocity, which is defined as the proportion of mutual edges between nodes. To illustrate the measure, we use a network of grooming relations among a group of rhesus monkeys.\n\ndata(\"rhesus\")\nreciprocity(rhesus)\n\n[1] 0.756757\n\n\nAbout 76% of edges are reciprocated in the network. The figure below highlights the reciprocated edges.\n\n\nWarning: `is.mutual()` was deprecated in igraph 2.0.0.\nℹ Please use `which_mutual()` instead.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Network Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-basic.html#dyad-and-triad-census",
    "href": "descriptives-basic.html#dyad-and-triad-census",
    "title": "1  Basic Network Statistics",
    "section": "1.3 Dyad and Triad Census",
    "text": "1.3 Dyad and Triad Census\nThe dyad census categorize all possible dyads within a network based on their mutual connection status. It classifies dyads into three categories: mutual (both nodes have a directed edge to the other, i.e. reciprocated), asymmetric (only one node has a directed edge to the other), and null (no directed edges between the nodes). The census provides insights into the overall reciprocity and directionality of relationships in the network, helping to understand the balance between mutual cooperation, one-sided relationships, and absence of direct interaction.\n\ndyad_census(rhesus)\n\n$mut\n[1] 42\n\n$asym\n[1] 27\n\n$null\n[1] 51\n\n\nMore important than the dyad census is usually the triad census. In a directed network, there are 16 possible configurations of edges that can occur between three nodes. \nThe triad census of a network gives the number of occurrences of each of these triad. Triads are labelled xyzL where x is the number of reciprocated ties, y is the number of unreciprocated ties and z is the number of null ties. The L term is a letter (U,C,D or T) which allows to differentiate between triads where these numbers are the same.\n\ntriad_census(rhesus)\n\n [1]  49  72 115  16  12  11  50  50   2   0  54  13  12   7  58  39",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Network Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-basic.html#use-case-triad-census",
    "href": "descriptives-basic.html#use-case-triad-census",
    "title": "1  Basic Network Statistics",
    "section": "1.4 Use case: Triad Census",
    "text": "1.4 Use case: Triad Census\nOne of the many applications of the triad census is to compare a set of networks. In this example, we are tackling the question of “how transitive is football?” and assess structural differences among a set of football leagues.\n\ndata(\"football_triad\")\n\nfootball_triad is a list which contains networks of 112 football leagues as igraph objects. A directed link between team A and B indicates that A won a match against B. Note that there can also be an edge from B to A, since most leagues play a double round robin. For the sake of simplicity, all draws were deleted so that there could also be null ties between two teams if both games ended in a draw.\nBelow, we calculate the triad census for all network at once using lapply(). The function returns the triad census for each network as a list, which we turn into a matrix in the second step. Afterwards, we manually add the row and column names of the matrix.\n\nfooty_census &lt;- lapply(football_triad, triad_census)\nfooty_census &lt;- matrix(unlist(footy_census), ncol = 16, byrow = T)\nrownames(footy_census) &lt;- sapply(football_triad, function(x) x$name)\ncolnames(footy_census) &lt;- c(\n    \"003\", \"012\", \"102\", \"021D\", \"021U\", \"021C\", \"111D\", \"111U\",\n    \"030T\", \"030C\", \"201\", \"120D\", \"120U\", \"120C\", \"210\", \"300\"\n)\n\n# normalize to make proportions comparable across leagues\nfooty_census_norm &lt;- footy_census / rowSums(footy_census)\n\n# check the Top 5 leagues\nidx &lt;- which(rownames(footy_census) %in% c(\n    \"england\", \"spain\", \"germany\",\n    \"italy\", \"france\"\n))\nfooty_census[idx, ]\n\n        003 012 102 021D 021U 021C 111D 111U 030T 030C 201 120D 120U 120C 210\nengland   2  10   0   58   31   40   34   44  338   29  19  118  129  143 131\nfrance    1  23   5   30   33   44   48   40  332   41  16  132  108  160 114\ngermany   0  21   6   27   19   49   38   46  165   16  23   77   79  117 120\nitaly     1   4   2   35   43   30   30   22  419   38   5  164  116  118  99\nspain     0   8   4   27   42   45   32   35  364   43  11  126  105  148 130\n        300\nengland  14\nfrance   13\ngermany  13\nitaly    14\nspain    20\n\n\nNotice how the transitive triad (030T) has the largest count in the top leagues, hinting toward the childhood wisdom: “If A wins against B and B wins against C, then A must win against C”.\nIn empirical studies, we are not necessarily only interested in transitive triads, but rather how the triad census profiles compare across networks. We follow Kathrine Faust’s suggestion and do a singular value decomposition (SVD) on the normalized triad census matrix.\n\nfooty_svd &lt;- svd(footy_census_norm)\n\nSVDs are used to reduce the dimensionality of the data, but retaining most of the information. In our case, the data is 16 dimensional, which is impossible to visualize to compare the networks. With an SVD, we can reduce it to two dimensions and get a better visual overview.\n\n\nWarning: ggrepel: 35 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n\nHow to interpret the dimensions? To investigate this question, we take a closer look at the first two dimensions and compare it to some network descriptives. For the sake of brevity, we here only look at the density and proportion of 030T triads. In general, any node/dyad/triad level statistic could be used.\n\n\n\n\n\n\n\n\n\nDensity doesn’t really seem to be related to the first dimension in this case (in many cases it is!). Might be worthwhile to explore this further\n\n\n\n\n\n\n\n\n\nFor the second dimension, we get a clearer association. It seems that the fraction of transitive triads is a good indicator for structural differences among leagues.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Network Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-basic.html#dyadtriad-census-with-attributes",
    "href": "descriptives-basic.html#dyadtriad-census-with-attributes",
    "title": "1  Basic Network Statistics",
    "section": "1.5 Dyad/Triad Census with Attributes",
    "text": "1.5 Dyad/Triad Census with Attributes\nThe R package netUtils implements a version of the dyad and triad census which can account for node attributes.\n\nlibrary(netUtils)\n\nThe node attribute should be integers from 1 to max(attr). The output of dyad_census_attr() is a data.frame where each row corresponds to a pair of attribute values and the count of asymmetric, symmetric and null dyads.\nThe output of triad_census_attr() is a named vector where the names are of the form Txxx-abc, where xxx corresponds to the standard triad census notation and “abc” are the attributes of the involved nodes.\n\nset.seed(112)\ng &lt;- sample_gnp(20, p = 0.3, directed = TRUE)\n# add a vertex attribute\nV(g)$type &lt;- rep(1:2, each = 10)\n\ndyad_census_attr(g, \"type\")\n\n  from_attr to_attr asym_ab asym_ba sym null\n1         1       1       0       0   4   41\n2         1       2      20      28  14   38\n3         2       2       0       0   8   37\n\ntriad_census_attr(g, \"type\")\n\n T003-111  T003-112  T003-122  T003-222  T012-111  T012-121  T012-112  T012-122 \n        8        33        28         7        32        40        31        19 \n T012-211  T012-221  T012-212  T012-222 T021D-111 T021D-211 T021D-112 T021D-212 \n       27        41        25        26         9        19        19        21 \nT021D-122 T021D-222  T102-111  T102-112  T102-122  T102-211  T102-212  T102-222 \n        7        10        11        18        16         5        19        10 \nT021C-111 T021C-211 T021C-121 T021C-221 T021C-112 T021C-212 T021C-122 T021C-222 \n       17        23        29        17        19         7        24        10 \nT111U-111 T111U-121 T111U-112 T111U-122 T111U-211 T111U-221 T111U-212 T111U-222 \n        9        16         7        21         5        13        10         6 \nT021U-111 T021U-112 T021U-122 T021U-211 T021U-212 T021U-222 T030T-111 T030T-121 \n       11        19        13         3        14         7        11        11 \nT030T-112 T030T-122 T030T-211 T030T-221 T030T-212 T030T-222 T120U-111 T120U-112 \n       11        13        10        14         8         5         1         8 \nT120U-122 T120U-211 T120U-212 T120U-222 T111D-111 T111D-121 T111D-112 T111D-122 \n        6         0         4         4         4        12         8        13 \nT111D-211 T111D-221 T111D-212 T111D-222  T201-111  T201-112  T201-121  T201-122 \n       14        20        10        15         0         5         3         5 \n T201-221  T201-222 T030C-111 T030C-112 T030C-122 T030C-222 T120C-111 T120C-121 \n        3         3         2        12        14         3         3         8 \nT120C-211 T120C-221 T120C-112 T120C-122 T120C-212 T120C-222 T120D-111 T120D-112 \n        7         5         5         7         7         6         0         9 \nT120D-211 T120D-212 T120D-122 T120D-222  T210-111  T210-121  T210-211  T210-221 \n        1         9         4         1         2         8         3         5 \n T210-112  T210-122  T210-212  T210-222  T300-111  T300-112  T300-122  T300-222 \n        1         3         5         5         0         1         0         2",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Network Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-basic.html#degree-distributions",
    "href": "descriptives-basic.html#degree-distributions",
    "title": "1  Basic Network Statistics",
    "section": "1.6 Degree distributions",
    "text": "1.6 Degree distributions",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Network Statistics</span>"
    ]
  },
  {
    "objectID": "descriptives-basic.html#scientific-reading",
    "href": "descriptives-basic.html#scientific-reading",
    "title": "1  Basic Network Statistics",
    "section": "1.7 Scientific Reading",
    "text": "1.7 Scientific Reading",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Network Statistics</span>"
    ]
  },
  {
    "objectID": "centrality-basic.html",
    "href": "centrality-basic.html",
    "title": "2  Centrality",
    "section": "",
    "text": "2.1 Introduction\nIn this chapter, we learn about network centrality, a key concept for identifying the most influential nodes within networks. In a nutshell, a measure of centrality is an index that assigns a numeric values to the nodes of the network. The higher the value, the more central the node. “Being central” is a very ambiguous term and it is thus no surprise that there exists a large variety of indices that assess centrality with very different structural properties of the network.\n[INSERT PERIODIC TABLE]",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Centrality</span>"
    ]
  },
  {
    "objectID": "centrality-basic.html#centrality-indices-igraph",
    "href": "centrality-basic.html#centrality-indices-igraph",
    "title": "2  Centrality",
    "section": "2.2 Centrality Indices igraph",
    "text": "2.2 Centrality Indices igraph\nThe package igraph implements the following 10 indices:\n\ndegree (degree())\nweighted degree (strength())\nbetweenness (betweenness())\ncloseness (closeness())\neigenvector (eigen_centrality())\nalpha centrality (alpha_centrality())\npower centrality (power_centrality())\nPageRank (page_rank())\neccentricity (eccentricity())\nhubs and authorities (authority_score() and hub_score())\nsubgraph centrality (subgraph_centrality())\n\nTo illustrate some of the indices, we use the “dbces11” graph which is part of the netrankr package.\n\ndata(\"dbces11\")\n\n\n\n\n\n\n\n\n\n\ndegree simply counts the number of neighbors a node has.\n\ndegree(dbces11)\n\nA B C D E F G H I J K \n1 1 2 2 3 4 4 4 4 4 5 \n\n\n\n\n\n\n\n\n\n\n\ncloseness computes the shortest path distances among nodes. The most central node has the minimum distance to all other nodes (Since high scores are associated with central nodes, the distances are inverted).\n\ncloseness(dbces11)\n\n        A         B         C         D         E         F         G         H \n0.0370370 0.0294118 0.0400000 0.0400000 0.0500000 0.0588235 0.0526316 0.0555556 \n        I         J         K \n0.0555556 0.0526316 0.0555556 \n\n\nThe animation below gives an intuition on the calculation for one node. \nbetweeness is the number of shortest paths that pass through a node (divided by the total number of shortest paths)\n\nbetweenness(dbces11)\n\n       A        B        C        D        E        F        G        H \n 0.00000  0.00000  0.00000  9.00000  3.83333  9.83333  2.66667 16.33333 \n       I        J        K \n 7.33333  1.33333 14.66667 \n\n\nTo get an intuition what it means to have a high betweenness, check the network below.\n\n\n\n\n\n\n\n\n\nAny shortest path from the right will pass through the red node and vice versa. The red note is thus a sort of “gatekeeper” for any information that is passed from left to right.\neigenvector centrality extends the idea of degree by assuming that a node is central if it is connected to other central nodes.\n\neigen_centrality(dbces11)$vector\n\n        A         B         C         D         E         F         G         H \n0.2259630 0.0645825 0.3786244 0.2415182 0.5709057 0.9846544 1.0000000 0.8386195 \n        I         J         K \n0.9113529 0.9986474 0.8450304 \n\n\nsubgraph centrality is a bit more abstract but what it does is summing up all closed walks weighting them by the inverse factorial of its length.\n\nsubgraph_centrality(dbces11)\n\n      A       B       C       D       E       F       G       H       I       J \n1.82510 1.59540 3.14857 2.42309 4.38713 7.80726 7.93941 6.67278 7.03267 8.24212 \n      K \n7.38956 \n\n\nThe remaining indices are mostly designed for directed networks, page rank being the prime example. Note, though that the indices above can also be applied to directed networks.\nIf we highlight the most central node for the calculated indices, we get the following.\n\n\n\n\n\n\n\n\n\nSo each index picks a different node as most central. While this is just a toy example, it highlights how influential the choice of indices can be in empirical settings.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Centrality</span>"
    ]
  },
  {
    "objectID": "centrality-basic.html#centrality-indices-sna",
    "href": "centrality-basic.html#centrality-indices-sna",
    "title": "2  Centrality",
    "section": "2.3 Centrality indices sna",
    "text": "2.3 Centrality indices sna\nThe sna package implements roughly the same indices as igraph but adds:\n\nflow betweenness (flowbet())\nload centrality (loadcent())\nGil-Schmidt Power Index (gilschmidt())\ninformation centrality (infocent())\nstress centrality (stresscent())",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Centrality</span>"
    ]
  },
  {
    "objectID": "centrality-basic.html#other-centrality-packages",
    "href": "centrality-basic.html#other-centrality-packages",
    "title": "2  Centrality",
    "section": "2.4 Other Centrality Packages",
    "text": "2.4 Other Centrality Packages\nThere are also some dedicated centrality packages, such as centiserve, CINNA, influenceR and keyplayer. The biggest in terms of implemented indices is currently centiserve with a total of 33 indices.\n\nlibrary(centiserve)\n\nLoading required package: Matrix\n\nas.character(lsf.str(\"package:centiserve\"))\n\n [1] \"averagedis\"            \"barycenter\"            \"bottleneck\"           \n [4] \"centroid\"              \"closeness.currentflow\" \"closeness.freeman\"    \n [7] \"closeness.latora\"      \"closeness.residual\"    \"closeness.vitality\"   \n[10] \"clusterrank\"           \"communibet\"            \"communitycent\"        \n[13] \"crossclique\"           \"decay\"                 \"diffusion.degree\"     \n[16] \"dmnc\"                  \"entropy\"               \"epc\"                  \n[19] \"geokpath\"              \"hubbell\"               \"katzcent\"             \n[22] \"laplacian\"             \"leaderrank\"            \"leverage\"             \n[25] \"lincent\"               \"lobby\"                 \"markovcent\"           \n[28] \"mnc\"                   \"pairwisedis\"           \"radiality\"            \n[31] \"salsa\"                 \"semilocal\"             \"topocoefficient\"      \n\n\nThe description of CINNA says “Functions for computing, comparing and demonstrating top informative centrality measures within a network.” Most of the indices in the package are imported from other package, such as centiserve. In addition, there are:\n\nDangalchev closeness (dangalchev_closeness_centrality())\ngroup centrality (group_centrality())\nharmonic closeness (harmonic_centrality())\nlocal bridging centrality (local_bridging_centrality())\n\nThe function calculate_centralities() can be used to calculate all applicable indices to a network. The primary purpose of the package is to facilitate the choice of indices by visual and statistical tools. If you are interested in the details, see this tutorial and this vignette.\ninfluenceR and keyplayer are comparably small packages which implement only a small number of indices.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Centrality</span>"
    ]
  },
  {
    "objectID": "centrality-basic.html#thoughts",
    "href": "centrality-basic.html#thoughts",
    "title": "2  Centrality",
    "section": "2.5 Thoughts",
    "text": "2.5 Thoughts\nThe choice of indices can be overwhelming and little guidelines exist on when to choose what. The worst thing to do in any case is to apply a handful of indices and pick the result that suits your interpretation best. In best case, you have substantive arguments to apply an index and the result does match the hypothesis (or not).",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Centrality</span>"
    ]
  },
  {
    "objectID": "centrality-basic.html#use-case-florentine-families",
    "href": "centrality-basic.html#use-case-florentine-families",
    "title": "2  Centrality",
    "section": "2.6 Use case: Florentine Families",
    "text": "2.6 Use case: Florentine Families\nA classic example application of centrality indices is the “Florentine Families” dataset, which is included in the networkdata package.\n\ndata(\"flo_marriage\")\n\n\n\n\n\n\n\n\n\n\nTh network shows marriage ties among Renaissance Families in Florence. Marriages at that time were strategic to improve the standing of families in society. The size of the names is proportional to the wealth of the families. Although the Strozzi were the wealthiest family, it was ultimately the Medici who became the most powerful family. This is in part due to their central position within this marriage network.\nThe table bellow shows the ranking for the four most commonly used centrality indices (1=top rank).\n\n\n\n\n\nname\ndegree\nbetweenness\ncloseness\neigen\n\n\n\n\nAcciaiuoli\n13.5\n14\n11.5\n12\n\n\nAlbizzi\n6.5\n3\n3.5\n9\n\n\nBarbadori\n10.5\n8\n6.5\n10\n\n\nBischeri\n6.5\n6\n8.0\n6\n\n\nCastellani\n6.5\n10\n9.5\n8\n\n\nGinori\n13.5\n14\n13.0\n14\n\n\nGuadagni\n2.5\n2\n5.0\n5\n\n\nLamberteschi\n13.5\n14\n14.0\n13\n\n\nMedici\n1.0\n1\n1.0\n1\n\n\nPazzi\n13.5\n14\n15.0\n15\n\n\nPeruzzi\n6.5\n11\n11.5\n7\n\n\nPucci\n16.0\n14\n16.0\n16\n\n\nRidolfi\n6.5\n5\n2.0\n3\n\n\nSalviati\n10.5\n4\n9.5\n11\n\n\nStrozzi\n2.5\n7\n6.5\n2\n\n\nTornabuoni\n6.5\n9\n3.5\n4\n\n\n\n\n\nNo matter what structural feature we consider to be important, the Medici always have the most advantageous position.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Centrality</span>"
    ]
  },
  {
    "objectID": "centrality-advanced.html",
    "href": "centrality-advanced.html",
    "title": "3  Advanced Centrality Concepts",
    "section": "",
    "text": "3.1 Introduction\nWhen looking at the vast amount of centrality indices, it may be reasonable to ask if there is any natural limit for what can be considered a centrality index. Concretely, are there any theoretical properties that an index has to have in order to be called a centrality index? There exist several axiomatic systems for centrality, which define some desirable properties that a proper index should have. While these systems are able to shed some light on specific groups of indices, they are in most cases not comprehensive. That is, it is often possible to construct counterexamples for most indices such that they do not fulfill the properties. Instead of the rather normative axiomatic approach, we explore a more descriptive approach. We will address the following questions:",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "centrality-advanced.html#introduction",
    "href": "centrality-advanced.html#introduction",
    "title": "3  Advanced Centrality Concepts",
    "section": "",
    "text": "Are there any properties that are shared by all (or almost all) indices?\nIf so, can they be exploited for a different kind of centrality analysis?",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "centrality-advanced.html#neighborhood-inclusion",
    "href": "centrality-advanced.html#neighborhood-inclusion",
    "title": "3  Advanced Centrality Concepts",
    "section": "3.2 Neighborhood-inclusion",
    "text": "3.2 Neighborhood-inclusion\nLet us start by looking at the following two small examples.\n\ng1 &lt;- readRDS(\"data/example_1.rds\")\ng2 &lt;- readRDS(\"data/example_2.rds\")\n\n[PLOT]\n[APPLY INDICES]\nIt turns out that there actually is a very intuitive structural property that underlies many centrality indices. If a node has exactly the same neighbors as another and potentially some more, it will never be less central, independent of the choice of index. This property is called neighborhood-inclusion.\nAn illustration is given below. \nWe can calculate all pairs of neighborhood-inclusion with the function neighborhood_inclusion() in the netrankr package.\n\nP1 &lt;- neighborhood_inclusion(g1)\n\nThis graph was created by an old(er) igraph version.\n  Call upgrade_graph() on it to use with the current igraph version\n  For now we convert it on the fly...\n\nP2 &lt;- neighborhood_inclusion(g2)\n\nThis graph was created by an old(er) igraph version.\n  Call upgrade_graph() on it to use with the current igraph version\n  For now we convert it on the fly...\n\n\nAn entry P[i,j] is one if the neighborhood of i is included in the neighborhood of j and zero otherwise. With the function comparable_pairs(), we can check the fraction of comparable pairs. Let us start with the first network.\n\ncomparable_pairs(P1)\n\n[1] 0.163636\n\n\nOnly 16% of pairs are comparable with neighborhood-inclusion. For a better understanding of the dominance relations, we can also visualize them as a graph.\nd1 &lt;- dominance_graph(P1)\n\nAn edge (i,j) is present, if P[i,j]=1. Centrality indices will always put these comparable pairs in the same order.\n[ADD EXAMPLE WITH INDEX PRESERVATION]\nMoving on to the second network.\n\ncomparable_pairs(P2)\n\n[1] 1\n\n\nSo all pairs are comparable by neighborhood-inclusion. Hence, all indices will induce the same ranking (up to some potential tied ranks, but no discordant pairs), as we already observed in the previous post.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "centrality-advanced.html#threshold-graphs-and-correlation-among-indices",
    "href": "centrality-advanced.html#threshold-graphs-and-correlation-among-indices",
    "title": "3  Advanced Centrality Concepts",
    "section": "3.3 Threshold graphs and correlation among indices",
    "text": "3.3 Threshold graphs and correlation among indices\nThe second example network is part of the class of threshold graphs. One of their defining features is that the partial ranking induced by neighborhood-inclusion is in fact a ranking. A random threshold graph can be created with the threshold_graph() function. The function takes two parameters, one for the number of nodes, and one (approximately) for the density. The class includes some well known graphs, such as the two below.\n\ntg1 &lt;- threshold_graph(n = 10, p = 1)\ntg2 &lt;- threshold_graph(n = 10, p = 0)\n\n\nWe know from the previous section that centrality indices will always produce the same ranking on these graphs. This allows us to reason about another topic that is frequently investigated: correlations among indices. Correlations are often attributed to the definitions of indices. Take closeness and betweenness. On first glance, they measure very different things: Being close to all nodes and being “in between” all nodes. Hence, we would expect them to be only weakly correlated. But threshold graphs give us a reason to believe, that correlations are not entirely dependent on the definitions but rather on structural features of the network. (This article gives more details and references on that topic. Let me know if you can’t access it).\nAs an illustration, we compare betweenness and closeness on a threshold graph and a threshold graph with added noise from a random graph.\n\n#threshold graph\ntg3 &lt;- threshold_graph(100,0.2)\n#noise graph\ngnp &lt;- sample_gnp(100,0.01)\nA1 &lt;- as_adjacency_matrix(tg3, sparse = FALSE)\nA2 &lt;- as_adjacency_matrix(gnp, sparse = FALSE)\n\n#construct a noise threshold graph\ntg3_noise &lt;- graph_from_adjacency_matrix(xor(A1,A2),mode = \"undirected\")\n\n#calculate discordant pairs for betweenness and closeness in both networks\ndisc1 &lt;- compare_ranks(betweenness(tg3),closeness(tg3))$discordant\ndisc2 &lt;- compare_ranks(betweenness(tg3_noise),closeness(tg3_noise))$discordant\nc(disc1,disc2)\n\n[1]   0 465\n\n\nOn the threshold graph we do not observe any discordant pairs for the two indices. However, the little noise we added to the threshold graph was enough to introduce 465 pairs of nodes that are now ranked differently. In general, we can say that\nThe closer a network is to be a threshold graph, the higher we expect the correlation of any pair of centrality indices to be, independent of their definition.\nBut how to define being close to a threshold graph? One obvious choice is to use the function comparable_pairs(). The more pairs are comparable, the less possibilities for indices to rank the nodes differently. Hence, we are close to a unique ranking obtained for threshold graphs. A second option is to use an appropriate distance measure for graphs. netrankr implements the so called majorization gap which operates on the degree sequences of graphs. In its essence, it returns the number of edges that need to be rewired, in order to turn an arbitrary graph into a threshold graph.\n\nmg1 &lt;- majorization_gap(tg3)\nmg2 &lt;- majorization_gap(tg3_noise)\nc(mg1,mg2)\n\n[1] 0.0000000 0.0291829\n\n\nThe result is given as a fraction of the total number of edges. So 12% of edges need to be rewired in the noisy graph to turn it into a threshold graph. To get the raw count, set norm=FALSE.\n\nmajorization_gap(tg3_noise,norm = FALSE)\n\n[1] 30",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "centrality-advanced.html#partial-centrality",
    "href": "centrality-advanced.html#partial-centrality",
    "title": "3  Advanced Centrality Concepts",
    "section": "3.4 Partial Centrality",
    "text": "3.4 Partial Centrality\nThe function rank_intervals() is used to calculate the maximal and minimal possible rank for each node in any ranking that is in accordance with a given partial ranking.\n\ndata(\"dbces11\")\n\n#neighborhood inclusion \nP &lt;- neighborhood_inclusion(dbces11, sparse = FALSE)\n\nrank_intervals(P)\n\n node:A rank interval: [1, 6]\n node:B rank interval: [1, 9]\n node:C rank interval: [2, 9]\n node:D rank interval: [2, 11]\n node:E rank interval: [3, 11]\n node:F rank interval: [2, 11]\n node:G rank interval: [2, 11]\n node:H rank interval: [2, 11]\n node:I rank interval: [1, 11]\n node:J rank interval: [1, 11]\n node:K rank interval: [3, 11]\n\n\nThe package uses the convention, that higher numerical ranks correspond to top ranked position. The lowest possible rank is thus 1. The column mid_point should not be confused with the expected rank of nodes, which is calculated with the function exact_rank_prob().\n\nRank intervals are useful to assess the ambiguity of ranking nodes. The bigger the intervals are, the more freedom exists, e.g. for centrality indices, to rank nodes differently.\n\nThe intervals can be visualized with its own plot() function. The function can take a data frame of centrality scores as an additional parameter cent_scores. The ranks of each node for each index are then plotted within each interval. Again, the higher the numerical rank the higher ranked the node is according to the index.\n\ncent_scores &lt;- data.frame(\n   degree=degree(dbces11),\n   betweenness=round(betweenness(dbces11),4),\n   closeness=round(closeness(dbces11),4),\n   eigenvector=round(eigen_centrality(dbces11)$vector,4))\n\nrk_int &lt;- rank_intervals(P)\nplot(rk_int,cent_scores = cent_scores)\n\n\n\n\n\n\n\n\nA small jitter effect is added to the points to reduce over-plotting.\n\nNote that you may encounter situations, where ranks of centralities may fall outside of interval. This can happen in cases of ties in rankings, especially for betweenness centrality. Betweenness is, so far, the only index that does not strictly preserve neighborhood-inclusion. That is, while \\[\nN(u)\\subseteq N[v] \\text{ and } N(v)\\not\\subseteq N[u] \\implies c(u)&lt;c(v)\n\\] holds for most indices, betweenness fails to fulfill this property.\n\nThe intervals reduce to single points for threshold graphs, since all nodes are pairwise comparable by neighborhood-inclusion.\n\nset.seed(123)\ntg &lt;- threshold_graph(20,0.2)\n\n#neighborhood inclusion \nP &lt;- tg %&gt;% neighborhood_inclusion(sparse = FALSE)\n\n#without %&gt;% operator:\n# P &lt;- neighborhood_inclusion(tg,sparse = FALSE)\nplot(rank_intervals(P))\n\n\n\n\n\n\n\n\nThe described betweenness inconsistancy is most evident for threshold graphs as shown in the rank intervals below.\n\ncent_scores &lt;- data.frame(\n   degree=degree(tg),\n   betweenness=round(betweenness(tg),4),\n   closeness=round(closeness(tg),4),\n   eigenvector=round(eigen_centrality(tg)$vector,4))\n\n\nplot(rank_intervals(P),cent_scores = cent_scores)",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "centrality-advanced.html#exact-probabilities",
    "href": "centrality-advanced.html#exact-probabilities",
    "title": "3  Advanced Centrality Concepts",
    "section": "3.5 Exact Probabilities",
    "text": "3.5 Exact Probabilities\nBefore calculating any probabilities consider the following example graph and the rankings induced by various centrality indices, shown as rank intervals.\n[MORE TEXT]\nBut first, let us briefly look at all the return values.\n\nres &lt;- exact_rank_prob(P)\n\nWarning in exact_rank_prob(P): P is already a ranking.\nExpected Ranks correspond to the only possible ranking.\n\nres\n\nNumber of possible centrality rankings:  1 \nEquivalence Classes (max. possible): 8 (20)\n- - - - - - - - - - \nRank Probabilities (rows:nodes/cols:ranks)\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\nV1  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV2  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV3  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV4  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV5  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV6  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  1  0  0  0\nV7  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV8  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV9  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV10 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV11 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV12 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV13 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV14 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV15 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  1  0  0\nV16 0 0 1 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV17 0 0 1 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV18 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  1  0\nV19 1 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV20 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  1\n- - - - - - - - - - \nRelative Rank Probabilities (row ranked lower than col)\n    V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20\nV1   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV2   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV3   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV4   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV5   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV6   0  0  0  0  0  0  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV7   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV8   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV9   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV10  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV11  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV12  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV13  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV14  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV15  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   1   0   1\nV16  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   0   0   1   0   1\nV17  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   0   0   1   0   1\nV18  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   1\nV19  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   1   1   1   0   1\nV20  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0\n- - - - - - - - - - \nExpected Ranks (higher values are better)\n V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 \n 16  16  16  16  16  17  11  11  11  11  11  11  11  11  18   3   3  19   1  20 \n- - - - - - - - - - \nSD of Rank Probabilities\n V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 \n  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n- - - - - - - - - - \n\n\nThe function returns an object of type which contains the result of a full probabilistic rank analysis. The specific list entries are discussed in the following subsections.\n\n3.5.1 Rank Probabilities\nInstead of insisting on fixed ranks of nodes as given by indices, we can use rank probabilities to assess the likelihood of certain rank. Formally, rank probabilities are simply defined as \\[\nP(rk(u)=k)=\\frac{\\lvert \\{rk \\in  \\mathcal{R}(\\leq) \\; : \\; rk(u)=k\\} \\rvert}{\\lvert \\mathcal{R}(\\leq) \\rvert}.\n\\] Rank probabilities are given by the return value rank.prob of the exact_rank_prob() function.\n\nrp &lt;- round(res$rank.prob,2)\nrp\n\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\nV1  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV2  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV3  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV4  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV5  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV6  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  1  0  0  0\nV7  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV8  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV9  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV10 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV11 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV12 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV13 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV14 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV15 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  1  0  0\nV16 0 0 1 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV17 0 0 1 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV18 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  1  0\nV19 1 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV20 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  1\n\n\nEntries rp[u,k] correspond to \\(P(rk(u)=k)\\).\n\nThe most interesting probabilities are certainly \\(P(rk(u)=n)\\), that is how likely is it for a node to be the most central.\n\nrp[,11]\n\n V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 \n  0   0   0   0   0   0   1   1   1   1   1   1   1   1   0   0   0   0   0   0 \n\n\nRecall from the previous section that we found five indices that ranked \\(6,7,8,10\\) and \\(11\\) on top. The probability tell us now, how likely it is to find an index that rank these nodes on top. In this case, node \\(11\\) has the highest probability to be the most central node.\n\n\n3.5.2 Relative Rank Probabilities\nIn some cases, we might not necessarily be interested in a complete ranking of nodes, but only in the relative position of a subset of nodes. This idea leads to relative rank probabilities, that is formally defined as \\[\nP(rk(u)\\leq rk(v))=\\frac{\\lvert \\{rk \\in  \\mathcal{R}(\\leq) \\; : \\; rk(u)\\leq rk(v)\\} \\rvert}{\\lvert \\mathcal{R}(\\leq) \\rvert}.\n\\] Relative rank probabilities are given by the return value relative.rank of the exact_rank_prob() function.\n\nrrp &lt;- round(res$relative.rank,2)\nrrp\n\n    V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20\nV1   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV2   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV3   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV4   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV5   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV6   0  0  0  0  0  0  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV7   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV8   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV9   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV10  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV11  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV12  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV13  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV14  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV15  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   1   0   1\nV16  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   0   0   1   0   1\nV17  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   0   0   1   0   1\nV18  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   1\nV19  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   1   1   1   0   1\nV20  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0\n\n\nEntries rrp[u,v] correspond to \\(P(rk(u)\\leq rk(v))\\).\n\nThe more a value rrp[u,v] deviates from \\(0.5\\) towards \\(1\\), the more confidence we gain that a node \\(v\\) is more central than a node \\(u\\).\n###Expected Ranks The expected rank of a node in centrality rankings is defined as the expected value of the rank probability distribution. That is, \\[\n\\rho(u)=\\sum_{k=1}^n k\\cdot P(rk(u)=k).\n\\] Expected ranks are given by the return value expected.rank of the exact_rank_prob() function.\n\nex_rk &lt;- round(res$expected.rank,2)\nex_rk\n\n V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 \n 16  16  16  16  16  17  11  11  11  11  11  11  11  11  18   3   3  19   1  20 \n\n\nAs a reminder, the higher the numeric rank, the more central a node is. In this case, node \\(11\\) has the highest expected rank in any centrality ranking.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Advanced Centrality Concepts</span>"
    ]
  },
  {
    "objectID": "clustering.html",
    "href": "clustering.html",
    "title": "4  Cohesive Subgroups",
    "section": "",
    "text": "4.1 Introduction\nIn this chapter, we explore cohesive subgroups within networks, focusing on cliques, community detection, blockmodeling, and core-periphery structures. Each concept offers a different way to examine how nodes cluster based on connectivity, from tightly-knit cliques, where every member is connected, to broader communities grouped by denser internal links. Blockmodeling abstracts these patterns into roles and relationships, while core-periphery structures reveal hierarchical organization with central and peripheral actors.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cohesive Subgroups</span>"
    ]
  },
  {
    "objectID": "clustering.html#cliques",
    "href": "clustering.html#cliques",
    "title": "4  Cohesive Subgroups",
    "section": "4.2 Cliques",
    "text": "4.2 Cliques\nA clique in a network is a set of nodes that form a complete subnetwork within a network (called a complete subgraph). A maximal clique is a clique that cannot be extended to a bigger clique by addding more nodes to it.\n\ndata(\"clique_graph\")\n\nAll maximal cliques can be calculated with max_cliques() (only feasible for fairly small networks). The min parameter can be used to set a minimum size. Here, we want to ignore all cliques of size \\(2\\).\n\n# only return cliques with three or more nodes\ncl &lt;- max_cliques(clique_graph, min = 3)\ncl\n\n[[1]]\n+ 3/30 vertices, from 0193e05:\n[1]  9 17 18\n\n[[2]]\n+ 3/30 vertices, from 0193e05:\n[1] 7 4 5\n\n[[3]]\n+ 3/30 vertices, from 0193e05:\n[1] 7 4 8\n\n[[4]]\n+ 3/30 vertices, from 0193e05:\n[1] 10  2 11\n\n[[5]]\n+ 3/30 vertices, from 0193e05:\n[1] 16 12 15\n\n[[6]]\n+ 3/30 vertices, from 0193e05:\n[1] 6 1 5\n\n[[7]]\n+ 4/30 vertices, from 0193e05:\n[1] 12 13 15 14\n\n[[8]]\n+ 3/30 vertices, from 0193e05:\n[1] 12  2  1\n\n[[9]]\n+ 5/30 vertices, from 0193e05:\n[1] 1 2 5 4 3\n\n\nThe figure below shows the network and the found maximal cliques.\n\n\n\n\n\n\n\n\n\nRelated to cliques is the k-core decomposition of a network. A k-core is a subgraph in which every node has at least k neighbors within the subgraph. A k-core is thus a relaxed version of a clique.\nThe function coreness() can be used to calculate the k-core membership for each node.\n\nkcore &lt;- coreness(clique_graph)\nkcore\n\n [1] 4 4 4 4 4 3 2 2 2 2 2 3 3 3 3 3 2 2 1 1 1 1 1 1 1 1 1 1 1 1\n\n\n\n\n\n\n\n\n\n\n\nCliques are the prototypical and most strict definition of a cohesive subgroup in a network. In empirical networks, however, we rarely encounter situations where we can partition the whole network into a set of cliques. The relaxed version of this problem is that of clustering, also referred to as comunity detection.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cohesive Subgroups</span>"
    ]
  },
  {
    "objectID": "clustering.html#comunity-detection",
    "href": "clustering.html#comunity-detection",
    "title": "4  Cohesive Subgroups",
    "section": "4.3 Comunity detection",
    "text": "4.3 Comunity detection\nA cluster is loosely defined as a group of nodes which are internally densely and externally sparsely connected. The network below shows an example for a network with a visible and intuitive cluster structure.\n\n# labeL; clustered-graph\n#| echo: FALSE\n\nn1 &lt;- 5\nn2 &lt;- 20\nset.seed(1234)\ng &lt;- sample_islands(n1, n2, 0.9, 5)\ng &lt;- simplify(g)\nV(g)$grp &lt;- rep(LETTERS[1:n1], each = n2)\nggraph(g, \"stress\") +\n    geom_edge_link0(edge_linewidth = 0.2, edge_color = \"grey66\") +\n    geom_node_point(shape = 21, size = 5, aes(fill = grp), show.legend = FALSE) +\n    theme_void()\n\n\n\n\n\n\n\n\nIn contrast, the network below does not really seem to have any well defined cluster structure.\n\n\n\n\n\n\n\n\n\nThe following algorithms for graph clustering are implemented in igraph.\n\n\n [1] \"cluster_edge_betweenness\"  \"cluster_fast_greedy\"      \n [3] \"cluster_fluid_communities\" \"cluster_infomap\"          \n [5] \"cluster_label_prop\"        \"cluster_leading_eigen\"    \n [7] \"cluster_leiden\"            \"cluster_louvain\"          \n [9] \"cluster_optimal\"           \"cluster_spinglass\"        \n[11] \"cluster_walktrap\"         \n\n\nMost of these algorithms are based on “modularity maximization”. Modularity is defined as the fraction of edges that fall within given groups minus the expected fraction if edges were distributed at random.\nThe workflow of a cluster analysis is always the same, independent from the chosen method. We illustrate the workflow using the infamous karate club network.\n\ndata(\"karate\")\n\n\n\n\n\n\n\n\n\n\n\n# compute clustering\nclu &lt;- cluster_louvain(karate)\n\n# cluster membership vector\nmem &lt;- membership(clu)\nmem\n\n [1] 1 1 1 1 2 2 2 1 3 1 2 1 1 1 3 3 2 1 3 1 3 1 3 4 4 4 3 4 4 3 3 4 3 3\n\n# clusters as list\ncom &lt;- communities(clu)\ncom\n\n$`1`\n [1]  1  2  3  4  8 10 12 13 14 18 20 22\n\n$`2`\n[1]  5  6  7 11 17\n\n$`3`\n [1]  9 15 16 19 21 23 27 30 31 33 34\n\n$`4`\n[1] 24 25 26 28 29 32\n\n\nTo compare the quality of clusterings, we can compute the modularity score for each output.\n\nimc &lt;- cluster_infomap(karate)\nlec &lt;- cluster_leading_eigen(karate)\nloc &lt;- cluster_louvain(karate)\nsgc &lt;- cluster_spinglass(karate)\nwtc &lt;- cluster_walktrap(karate)\nscores &lt;- c(\n    infomap = modularity(karate, membership(imc)),\n    eigen = modularity(karate, membership(lec)),\n    louvain = modularity(karate, membership(loc)),\n    spinglass = modularity(karate, membership(sgc)),\n    walk = modularity(karate, membership(wtc))\n)\nscores\n\n  infomap     eigen   louvain spinglass      walk \n 0.402038  0.393409  0.419790  0.419790  0.353222 \n\n\nFor the karate network, cluster_spinglass() produces the highest modularity score. The corresponding clustering is shown below.\n\n\n\n\n\n\n\n\n\nModularity maximization is still widely considered as the state-of-the-art clustering method for networks. There are, however, some technical shortcomings that one should be aware of. One of those is the so called “resolution limit”. When modularity is being maximized, it can happen that smaller clusters are merged together to form bigger clusters. The prime example is the graph that consists of cliques connected in a ring.\nThe figure below shows such a graph, consisting of 50 cliques of size 5.\n\n\n\n\n\n\n\n\n\nIntuitively, any clustering method should return a cluster for each clique.\n\nclu_louvain &lt;- cluster_louvain(K50)\ntable(membership(clu_louvain))\n\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n15 10 10 10 10 15 15 10 10 15 10 10 10 15 10 10 10 10 15 10 10 10 \n\n\nA clustering algorithm that fixes this issue is the leiden algorithm.\n\nclu_leiden &lt;- cluster_leiden(K50, objective_function = \"CPM\", resolution_parameter = 0.5)\ntable(membership(clu_leiden))\n\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n 5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 \n27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n 5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 \n\n\nThe figure below shows the clusters computed with the louvain method in grey and the leiden method in red.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nDon't know how to automatically pick scale for object of type &lt;membership&gt;.\nDefaulting to continuous.\nDon't know how to automatically pick scale for object of type &lt;membership&gt;.\nDefaulting to continuous.\n\n\n\n\n\n\n\n\n\nIf you are interested in the technical details of the Leiden method, check out the original paper.\nThe netUtils package includes the function sample_lfr() which implements the well-known Lancichinetti–Fortunato–Radicchi benchmark algorithm to generate artificial networks with a priori known communities and they can be used to compare different community detection methods.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cohesive Subgroups</span>"
    ]
  },
  {
    "objectID": "clustering.html#blockmodeling",
    "href": "clustering.html#blockmodeling",
    "title": "4  Cohesive Subgroups",
    "section": "4.4 Blockmodeling",
    "text": "4.4 Blockmodeling\nBlockmodeling is a more formal approach that aims to simplify the network’s structure into blocks based on patterns of connections between nodes. Instead of focusing on the density of connections, it categorizes the relationships between different groups (or blocks) of nodes according to the roles they play in the network.\nThe goal is to reduce the complexity of the network by identifying roles and positions within the network, where nodes in the same block have similar patterns of connections to other blocks, rather than necessarily being densely connected to each other.\nBlockmodeling involves partitioning the network into blocks and then modeling the connections between these blocks. It can be done through conventional (deterministic) or stochastic approaches, including k-block modeling and stochastic blockmodeling.\nBlockmodeling is particularly useful in sociology for role analysis and in organizational studies, where it’s important to understand how different groups (e.g., departments, hierarchies) interact, regardless of the density of the connections within each group.\nThere are several packages that implement different kinds of (stochastic) blockmodels. The most basic approaches are implemented in the package blockmodeling.\n\nlibrary(blockmodeling)\n\nIn principle, blockmodels can also be used for clustering, as we will illustrate on this random network with 3 dense blocks of size 20.\n\n\n\n\n\n\n\n\n\nThe disadvantage is that we need to specify a lot more parameters than for community detection.\n\nA &lt;- as_adj(g)\nblk &lt;- matrix(\n    c(\n        \"com\", \"nul\", \"nul\",\n        \"nul\", \"com\", \"nul\",\n        \"nul\", \"nul\", \"com\"\n    ),\n    nrow = 3\n)\nblk\n\n     [,1]  [,2]  [,3] \n[1,] \"com\" \"nul\" \"nul\"\n[2,] \"nul\" \"com\" \"nul\"\n[3,] \"nul\" \"nul\" \"com\"\n\nres &lt;- optRandomParC(\n    M = A, k = 3, approaches = \"bin\",\n    blocks = blk, rep = 5, mingr = 20, maxgr = 20\n)\n\n\n\nStarting optimization of the partiton 1 of 5 partitions.\nStarting partition: 1 1 1 2 2 3 1 1 1 2 3 1 2 1 2 1 1 3 1 3 3 1 2 1 2 3 3 1 3 2 3 3 1 2 1 2 2 3 1 3 2 3 2 3 2 2 1 3 3 2 2 3 2 1 3 3 2 2 3 1 \nFinal error: 364 \nFinal partition:    1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 \n\n\nStarting optimization of the partiton 2 of 5 partitions.\nStarting partition: 2 1 3 3 2 1 3 2 2 1 2 3 3 2 1 1 1 1 3 2 1 3 3 2 1 1 3 1 1 1 1 1 2 1 2 3 1 3 2 1 2 3 3 3 2 2 2 1 2 3 3 2 3 1 2 3 2 2 3 3 \nFinal error: 364 \nFinal partition:    2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 \n\n\nStarting optimization of the partiton 3 of 5 partitions.\nStarting partition: 1 3 1 2 3 2 3 2 3 1 2 3 1 3 1 1 3 3 1 2 1 2 1 3 2 2 2 3 1 2 2 3 2 1 2 3 3 2 1 3 2 1 1 1 2 1 2 1 3 2 1 2 3 2 3 3 1 1 3 3 \nFinal error: 364 \nFinal partition:    2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 \n\n\nStarting optimization of the partiton 4 of 5 partitions.\nStarting partition: 2 3 3 1 1 1 3 1 2 1 1 1 1 3 2 1 1 2 3 2 1 2 1 3 1 2 1 2 2 1 3 2 1 2 2 2 1 2 3 2 3 3 1 3 3 1 3 2 2 3 3 2 3 3 3 3 2 3 1 2 \nFinal error: 364 \nFinal partition:    1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 \n\n\nStarting optimization of the partiton 5 of 5 partitions.\nStarting partition: 3 1 3 3 1 1 2 2 2 2 1 3 1 2 1 2 3 3 1 3 3 1 3 1 1 1 1 3 3 2 2 2 2 3 2 3 3 3 3 2 1 2 3 1 1 2 2 1 2 1 1 2 1 2 2 2 3 1 3 3 \nFinal error: 364 \nFinal partition:    1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 \n\n\nOptimization of all partitions completed\nAll 5 solutions have err 364 \n\n\n\nk: number of blocks needs to be specified beforehand\napproaches: defines the type of blockmodel approach to be used. “bin” is for binary and “val” for valued blockmodeling. There are several more possibilities available in the help of the function\nblocks: allowed block types. Basically, what defines a block in the network. In our example we give a strict patterning that corresponds to a clustering. The diagonal blocks should be complete (“com”) and offdiagonals should be empty (“nul”). So in the best case, we have 3 disconnected cliques. Again, consult the help for more available block options.\nrep: number of random starting partitions to start the iteration from\nmingr and maxgr: min and max size of the blocks.\n\nthe result can be accessed with clu.\n\nclu(res)\n\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[39] 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n\n\nNote that this type of Blockmodeling is computationally expensive and best suited for small networks.\nLooking at a more realistic dataset, we load the baker dataset from the blockmodeling package. The dataset includes citation data between social work journals for 1985-86.\n\ndata(\"baker\")\ndiag(baker) &lt;- 0\n\nplotMat(baker,\n    main = \"Baker Network Data\",\n    mar = c(1, 1, 3, 1), title.line = 2\n)\n\n\n\n\n\n\n\n\nFirst, we run a binary blockmodel. This time we increase the number of repetions to 1000 and instead of giving a lear block structure, we just specify, what type of blocks we want our result to include. How they are distributed, we do not care and let the algorithm decide. We run the optimization in parallel (nCores = 0), which requires the packages doParallel and doRNG to be installed.\n\nbaker_binary &lt;- baker\nbaker_binary[baker_binary &gt; 0] &lt;- 1\n\nres_baker_binary &lt;- optRandomParC(\n    M = baker_binary, k = 3, rep = 1000,\n    nCores = 0, blocks = c(\"nul\", \"com\"), approach = \"bin\"\n)\n\nLoading required namespace: doParallel\n\n\nLoading required namespace: doRNG\n\n\n\n\nOptimization of all partitions completed\n1 solution(s) with minimal error = 47 found. \n\n\nThe obtained optimal block structure can be accessed via IM.\n\nIM(res_baker_binary)\n\n     [,1]  [,2]  [,3] \n[1,] \"com\" \"com\" \"nul\"\n[2,] \"com\" \"com\" \"nul\"\n[3,] \"nul\" \"com\" \"nul\"\n\n\nThe resulting blocks can be visualized via the plot function.\n\nplot(\n    res_baker_binary,\n    main = \"Baker Binary Network Data\",\n    mar = c(1, 2, 3, 1), title.line = 2\n)\n\n\n\n\n\n\n\n\nNow we run a valued blockmodel on the original data. The parameter preSpecM is set to the median of the non-zero entries and defines a kind of cutoff for when to consider a value high enough to be a block internal tie.\n\nres_baker_valued &lt;- optRandomParC(\n    M = baker, k = 3, rep = 1000,\n    preSpecM = 13, approach = \"val\", blocks = c(\"nul\", \"com\"),\n    nCores = 0\n)\n\n\n\nOptimization of all partitions completed\n1 solution(s) with minimal error = 626 found. \n\n\n\nIM(res_baker_valued)\n\n     [,1]  [,2]  [,3] \n[1,] \"com\" \"com\" \"nul\"\n[2,] \"com\" \"nul\" \"nul\"\n[3,] \"nul\" \"nul\" \"nul\"\n\n\n\nplot(\n    res_baker_valued,\n    main = \"Baker Valued Network Data\",\n    mar = c(1, 2, 3, 1), title.line = 2\n)",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cohesive Subgroups</span>"
    ]
  },
  {
    "objectID": "clustering.html#core-periphery",
    "href": "clustering.html#core-periphery",
    "title": "4  Cohesive Subgroups",
    "section": "4.5 Core-Periphery",
    "text": "4.5 Core-Periphery\nCommunity detection aims to find clusters or groups of nodes within the network that are more densely connected to each other than to nodes outside the group. The core-periphery structure, in contrast, posits that a network is organized into a densely connected core and a sparsely connected periphery. The core consists of central nodes that are highly connected to each other and also to peripheral nodes. Peripheral nodes, on the other hand, have fewer connections and are mostly connected to nodes in the core rather than to each other.\nthe netutils package includes a function core_periphery() which allows to fit a discrete core-periphery model to a network.\n\nlibrary(netUtils)\n\nTo illustrate the function, we construct a graph which has a perfect core-periphery structure, also known as a split graph.\n\nset.seed(1234)\nsg &lt;- split_graph(n = 50, p = 0.35, core = 0.3)\n\nThe created graph has 50 nodes and 30% of all nodes are in the core. The probability that a periphery node connects to a core node is 0.35.\n\n\n\n\n\n\n\n\n\nRunning the core_periphery() function on this idealized graph should give the optimal result.\n\ncore_periphery(sg)\n\n$vec\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 0 0 0 0 0 0 0\n\n$corr\n[1] 1\n\n\nThe function returns a list with two entries. The first, vec, returns the membership of nodes. It is one if a node is in the core and 0 if not. The second entry corr is the correlation of the adjacency matrix with the ideal adjacency matrix given from the vec memberships. In this case, the correlation is one meaning that we have discovered the perfect core-periphery structure. In empirical applications, we rarely expect such a good fit.\nThe function also has an argument which allows to use different optimization techniques to find core-periphery structures (the problem of finding the optimal solution is too complex). For illustration, we rewire some edges of the graph sg to destroy the idealized structure and use all implemented optimization methods.\n\nset.seed(45)\nsg1 &lt;- rewire(sg, each_edge(0.25))\ncore_periphery(sg1, method = \"rk1_dc\")\n\n$vec\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 0 0 0 0 0 0 0\n\n$corr\n[1] 0.516635\n\ncore_periphery(sg1, method = \"rk1_ec\")\n\n$vec\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 1 0 0 0 0 0 0\n\n$corr\n[1] 0.515428\n\ncore_periphery(sg1, method = \"GA\")\n\n$vec\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 1 0 0 0 0 0 0\n\n$corr\n[1] 0.519357\n\n\nrk1_dc and rk1_ec are so called rank-one matix approximation methods which infer an idealized structure via the degrees and eigenvectors of the adjacency matrix. These methods are extremely fast but might result in a lower quality of the result compared to GA which runs a genetic algorithm.\nThere are several extensions to this simple discrete core-periphery model. An extension for weighted networks is implemented in the package ITNr.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cohesive Subgroups</span>"
    ]
  },
  {
    "objectID": "clustering.html#scientific-reading",
    "href": "clustering.html#scientific-reading",
    "title": "4  Cohesive Subgroups",
    "section": "4.6 Scientific Reading",
    "text": "4.6 Scientific Reading\nVincent D. Blondel, Jean-Loup Guillaume, Renaud Lambiotte, Etienne Lefebvre: Fast unfolding of communities in large networks. J. Stat. Mech. (2008) P10008\nTraag, V. A., Waltman, L., & van Eck, N. J. (2019). From Louvain to Leiden: guaranteeing well-connected communities. Scientific reports, 9(1), 5233.\nŽiberna, A. (2007). Generalized Blockmodeling of Valued Networks. Social Networks, 29(1), 105-126. doi: 10.1016/j.socnet.2006.04.002\nŽiberna, A. (2008). Direct and indirect approaches to blockmodeling of valued networks in terms of regular equivalence. Journal of Mathematical Sociology, 32(1), 57-84. doi: 10.1080/00222500701790207\nŽiberna, A. (2014). Blockmodeling of multilevel networks. Social Networks, 39(1), 46-61. doi: 10.1016/j.socnet.2014.04.002\nBorgatti, Stephen P., and Martin G. Everett. “Models of core/periphery structures.” Social networks 21.4 (2000): 375-395.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Cohesive Subgroups</span>"
    ]
  },
  {
    "objectID": "two-mode-networks.html",
    "href": "two-mode-networks.html",
    "title": "5  Two-Mode Networks",
    "section": "",
    "text": "5.1 Introduction\nA two-mode network is a network that consists of two disjoint sets of nodes (like people and events). Ties connect the two sets, for example participation of people in events. Other examples are\nThere are two ways of analysing a two-mode network. Either directly by using methods specifically created for such networks, or by projecting it to a regular one-mode network. The advantage of the former is that there is no information loss and the advantage of the latter is that we are working with more familiar data structures. The projection approach is more popular these days, but we will still introduce some direct methods to analyse two-mode networks. The main part of this chapter will however deal with the projection approach.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Two-Mode Networks</span>"
    ]
  },
  {
    "objectID": "two-mode-networks.html#introduction",
    "href": "two-mode-networks.html#introduction",
    "title": "5  Two-Mode Networks",
    "section": "",
    "text": "Affiliation networks (Membership in institutions/clubs)\nVoting/Sponsorship networks (politicians and bills)\nCitation network (authors and papers)\nCo-Authorship networks (also authors and papers)",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Two-Mode Networks</span>"
    ]
  },
  {
    "objectID": "two-mode-networks.html#two-mode-data-structure",
    "href": "two-mode-networks.html#two-mode-data-structure",
    "title": "5  Two-Mode Networks",
    "section": "5.2 Two-mode data structure",
    "text": "5.2 Two-mode data structure\nWe will discuss some methods tailored for two-mode networks via the famous “southern women” dataset consisting of 18 women who attended a series of 14 events. The network is included in the networkdata package.\n\ndata(\"southern_women\")\nsouthern_women\n\nIGRAPH 1074643 UN-B 32 89 -- \n+ attr: type (v/l), name (v/c)\n+ edges from 1074643 (vertex names):\n [1] EVELYN   --6/27 EVELYN   --3/2  EVELYN   --4/12 EVELYN   --9/26\n [5] EVELYN   --2/25 EVELYN   --5/19 EVELYN   --9/16 EVELYN   --4/8 \n [9] LAURA    --6/27 LAURA    --3/2  LAURA    --4/12 LAURA    --2/25\n[13] LAURA    --5/19 LAURA    --3/15 LAURA    --9/16 THERESA  --3/2 \n[17] THERESA  --4/12 THERESA  --9/26 THERESA  --2/25 THERESA  --5/19\n[21] THERESA  --3/15 THERESA  --9/16 THERESA  --4/8  BRENDA   --6/27\n[25] BRENDA   --4/12 BRENDA   --9/26 BRENDA   --2/25 BRENDA   --5/19\n[29] BRENDA   --3/15 BRENDA   --9/16 CHARLOTTE--4/12 CHARLOTTE--9/26\n+ ... omitted several edges\n\n\nigraph interprets a network as a two-mode network if it has a logical node attribute called type.\n\ntable(V(southern_women)$type)\n\n\nFALSE  TRUE \n   18    14 \n\n\n\n\n\n\n\n\n\n\n\nThe adjacency matrix of a two-mode network is referred to as biadjacency matrix and can be obtained via as_biadjacency_matrix().\n\nA &lt;- as_biadjacency_matrix(southern_women)\nA\n\n          6/27 3/2 4/12 9/26 2/25 5/19 3/15 9/16 4/8 6/10 2/23 4/7 11/21 8/3\nEVELYN       1   1    1    1    1    1    0    1   1    0    0   0     0   0\nLAURA        1   1    1    0    1    1    1    1   0    0    0   0     0   0\nTHERESA      0   1    1    1    1    1    1    1   1    0    0   0     0   0\nBRENDA       1   0    1    1    1    1    1    1   0    0    0   0     0   0\nCHARLOTTE    0   0    1    1    1    0    1    0   0    0    0   0     0   0\nFRANCES      0   0    1    0    1    1    0    1   0    0    0   0     0   0\nELEANOR      0   0    0    0    1    1    1    1   0    0    0   0     0   0\nPEARL        0   0    0    0    0    1    0    1   1    0    0   0     0   0\nRUTH         0   0    0    0    1    0    1    1   1    0    0   0     0   0\nVERNE        0   0    0    0    0    0    1    1   1    0    0   1     0   0\nMYRNA        0   0    0    0    0    0    0    1   1    1    0   1     0   0\nKATHERINE    0   0    0    0    0    0    0    1   1    1    0   1     1   1\nSYLVIA       0   0    0    0    0    0    1    1   1    1    0   1     1   1\nNORA         0   0    0    0    0    1    1    0   1    1    1   1     1   1\nHELEN        0   0    0    0    0    0    1    1   0    1    1   1     0   0\nDOROTHY      0   0    0    0    0    0    0    1   1    0    0   0     0   0\nOLIVIA       0   0    0    0    0    0    0    0   1    0    1   0     0   0\nFLORA        0   0    0    0    0    0    0    0   1    0    1   0     0   0",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Two-Mode Networks</span>"
    ]
  },
  {
    "objectID": "two-mode-networks.html#direct-approach",
    "href": "two-mode-networks.html#direct-approach",
    "title": "5  Two-Mode Networks",
    "section": "5.3 Direct Approach",
    "text": "5.3 Direct Approach\nThe tnet and bipartite packages offer some methods to analyse two mode networks directly, by adapting tools for standard (one-mode) networks, like the methods described in previous sections.\n\nlibrary(tnet)\n\ntnet implements a version of the clustering coefficient for two-mode networks. Remember that its one-mode equivalent is based on triangle counts, a structure that cannot exist in two-mode networks (think about it for a second).\n\ntransitivity(southern_women)\n\n[1] 0\n\ntransitivity(southern_women, type = \"local\")\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n\nThe version implemented in tnet is based on cycles of length 6, which involves three nodes of each mode.\n\nel_women &lt;- as_edgelist(southern_women, names = FALSE)\n\nclustering_tm(el_women)\n\n[1] 0.771897\n\n# coefficient for first mode\nclustering_local_tm(el_women)\n\n   node       lc\n1     1 0.766667\n2     2 0.842175\n3     3 0.752344\n4     4 0.838791\n5     5 1.000000\n6     6 0.869048\n7     7 0.795918\n8     8 0.646259\n9     9 0.670251\n10   10 0.674089\n11   11 0.713881\n12   12 0.769556\n13   13 0.746193\n14   14 0.837950\n15   15 0.815920\n16   16 0.540741\n17   17 0.580645\n18   18 0.580645\n\n# coefficient for second mode\nclustering_local_tm(el_women[, 2:1])\n\n   node       lc\n1     1      NaN\n2     2      NaN\n3     3      NaN\n4     4      NaN\n5     5      NaN\n6     6      NaN\n7     7      NaN\n8     8      NaN\n9     9      NaN\n10   10      NaN\n11   11      NaN\n12   12      NaN\n13   13      NaN\n14   14      NaN\n15   15      NaN\n16   16      NaN\n17   17      NaN\n18   18      NaN\n19   19 1.000000\n20   20 0.948718\n21   21 0.953297\n22   22 0.964497\n23   23 0.962825\n24   24 0.813559\n25   25 0.717182\n26   26 0.779158\n27   27 0.735363\n28   28 0.854460\n29   29 0.955556\n30   30 0.884477\n31   31 0.870968\n32   32 0.870968\n\n\nNote that it is very cumbersome to count these cycles. It is advisable to run this function only on fairly small networks.\nThe package does include some more two-mode specific functions (look for *_tm()), but the outcomes are equivalent to using its counterpart in igraph.\nThe bipartite package is tailored towards ecological network analysis. Relevant functions for standard two-mode networks are the same as in tnet.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Two-Mode Networks</span>"
    ]
  },
  {
    "objectID": "two-mode-networks.html#projection-approach",
    "href": "two-mode-networks.html#projection-approach",
    "title": "5  Two-Mode Networks",
    "section": "5.4 Projection Approach",
    "text": "5.4 Projection Approach\n\n5.4.1 Weighted Projection\nBesides analyzing a two-mode network as-is, there is also the possibility to project it to one mode. Mathematically, this is done by calculating \\(AA^T\\) or \\(A^TA\\), depending which mode we project on. As an example, consider the southern women dataset again.\n\nB &lt;- A %*% t(A)\nB\n\n          EVELYN LAURA THERESA BRENDA CHARLOTTE FRANCES ELEANOR PEARL RUTH\nEVELYN         8     6       7      6         3       4       3     3    3\nLAURA          6     7       6      6         3       4       4     2    3\nTHERESA        7     6       8      6         4       4       4     3    4\nBRENDA         6     6       6      7         4       4       4     2    3\nCHARLOTTE      3     3       4      4         4       2       2     0    2\nFRANCES        4     4       4      4         2       4       3     2    2\nELEANOR        3     4       4      4         2       3       4     2    3\nPEARL          3     2       3      2         0       2       2     3    2\nRUTH           3     3       4      3         2       2       3     2    4\nVERNE          2     2       3      2         1       1       2     2    3\nMYRNA          2     1       2      1         0       1       1     2    2\nKATHERINE      2     1       2      1         0       1       1     2    2\nSYLVIA         2     2       3      2         1       1       2     2    3\nNORA           2     2       3      2         1       1       2     2    2\nHELEN          1     2       2      2         1       1       2     1    2\nDOROTHY        2     1       2      1         0       1       1     2    2\nOLIVIA         1     0       1      0         0       0       0     1    1\nFLORA          1     0       1      0         0       0       0     1    1\n          VERNE MYRNA KATHERINE SYLVIA NORA HELEN DOROTHY OLIVIA FLORA\nEVELYN        2     2         2      2    2     1       2      1     1\nLAURA         2     1         1      2    2     2       1      0     0\nTHERESA       3     2         2      3    3     2       2      1     1\nBRENDA        2     1         1      2    2     2       1      0     0\nCHARLOTTE     1     0         0      1    1     1       0      0     0\nFRANCES       1     1         1      1    1     1       1      0     0\nELEANOR       2     1         1      2    2     2       1      0     0\nPEARL         2     2         2      2    2     1       2      1     1\nRUTH          3     2         2      3    2     2       2      1     1\nVERNE         4     3         3      4    3     3       2      1     1\nMYRNA         3     4         4      4    3     3       2      1     1\nKATHERINE     3     4         6      6    5     3       2      1     1\nSYLVIA        4     4         6      7    6     4       2      1     1\nNORA          3     3         5      6    8     4       1      2     2\nHELEN         3     3         3      4    4     5       1      1     1\nDOROTHY       2     2         2      2    1     1       2      1     1\nOLIVIA        1     1         1      1    2     1       1      2     2\nFLORA         1     1         1      1    2     1       1      2     2\n\n\nThis matrix can now be interpreted as a weighted network among the 18 women. Each entry corresponds to the number of times two women went to the same event.\nThe same can be achieved with the function bipartite_projection(), which returns both projections.\n\nprojs &lt;- bipartite_projection(southern_women)\nprojs\n\n$proj1\nIGRAPH 2a712ab UNW- 18 139 -- \n+ attr: name (v/c), weight (e/n)\n+ edges from 2a712ab (vertex names):\n [1] EVELYN --LAURA     EVELYN --BRENDA    EVELYN --THERESA   EVELYN --CHARLOTTE\n [5] EVELYN --FRANCES   EVELYN --ELEANOR   EVELYN --RUTH      EVELYN --PEARL    \n [9] EVELYN --NORA      EVELYN --VERNE     EVELYN --MYRNA     EVELYN --KATHERINE\n[13] EVELYN --SYLVIA    EVELYN --HELEN     EVELYN --DOROTHY   EVELYN --OLIVIA   \n[17] EVELYN --FLORA     LAURA  --BRENDA    LAURA  --THERESA   LAURA  --CHARLOTTE\n[21] LAURA  --FRANCES   LAURA  --ELEANOR   LAURA  --RUTH      LAURA  --PEARL    \n[25] LAURA  --NORA      LAURA  --VERNE     LAURA  --SYLVIA    LAURA  --HELEN    \n[29] LAURA  --MYRNA     LAURA  --KATHERINE LAURA  --DOROTHY   THERESA--BRENDA   \n+ ... omitted several edges\n\n$proj2\nIGRAPH 8c38084 UNW- 14 66 -- \n+ attr: name (v/c), weight (e/n)\n+ edges from 8c38084 (vertex names):\n [1] 6/27--3/2   6/27--4/12  6/27--9/26  6/27--2/25  6/27--5/19  6/27--9/16 \n [7] 6/27--4/8   6/27--3/15  3/2 --4/12  3/2 --9/26  3/2 --2/25  3/2 --5/19 \n[13] 3/2 --9/16  3/2 --4/8   3/2 --3/15  4/12--9/26  4/12--2/25  4/12--5/19 \n[19] 4/12--9/16  4/12--4/8   4/12--3/15  9/26--2/25  9/26--5/19  9/26--9/16 \n[25] 9/26--4/8   9/26--3/15  2/25--5/19  2/25--9/16  2/25--4/8   2/25--3/15 \n[31] 5/19--9/16  5/19--4/8   5/19--3/15  5/19--6/10  5/19--2/23  5/19--4/7  \n[37] 5/19--11/21 5/19--8/3   3/15--9/16  3/15--4/8   3/15--4/7   3/15--6/10 \n[43] 3/15--11/21 3/15--8/3   3/15--2/23  9/16--4/8   9/16--4/7   9/16--6/10 \n+ ... omitted several edges\n\n\n\n\n\n\n\n\n\n\n\nAs you can see, the network is weighted and very dense. In principle it is possible to analyze the network as is, but a very common step is to binarize the network. In doing so, we basically turn the network into a simple undirected one-mode network. This makes all methods we described in the first few sections applicable to the network (at least in theory).\n\n\n5.4.2 Simple Binary Projections\nThe simplest way of binarizing a weighted projection is to define a global threshold and remove a tie if its weight is below the global threshold. A popular choice is to take the mean edge weight (sometimes also plus the 1-2 times the standard deviation).\n\nwomen_proj &lt;- projs$proj1\nthreshold &lt;- mean(E(projs$proj1)$weight)\nwomen_bin &lt;- delete_edges(women_proj, which(E(women_proj)$weight &lt;= threshold))\nwomen_bin &lt;- delete_edge_attr(women_bin, \"weight\")\nwomen_bin\n\nIGRAPH 989d041 UN-- 18 46 -- \n+ attr: name (v/c)\n+ edges from 989d041 (vertex names):\n [1] EVELYN --LAURA     EVELYN --BRENDA    EVELYN --THERESA   EVELYN --CHARLOTTE\n [5] EVELYN --FRANCES   EVELYN --ELEANOR   EVELYN --RUTH      EVELYN --PEARL    \n [9] LAURA  --BRENDA    LAURA  --THERESA   LAURA  --CHARLOTTE LAURA  --FRANCES  \n[13] LAURA  --ELEANOR   LAURA  --RUTH      THERESA--BRENDA    THERESA--CHARLOTTE\n[17] THERESA--FRANCES   THERESA--ELEANOR   THERESA--RUTH      THERESA--PEARL    \n[21] THERESA--NORA      THERESA--VERNE     THERESA--SYLVIA    BRENDA --CHARLOTTE\n[25] BRENDA --FRANCES   BRENDA --ELEANOR   BRENDA --RUTH      FRANCES--ELEANOR  \n[29] ELEANOR--RUTH      RUTH   --VERNE     RUTH   --SYLVIA    VERNE  --SYLVIA   \n+ ... omitted several edges\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.4.3 Model-based Binary Projections\nThe global threshold method is very simple but in many cases leads to undesirable structural features. More sophisticated tools work with statistical models in the background which determine if an edge weight differs enough from the expected value of an underlying null model. If so, the edge is kept in the binary projection. Many of such models are implemented in the backbone package.\n\nlibrary(backbone)\n\nThe idea behind all of the models is always the same:\n\nCreate the weighted projection of interest, e.g. B &lt;- A%*%t(A)\nGenerate random two-mode networks according to a given model.\nCompare if the values B[i,j] differ significantly from the distribution of values in the random projections.\n\nThe only difference in all models is the construction of the random two-mode networks which follow different rules:\n\nFixed Degree Sequence Model fdsm(): Create random two-mode networks with the same row and column sums as A.\nFixed Column Model fixedcol(): Create random two-mode networks with the same column sums as A.\nFixed Row Model fixedrow(): Create random two-mode networks with the same row sums as A.\nFixed Fill Model fixedfill(): Create random two-mode networks with the same number of ones as A.\nStochastic Degree Sequence Model sdsm(): Create random two-mode networks with approximately the same row and column sums as A.\n\nBefore we move to an actual use case, you may ask: So which model is the right one for me? That is actually quite a tricky question. There is some guidance available but in general you can follow these rough guidelines:\n\nUse the model that fits you empirical setting or a known link formation process. If that link formation process dictates that row sums are fixed but column sums not, then choose fixedow().\nUse fdsm() if your network is small enough. Sampling from the FDSM is quite expensive.\nUse the sdsm() for large networks.\n\nGiven that there is never a “ground-truth” binary projection, any choice of model is fine as long as it is motivated substantively and not merely because it fits the papers narrative best.\nTo illustrate the model fitting, we use a bill cosponsorship of the Senate 2015. A link between a senator and a bill exists, if they sponsored it. We are no interested in how the binary projection of Senators looks like.\n\ndata(\"cosponsor\")\ncosponsor\n\nIGRAPH 6eddec8 UN-B 3984 26392 -- \n+ attr: name (v/c), type (v/l), party (v/c)\n+ edges from 6eddec8 (vertex names):\n [1] 115s1   --Enzi, Michael B.    115s10  --Cardin, Benjamin L.\n [3] 115s10  --Wicker, Roger F.    115s100 --Alexander, Lamar   \n [5] 115s1000--Franken, Al         115s1000--Murray, Patty      \n [7] 115s1000--Brown, Sherrod      115s1000--Warren, Elizabeth  \n [9] 115s1000--Markey, Edward J.   115s1001--Crapo, Mike        \n[11] 115s1001--Blumenthal, Richard 115s1001--Murphy, Christopher\n[13] 115s1001--Cassidy, Bill       115s1001--Alexander, Lamar   \n[15] 115s1001--Bennet, Michael F.  115s1002--Moran, Jerry       \n+ ... omitted several edges\n\n\nGiven that the network is fairly large, we will use the SDSM. Note that all models create the projection for the mode where type == FALSE. If you want to project on the TRUE mode, you need to invert the type attribute.\n\nsenators &lt;- sdsm(cosponsor, alpha = 0.05, signed = FALSE)\nsenators\n\nIGRAPH ef65957 UNW- 110 1591 -- \n+ attr: name (v/c), party (v/c), weight (e/n), sign (e/n)\n+ edges from ef65957 (vertex names):\n [1] Enzi, Michael B.--Wicker, Roger F. Enzi, Michael B.--Alexander, Lamar\n [3] Enzi, Michael B.--Crapo, Mike      Enzi, Michael B.--Moran, Jerry    \n [5] Enzi, Michael B.--Scott, Tim       Enzi, Michael B.--Daines, Steve   \n [7] Enzi, Michael B.--Perdue, David    Enzi, Michael B.--Blunt, Roy      \n [9] Enzi, Michael B.--Inhofe, James M. Enzi, Michael B.--Barrasso, John  \n[11] Enzi, Michael B.--Fischer, Deb     Enzi, Michael B.--Ernst, Joni     \n[13] Enzi, Michael B.--Rounds, Mike     Enzi, Michael B.--Kennedy, John   \n[15] Enzi, Michael B.--Flake, Jeff      Enzi, Michael B.--Hoeven, John    \n+ ... omitted several edges\n\n\nFor signed = FALSE, a one-tailed test is performed for each edge with a non-zero weight. It yields a projection that preserves edges whose weights are significantly stronger than expected in the null model.\nWhen signed = TRUE, a two-tailed test is performed for every pair of nodes. It yields a backbone that contains positive edges for edges whose weights are significantly stronger, and negative edges for edges whose weights are significantly weaker, than expected in the chosen null model. The projections thus becomes a signed network (see Chapter 6).\nThe figure below shows the not so surprising result that Democrats and Republicans do not tend to significantly cosponsor the same bills.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Two-Mode Networks</span>"
    ]
  },
  {
    "objectID": "two-mode-networks.html#notable-packages",
    "href": "two-mode-networks.html#notable-packages",
    "title": "5  Two-Mode Networks",
    "section": "5.5 Notable Packages",
    "text": "5.5 Notable Packages\n\nincidentally to create random two-mode networks with given structural features",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Two-Mode Networks</span>"
    ]
  },
  {
    "objectID": "two-mode-networks.html#scientific-reading",
    "href": "two-mode-networks.html#scientific-reading",
    "title": "5  Two-Mode Networks",
    "section": "5.6 Scientific Reading",
    "text": "5.6 Scientific Reading\nFaust, K. (1997). Centrality in affiliation networks. Social networks, 19(2), 157-191.\nEverett, M. G., & Borgatti, S. P. (2013). The dual-projection approach for two-mode networks. Social networks, 35(2), 204-210.\nOpsahl, T. (2013). Triadic closure in two-mode networks: Redefining the global and local clustering coefficients. Social networks, 35(2), 159-167.\nNeal, Z. P. (2014). The backbone of bipartite projections: Inferring relationships from co-authorship, co-sponsorship, co-attendance, and other co-behaviors. Social Networks, 39, 84-97.\nNeal, Z. P., Domagalski, R., and Sagan, B. (2021). Comparing Alternatives to the Fixed Degree Sequence Model for Extracting the Backbone of Bipartite Projections. Scientific Reports, 11, 23929.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Two-Mode Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html",
    "href": "signed-networks.html",
    "title": "6  Signed Networks",
    "section": "",
    "text": "6.1 Introduction\nTraditional SNA usually deals with relations among entities (e.g. people) that are positive, including “friendship”, “advice seeking”, etc. Most network analytic tools are devised under this premise, be that centrality indices, clustering tools and so forth. But of course not all occurring relations are positive. People can be friends but also foes.\nThis gives rise to signed networks. These networks are usually composed of both, positive and negative, ties measured among a set of entities. Traditional network analytic tools are not applicable to such networks without adapting for negative ties.\nThe signnet package brings together methods that have been developed to analyse signed networks. This includes",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html#introduction",
    "href": "signed-networks.html#introduction",
    "title": "6  Signed Networks",
    "section": "",
    "text": "Structural balance\nBlockmodeling\nCentrality\nSigned two-mode networks",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html#data-structures-for-signed-networks",
    "href": "signed-networks.html#data-structures-for-signed-networks",
    "title": "6  Signed Networks",
    "section": "6.2 Data structures for signed networks",
    "text": "6.2 Data structures for signed networks\nThe foundation of signnet is provided by igraph. All functions in the package assume that an igraph object is a signed network if it has an edge attribute “sign” with values 1 (positive) or -1 (negative).\n\ng &lt;- graph.full(5, directed = FALSE, loops = FALSE)\nE(g)$sign &lt;- 1\ng\n\nIGRAPH c6c7c73 U--- 5 10 -- Full graph\n+ attr: name (g/c), loops (g/l), sign (e/n)\n+ edges from c6c7c73:\n [1] 1--2 1--3 1--4 1--5 2--3 2--4 2--5 3--4 3--5 4--5\n\n\nAll methods throw an error if the sign attribute is missing or contains other values than -1 and 1.\nMatrices associated with a signed network follow the igraph naming scheme. The signed adjacency matrix can be obtained with as_adj_signed().\n\ndata(\"tribes\")\nas_adj_signed(tribes)[1:5,1:5]\n\n      Gavev Kotun Ove Alika Nagam\nGavev     0     1  -1    -1    -1\nKotun     1     0  -1     0    -1\nOve      -1    -1   0     1     0\nAlika    -1     0   1     0     0\nNagam    -1    -1   0     0     0\n\n\nThe signed Laplacian matrix is obtained by laplacian_matrix_signed().\n\nlaplacian_matrix_signed(tribes)[1:5,1:5]\n\n      Gavev Kotun Ove Alika Nagam\nGavev     8    -1   1     1     1\nKotun    -1     8   1     0     1\nOve       1     1   6    -1     0\nAlika     1     0  -1     3     0\nNagam     1     1   0     0     7\n\n\nThe signnet package includes two well known example datasets.\nThe “tribes” dataset is a signed social network of tribes of the Gahuku–Gama alliance structure of the Eastern Central Highlands of New Guinea. The network contains sixteen tribes connected by friendship (“rova”) and enmity (“hina”).\nThe “cowList” dataset contains a list of 52 signed networks of inter-state relations over time (1946-1999). Two countries are connected by a positive tie if they form an alliance or have a peace treaty. A negative tie exists between countries who are at war or in other kinds of conflicts. The dataset is derrived from the correlates of war.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html#structural-balance",
    "href": "signed-networks.html#structural-balance",
    "title": "6  Signed Networks",
    "section": "6.3 Structural Balance",
    "text": "6.3 Structural Balance\nThe principles underlying structural balance are based on a theory in social psychology dating back to the work of Heider in the 1940s, which was generalized and extended to graphs by Cartwright and Harary in the 1950s. In its simplest form, it is defined via triangles. A triangle is balanced if all ties are positive (“the friend of a friend is a friend”) or only one tie is positive (“the enemy of my enemy is my friend”). The remaining configurations are said to be unbalanced.\n\nA network is balanced if i.a., it can be partitioned into two vertex subsets, such that intra-group edges are all positive and inter-group edges are all negative.\nA (random) balanced network can be obtained with the function sample_islands_signed() which is pretty much the same as sample_islands() from the igraph package.\n\ng &lt;- sample_islands_signed(islands.n = 2,islands.size = 10,\n                           islands.pin = 0.8,n.inter = 5)\n\n(The function ggsigned() can be used to visualize signed networks. Note that this requires the package ggraph to be installed.) Increasing islands.n leads to “clusterable” networks as defined by Davis.\nA balanced network only contains balanced triangles. This can be verified with count_signed_triangles().\n\ncount_signed_triangles(g)\n\n+++ ++- +-- --- \n129   0   6   0 \n\n\nNote the absence of ++- and --- triangles.\nTo list all triangles use signed_triangles().\n\nhead(signed_triangles(g))\n\n     V1 V2 V3 P\n[1,]  8  1  2 3\n[2,]  8  1  4 3\n[3,]  8  1  7 3\n[4,]  8  1  6 3\n[5,]  8  2  6 3\n[6,]  8  2  4 3\n\n\nThe column P indicated the number of positive ties in the triangle. A value of 3 indicates that the triangle is “+++”.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html#balancedness",
    "href": "signed-networks.html#balancedness",
    "title": "6  Signed Networks",
    "section": "6.4 Balancedness",
    "text": "6.4 Balancedness\nDetermining if a network is balanced or not is easy, but measuring a degree of balancedness (i.e. how close is a network to be balanced?) is not. The package, so far, implements three methods to calculate balance scores. All are defined such that a value of one indicates perfect balance and zero perfect unbalance. Though for intermediate networks, results may vary significantly. Check the paper by Samin Aref (and his other work) for more details.\n\nbalance_score(g, method = \"triangles\")\n\n[1] 1\n\nbalance_score(g, method = \"walk\")\n\n[1] 1\n\nbalance_score(g, method = \"frustration\")\n\n[1] 1\n\n\n“triangles” returns the fraction of balanced triangles.\n“walk” is based on eigenvalues of the signed and underlying unsigned network. Check the paper by Estrada for details.\n“frustration” assumes that the network can be partitioned into two groups, where intra group edges are positive and inter group edges are negative. The index is defined as the sum of intra group negative and inter group positive edges. Note that the problem is NP complete and only an upper bound is returned (based on simulated annealing). The function frustration_exact() implements an integer program to solve the exact optimization problem. More details can be found in the work of Aref.\nThere disagreement for non-balanced networks can be seen with the included “tribes” dataset.\n\ndata(\"tribes\")\nbalance_score(tribes, method = \"triangles\")\n\n[1] 0.867647\n\nbalance_score(tribes, method = \"walk\")\n\n[1] 0.357576\n\nbalance_score(tribes, method = \"frustration\")\n\n[1] 0.758621",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html#triangles",
    "href": "signed-networks.html#triangles",
    "title": "6  Signed Networks",
    "section": "6.5 Triangles",
    "text": "6.5 Triangles\nThe function triad_census_signed() calculates the signed triad census of a directed signed network. While the unsigned triad census has only 16 possible outcomes, there are 138 non-isomorphic signed triads, shown below.\n\nThe naming scheme is “xxx-yyyyyy” where “xxx” corresponds to the name of the respective unsigned triad and “yyyyyy” is a string of “0”, “N”, “P”, describing the type of ties present. So “300-NNNNNN” is a triad with all ties present and all ties are negative.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html#traditional-blockmodeling",
    "href": "signed-networks.html#traditional-blockmodeling",
    "title": "6  Signed Networks",
    "section": "6.6 Traditional Blockmodeling",
    "text": "6.6 Traditional Blockmodeling\nIn signed blockmodeling, the goal is to determine k blocks of nodes such that all intra-block edges are positive and inter-block edges are negative. In the example below, we construct a network with a perfect block structure with sample_islands_signed(). The network consists of 10 blocks with 10 vertices each, where each block has a density of 1 (of positive edges). The function signed_blockmodel() is used to construct the blockmodel. The parameter k is the number of desired blocks. alpha is a trade-off parameter. The function minimizes \\(P(C)=\\alpha N+(1-\\alpha)P\\), where \\(N\\) is the total number of negative ties within blocks and \\(P\\) be the total number of positive ties between blocks.\n\ng &lt;- sample_islands_signed(10,10,1,20)\nclu &lt;- signed_blockmodel(g,k = 10,alpha = 0.5)\ntable(clu$membership)\n\n\n 1  2  3  4  5  6  7  8  9 10 \n10 10 10 10 10 10 10 10 10 10 \n\nclu$criterion\n\n[1] 0\n\n\nThe function returns a list with two entries. The block membership of nodes and the value of \\(P(C)\\).\nThe function ggblock() can be used to plot the outcome of the blockmodel (ggplot2 is required).\n\nggblock(g,clu$membership,show_blocks = TRUE)\n\n\n\n\n\n\n\n\nIf the parameter annealing is set to TRUE, simulated annealing is used in the optimization step. This generally leads to better results but longer runtimes.\n\ndata(\"tribes\")\nset.seed(44) #for reproducibility\n\nsigned_blockmodel(tribes,k = 3,alpha=0.5,annealing = TRUE)\n\n$membership\n [1] 1 1 2 2 3 2 2 2 3 3 2 2 3 3 1 1\n\n$criterion\n[1] 2\n\nsigned_blockmodel(tribes,k = 3,alpha=0.5,annealing = FALSE)\n\n$membership\n [1] 1 1 2 2 3 2 2 2 3 3 2 2 3 3 1 1\n\n$criterion\n[1] 2",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html#generalized-blockmodeling",
    "href": "signed-networks.html#generalized-blockmodeling",
    "title": "6  Signed Networks",
    "section": "6.7 Generalized Blockmodeling",
    "text": "6.7 Generalized Blockmodeling\nThe function signed_blockmodel() is only able to provide a blockmodel where the diagonal blocks are positive and off-diagonal blocks are negative. The function signed_blockmodel_general() can be used to specify different block structures. In the below example, we construct a network that contains three blocks. Two have positive and one has negative intra-group ties. The inter-group edges are negative between group one and two, and one and three. Between group two and three, all edges are positive.\n\ng1 &lt;- g2 &lt;- g3 &lt;- graph.full(5)\n\nV(g1)$name &lt;- as.character(1:5)\nV(g2)$name &lt;- as.character(6:10)\nV(g3)$name &lt;- as.character(11:15)\n\ng &lt;- Reduce(\"%u%\",list(g1,g2,g3))\nE(g)$sign &lt;- 1\nE(g)$sign[1:10] &lt;- -1\ng &lt;- add.edges(g,c(rbind(1:5,6:10)),attr = list(sign=-1))\ng &lt;- add.edges(g,c(rbind(1:5,11:15)),attr = list(sign=-1))\ng &lt;- add.edges(g,c(rbind(11:15,6:10)),attr = list(sign=1))\n\nThe parameter blockmat is used to specify the desired block structure.\n\nset.seed(424)\nblockmat &lt;- matrix(c(1,-1,-1,-1,1,1,-1,1,-1),3,3,byrow = TRUE)\nblockmat\n\n     [,1] [,2] [,3]\n[1,]    1   -1   -1\n[2,]   -1    1    1\n[3,]   -1    1   -1\n\ngeneral &lt;- signed_blockmodel_general(g,blockmat,alpha = 0.5)\ntraditional &lt;- signed_blockmodel(g,k = 3,alpha = 0.5,annealing = TRUE)\n\nc(general$criterion,traditional$criterion)\n\n[1] 0 6",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html#centrality",
    "href": "signed-networks.html#centrality",
    "title": "6  Signed Networks",
    "section": "6.8 Centrality",
    "text": "6.8 Centrality\nThere exist dozens of indices for networks with positive ties, but for signed networks they are rather scarce. The package implements three indices so far. Versions of degree and eigenvector centrality, and PN centrality by Everett & Borgatti.\nDegree centrality can be calculated in four different ways with degree_signed(), specified by the type parameter:\n\ntype=\"pos\" count only positive neighbors\ntype=\"neg\" count only negative neighbors\ntype=\"ratio\" positive neighbors/(positive neighbors+negative neighbors)\ntype=\"net\" positive neighbors-negative neighbors\n\nThe mode parameter can be used to get “in” and “out” versions for directed networks.\nThe PN index is very similar to Katz status and Hubbell’s measure for networks with only positive ties. The technical details can be found in the paper by Everett & Borgatti.\nThe below example illustrates all indices with a network where signed degree can not distinguish vertices.\n\nA &lt;- matrix(c(0,  1,  0,  1,  0,  0,  0, -1, -1,  0,  \n               1,  0,  1, -1,  1, -1, -1,  0,  0,  0,  \n               0,  1,  0,  1, -1,  0,  0,  0, -1,  0,  \n               1, -1,  1,  0,  1, -1, -1,  0,  0,  0,  \n               0,  1, -1,  1,  0,  1,  0, -1,  0, -1,  \n               0, -1,  0, -1,  1,  0,  1,  0,  1, -1,  \n               0, -1,  0, -1,  0,  1,  0,  1, -1,  1,  \n              -1,  0,  0,  0, -1,  0,  1,  0,  1,  0,  \n              -1,  0, -1,  0,  0,  1, -1,  1,  0,  1,  \n               0,  0,  0,  0, -1, -1,  1,  0,  1,  0),10,10)\n\ng &lt;- graph_from_adjacency_matrix(A,\"undirected\",weighted = \"sign\")\n\ndegree_signed(g,type=\"ratio\")\n\n [1] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n\neigen_centrality_signed(g)\n\n [1] 0.6221496 1.0000000 0.7451885 1.0000000 0.8999004 0.6428959 0.3582816\n [8] 0.3747192 0.2808741 0.0783457\n\npn_index(g)\n\n [1] 0.900975 0.861348 0.907700 0.861348 0.841066 0.849656 0.861732 0.901591\n [9] 0.850985 0.907293\n\n\nNote that PN centrality and eigenvector centrality differ significantly for this network.\n\ncor(eigen_centrality_signed(g),pn_index(g),method = \"kendall\")\n\n[1] -0.244444\n\n\n\n6.8.1 A note on eigenvector centrality\nThe adjacency matrix of a signed network may not have a dominant eigenvalue. This means it is not clear which eigenvector should be used. In addition it is possible for the adjacency matrix to have repeated eigenvalues and hence multiple linearly independent eigenvectors. In this case certain centralities can be arbitrarily assigned. The eigen_centrality_signed() function returns an error if this is the case.\n\nA &lt;- matrix(c( 0,  1,  1, -1,  0,  0, -1,  0,  0, \n               1,  0,  1,  0, -1,  0,  0, -1,  0, \n               1,  1,  0,  0,  0, -1,  0,  0, -1, \n              -1,  0,  0,  0,  1,  1, -1,  0,  0, \n               0, -1,  0,  1,  0,  1,  0, -1,  0, \n               0,  0, -1,  1,  1,  0,  0,  0, -1, \n              -1,  0,  0, -1,  0,  0,  0,  1,  1, \n               0, -1,  0,  0, -1,  0,  1,  0,  1, \n               0,  0, -1,  0,  0, -1,  1,  1, 0), 9, 9)\n\ng &lt;- igraph::graph_from_adjacency_matrix(A,\"undirected\",weighted = \"sign\")\neigen_centrality_signed(g)\n\nError in eigen_centrality_signed(g): no dominant eigenvalue exists",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "signed-networks.html#scientific-reading",
    "href": "signed-networks.html#scientific-reading",
    "title": "6  Signed Networks",
    "section": "6.9 Scientific Reading",
    "text": "6.9 Scientific Reading\nEverett, Martin G., and Stephen P. Borgatti. 2014. “Networks Containing Negative Ties.” Social Networks 38: 111–20.\nBonacich, Phillip, and Paulette Lloyd. 2004. “Calculating Status with Negative Relations.” Social Networks 26 (4): 331–38.\nDoreian, Patrick, and Andrej Mrvar. 1996. “A Partitioning Approach to Structural Balance.” Social Networks 18 (2): 149–68.\nDoreian, Patrick, and Andrej Mrvar. 2009. “Partitioning Signed Social Networks.” Social Networks 31 (1): 1–11.\nDoreian, Patrick, and Andrej Mrvar. 2015. “Structural Balance and Signed International Relations.” Journal of Social Structure 16: 1.\nHeider, Fritz. 1946. “Attitudes and Cognitive Organization.” The Journal of Psychology 21 (1): 107–12.\nCartwright, Dorwin, and Frank Harary. 1956. “Structural Balance: A Generalization of Heider’s Theory.” Psychological Review 63 (5): 277.\nDavis, James A. 1967. “Clustering and Structural Balance in Graphs.” Human Relations 20 (2): 181–87.\nAref, Samin, and Mark C. Wilson. 2018. “Measuring Partial Balance in Signed Networks.” Journal of Complex Networks 6 (4): 566–95.\nEstrada, Ernesto. 2019. “Rethinking Structural Balance in Signed Social Networks.” Discrete Applied Mathematics",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Signed Networks</span>"
    ]
  },
  {
    "objectID": "ego-networks.html",
    "href": "ego-networks.html",
    "title": "7  Ego Networks",
    "section": "",
    "text": "7.1 Scientific Reading\nMcCarty, C., Lubbers, M. J., Vacca, R., & Molina, J. L. (2019). Conducting personal network research: A practical guide. The Guilford Press.",
    "crumbs": [
      "Descriptive Network Analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ego Networks</span>"
    ]
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "Network Visualization",
    "section": "",
    "text": "Required libraries\nTo run all the code in this tutorial, you need to install and load several packages.\ninstall.packages(c(\"igraph\", \"graphlayouts\", \"ggraph\", \"ggforce\"))\ndevtools::install_github(\"schochastics/networkdata\")\nMake sure you have at least the version given below. Some of the examples may not be backward compatible.\npackageVersion(\"igraph\")\n\n[1] '1.6.0'\n\npackageVersion(\"graphlayouts\")\n\n[1] '1.1.1'\n\npackageVersion(\"ggraph\")\n\n[1] '2.2.0'\n\npackageVersion(\"networkdata\")\n\n[1] '0.2.1'\n\npackageVersion(\"ggforce\")\n\n[1] '0.4.1'\nigraph is mostly used for its data structures and graphlayouts and ggraph for visualizations. The networkdata package contains a huge amount of example network data that always comes in handy for learning new visualization techniques.\nlibrary(igraph)\nlibrary(ggraph)\n\nLoading required package: ggplot2\n\nlibrary(graphlayouts)\nlibrary(ggforce)",
    "crumbs": [
      "Network Visualization"
    ]
  },
  {
    "objectID": "ggraph-basics.html",
    "href": "ggraph-basics.html",
    "title": "8  Basics of ggraph",
    "section": "",
    "text": "8.1 Introduction\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(graphlayouts)\nlibrary(networkdata)\n\ndata(\"got\")\ngotS1 &lt;- got[[1]]\nWe add some more node attributes to the GoT network that can be used for visualization purposes.\n## define a custom color palette\ngot_palette &lt;- c(\n    \"#1A5878\", \"#C44237\", \"#AD8941\", \"#E99093\",\n    \"#50594B\", \"#8968CD\", \"#9ACD32\"\n)\n\n## compute a clustering for node colors\nV(gotS1)$clu &lt;- as.character(membership(cluster_louvain(gotS1)))\n\n## compute degree as node size\nV(gotS1)$size &lt;- degree(gotS1)\nTo champion ggraph you need to understand the basics of, or at least develop a feeling for, the grammar of graphics. Instead of explaining the grammar, let us directly jump into some code and work through it one line at a time.\nggraph(gotS1, layout = \"stress\") +\n  geom_edge_link0(aes(edge_linewidth = weight), edge_colour = \"grey66\") +\n  geom_node_point(aes(fill = clu, size = size), shape = 21) +\n  geom_node_text(aes(filter = size &gt;= 26, label = name), family = \"serif\") +\n  scale_fill_manual(values = got_palette) +\n  scale_edge_width(range = c(0.2, 3)) +\n  scale_size(range = c(1, 6)) +\n  theme_graph() +\n  theme(legend.position = \"none\")\nggraph works with layers. Each layer adds a new feature to the plot and thus builds the figure step-by-step. We will work through each of the layers separately in the following sections.",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Basics of ggraph</span>"
    ]
  },
  {
    "objectID": "ggraph-basics.html#layout",
    "href": "ggraph-basics.html#layout",
    "title": "8  Basics of ggraph",
    "section": "8.2 Layout",
    "text": "8.2 Layout\nggraph(gotS1, layout = \"stress\")\nThe first step is to compute a layout. The layout parameter specifies the algorithm to use. The “stress” layout is part of the graphlayouts package and is always a safe choice since it is deterministic and produces nice layouts for almost any graph. I would recommend to use it as your default choice. Other algorithms for, e.g., concentric layouts and clustered networks are described further down in this tutorial. For the sake of completeness, here is a list of layout algorithms of igraph.\nc(\n  \"layout_with_dh\", \"layout_with_drl\", \"layout_with_fr\",\n  \"layout_with_gem\", \"layout_with_graphopt\", \"layout_with_kk\",\n  \"layout_with_lgl\", \"layout_with_mds\", \"layout_with_sugiyama\",\n  \"layout_as_bipartite\", \"layout_as_star\", \"layout_as_tree\"\n)\nTo use them, you just need the last part of the name.\nggraph(gotS1, layout = \"dh\") +\n  ...\nNote that there technically is no right or wrong choice. All layout algorithms are in a sense arbitrary since we can choose x and y coordinates freely (compare this to ordinary data!). It is all mostly about aesthetics.\nYou can also precompute the layout with the create_layout() function. This makes sense in cases where the calculation of the layout takes very long and you want to play around with other visual aspects.\ngotS1_layout &lt;- create_layout(gotS1 = \"stress\")\n\nggraph(gotS1_layout) +\n  ...",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Basics of ggraph</span>"
    ]
  },
  {
    "objectID": "ggraph-basics.html#edges",
    "href": "ggraph-basics.html#edges",
    "title": "8  Basics of ggraph",
    "section": "8.3 Edges",
    "text": "8.3 Edges\ngeom_edge_link0(aes(width = weight), edge_colour = \"grey66\")\nThe second layer specifies how to draw the edges. Edges can be drawn in many different ways as the list below shows.\nc(\n  \"geom_edge_arc\", \"geom_edge_arc0\", \"geom_edge_arc2\", \"geom_edge_density\",\n  \"geom_edge_diagonal\", \"geom_edge_diagonal0\", \"geom_edge_diagonal2\",\n  \"geom_edge_elbow\", \"geom_edge_elbow0\", \"geom_edge_elbow2\", \"geom_edge_fan\",\n  \"geom_edge_fan0\", \"geom_edge_fan2\", \"geom_edge_hive\", \"geom_edge_hive0\",\n  \"geom_edge_hive2\", \"geom_edge_link\", \"geom_edge_link0\", \"geom_edge_link2\",\n  \"geom_edge_loop\", \"geom_edge_loop0\"\n)\nYou can do a lot of fancy things with these geoms but for a standard network plot, you should almost always stick with geom_edge_link0 since it simply draws a straight line between the endpoints. Some tools draw curved edges by default. While this may add some artistic value, it reduces readability. Always go with straight lines! If your network has multiple edges between two nodes, then you can switch to geom_edge_parallel().\nIn case you are wondering what the “0” stands for: The standard geom_edge_link() draws 100 dots on each edge compared to only two dots (the endpoints) in geom_edge_link0(). This is done to allow, e.g., gradients along the edge.\n\nggraph(gotS1, layout = \"stress\") +\n  geom_edge_link(aes(alpha = after_stat(index)), edge_colour = \"black\") +\n  geom_node_point(aes(fill = clu, size = size), shape = 21) +\n  scale_fill_manual(values = got_palette) +\n  scale_edge_width_continuous(range = c(0.2, 3)) +\n  scale_size_continuous(range = c(1, 6)) +\n  theme_graph() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe drawback of using geom_edge_link() is that the time to render the plot increases and so does the size of the file if you export the plot (example) Typically, you do not need gradients along an edge. Hence, geom_edge_link0() should be your default choice to draw edges.\nWithin geom_edge_link0, you can specify the appearance of the edge, either by mapping edge attributes to aesthetics or setting them globally for the graph. Mapping attributes to aesthetics is done within aes(). In the example, we map the edge width to the edge attribute “weight”. ggraph then automatically scales the edge width according to the attribute. The colour of all edges is globally set to “grey66”.\nThe following aesthetics can be used within geom_edge_link0 either within aes() or globally:\n\nedge_colour (colour of the edge)\nedge_linewidth (width of the edge)\nedge_linetype (linetype of the edge, defaults to “solid”)\nedge_alpha (opacity; a value between 0 and 1)\n\nggraph does not automatically draw arrows if your graph is directed. You need to do this manually using the arrow parameter.\ngeom_edge_link0(aes(...), ...,\n  arrow = arrow(\n    angle = 30, length = unit(0.15, \"inches\"),\n    ends = \"last\", type = \"closed\"\n  )\n)\nThe default arrowhead type is “open”, yet “closed” usually has a nicer appearance.",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Basics of ggraph</span>"
    ]
  },
  {
    "objectID": "ggraph-basics.html#nodes",
    "href": "ggraph-basics.html#nodes",
    "title": "8  Basics of ggraph",
    "section": "8.4 Nodes",
    "text": "8.4 Nodes\ngeom_node_point(aes(fill = clu, size = size), shape = 21) +\n  geom_node_text(aes(filter = size &gt;= 26, label = name), family = \"serif\")\nOn top of the edge layer, we draw the node layer. Always draw the node layer above the edge layer. Otherwise, edges will be visible on top of nodes. There are slightly less geoms available for nodes.\nc(\n  \"geom_node_arc_bar\", \"geom_node_circle\", \"geom_node_label\",\n  \"geom_node_point\", \"geom_node_text\", \"geom_node_tile\", \"geom_node_treemap\"\n)\nThe most important ones here are geom_node_point() to draw nodes as simple geometric objects (circles, squares,…) and geom_node_text() to add node labels. You can also use geom_node_label(), but this draws labels within a box.\nThe mapping of node attributes to aesthetics is similar to edge attributes. In the example code, we map the fill attribute of the node shape to the “clu” attribute, which holds the result of a clustering, and the size of the nodes to the attribute “size”. The shape of the node is globally set to 21.\nThe figure below shows all possible shapes that can be used for the nodes.\n\nPersonally, I prefer “21” since it draws a border around the nodes. If you prefer another shape, say “19”, you have to be aware of several things. To change the color of shapes 1-20, you need to use the colour parameter. For shapes 21-25 you need to use fill. The colour parameter only controls the border for these cases.\nThe following aesthetics can be used within geom_node_point() either within aes() or globally:\n\nalpha (opacity; a value between 0 and 1)\ncolour (colour of shapes 0-20 and border colour for 21-25)\nfill (fill colour for shape 21-25)\nshape (node shape; a value between 0 and 25)\nsize (size of node)\nstroke (size of node border)\n\nFor geom_node_text(), there are a lot more options available, but the most important once are:\n\nlabel (attribute to be displayed as node label)\ncolour (text colour)\nfamily (font to be used)\nsize (font size)\n\nNote that we also used a filter within aes() of geom_node_text(). The filter parameter allows you to specify a rule for when to apply the aesthetic mappings. The most frequent use case is for node labels (but can also be used for edges or nodes). In the example, we only display the node label if the size attribute is larger than 26.",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Basics of ggraph</span>"
    ]
  },
  {
    "objectID": "ggraph-basics.html#scales",
    "href": "ggraph-basics.html#scales",
    "title": "8  Basics of ggraph",
    "section": "8.5 Scales",
    "text": "8.5 Scales\nscale_fill_manual(values = got_palette) +\n  scale_edge_width_continuous(range = c(0.2, 3)) +\n  scale_size_continuous(range = c(1, 6))\nThe scale_* functions are used to control aesthetics that are mapped within aes(). You do not necessarily need to set them, since ggraph can take care of it automatically.\n\nggraph(gotS1, layout = \"stress\") +\n  geom_edge_link0(aes(edge_linewidth = weight), edge_colour = \"grey66\") +\n  geom_node_point(aes(fill = clu, size = size), shape = 21) +\n  geom_node_text(aes(filter = size &gt;= 26, label = name), family = \"serif\") +\n  theme_graph() +\n  theme(legend.position = \"none\")\n\nWarning: The `trans` argument of `continuous_scale()` is deprecated as of ggplot2 3.5.0.\nℹ Please use the `transform` argument instead.\n\n\n\n\n\n\n\n\n\nWhile the node fill and size seem reasonable, the edges are a little too thick. In general, it is always a good idea to add a scale_* for each aesthetic within aes().\nWhat kind of scale_* function you need depends on the aesthetic and on the type of attribute you are mapping. Generally, scale functions are structured like this:\nscale_&lt;aes&gt;_&lt;variable type&gt;().\nThe “aes” part is easy. Just us the type you specified within aes(). For edges, however, you have to prepend edge_. The “variable type” part depends on which scale the attribute is on. Before we continue, it may be a good idea to briefly discuss what aesthetics make sense for which variable type.\n\n\n\n\n\n\n\n\naesthetic\nvariable type\nnotes\n\n\n\n\nnode size\ncontinuous\n\n\n\nedge width\ncontinuous\n\n\n\nnode colour/fill\ncategorical/continuous\nuse a gradient for continuous variables\n\n\nedge colour\ncontinuous\ncategorical only if there are different types of edges\n\n\nnode shape\ncategorical\nonly if there are a few categories (1-5). Colour should be the preferred choice\n\n\nedge linetype\ncategorical\nonly if there are a few categories (1-5). Colour should be the preferred choice\n\n\nnode/edge alpha\ncontinuous\n\n\n\n\nThe easiest to use scales are those for continuous variables mapped to edge width and node size (also the alpha value, which is not used here). While there are several parameters within scale_edge_width_continuous() and scale_size_continuous(), the most important one is “range” which fixes the minimum and maximum width/size. It usually suffices to adjust this parameter.\nFor continuous variables that are mapped to node/edge colour, you can use scale_colour_gradient() scale_colour_gradient2() or scale_colour_gradientn() (add edge_ before colour for edge colours). The difference between these functions is in how the gradient is constructed. gradient creates a two colour gradient (low-high). Simply specify the the two colours to be used (e.g. low = “blue”, high = “red”). gradient2 creates a diverging colour gradient (low-mid-high) (e.g. low = “blue”, mid = “white”, high = “red”) and gradientn a gradient consisting of more than three colours (specified with the colours parameter).\nFor categorical variables that are mapped to node colours (or fill in our example), you can use scale_fill_manual(). This forces you to choose a color for each category yourself. Simply create a vector of colors (see the got_palette) and pass it to the function with the parameter values.\nggraph then assigns the colors in the order of the unique values of the categorical variable. This are either the factor levels (if the variable is a factor) or the result of sorting the unique values (if the variable is a character).\n\nsort(unique(V(gotS1)$clu))\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\"\n\n\nIf you want more control over which value is mapped to which colour, you can pass the vector of colours as a named vector.\n\ngot_palette2 &lt;- c(\n    \"5\" = \"#1A5878\", \"3\" = \"#C44237\", \"2\" = \"#AD8941\",\n    \"1\" = \"#E99093\", \"4\" = \"#50594B\", \"7\" = \"#8968CD\", \"6\" = \"#9ACD32\"\n)\n\n\n\n\n\n\n\n\n\n\nUsing your own colour palette gives your network a unique touch. If you can’t be bothered with choosing colours, you may want to consider scale_fill_brewer() and scale_colour_brewer(). The function offers all palettes available at colorbrewer2.org.\n\nggraph(gotS1, layout = \"stress\") +\n  geom_edge_link0(aes(edge_linewidth = weight), edge_colour = \"grey66\") +\n  geom_node_point(aes(fill = clu, size = size), shape = 21) +\n  geom_node_text(aes(filter = size &gt;= 26, label = name), family = \"serif\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  scale_edge_width_continuous(range = c(0.2, 3)) +\n  scale_size_continuous(range = c(1, 6)) +\n  theme_graph() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n(Check out this github repo from Emil Hvitfeldt for a comprehensive list of color palettes available in R)",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Basics of ggraph</span>"
    ]
  },
  {
    "objectID": "ggraph-basics.html#themes",
    "href": "ggraph-basics.html#themes",
    "title": "8  Basics of ggraph",
    "section": "8.6 Themes",
    "text": "8.6 Themes\ntheme_graph() +\n  theme(legend.position = \"none\")\nthemes control the overall look of the plot. There are a lot of options within the theme() function of ggplot2. Luckily, we really don’t need any of those. theme_graph() is used to erase all of the default ggplot theme (e.g. axis, background, grids, etc.) since they are irrelevant for networks. The only option worthwhile in theme() is legend.position, which we set to “none”, i.e. don’t show the legend.\nThe code below gives an example for a plot with a legend.\n\nggraph(gotS1, layout = \"stress\") +\n  geom_edge_link0(aes(edge_linewidth = weight), edge_colour = \"grey66\") +\n  geom_node_point(aes(fill = clu, size = size), shape = 21) +\n  geom_node_text(aes(filter = size &gt;= 26, label = name), family = \"serif\") +\n  scale_fill_manual(values = got_palette) +\n  scale_edge_width_continuous(range = c(0.2, 3)) +\n  scale_size_continuous(range = c(1, 6)) +\n  theme_graph() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nThis covers all the necessary steps to produce a standard network plot with ggraph. More advanced techniques will be covered in the next sections. We conclude the introductory part by recreating a quite famous network visualization",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Basics of ggraph</span>"
    ]
  },
  {
    "objectID": "ggraph-basics.html#extended-example",
    "href": "ggraph-basics.html#extended-example",
    "title": "8  Basics of ggraph",
    "section": "8.7 Extended Example",
    "text": "8.7 Extended Example\nIn this section, we do a little code through to recreate the figure shown below.\n The network shows the linking between political blogs during the 2004 election in the US. Red nodes are conservative leaning blogs and blue ones liberal.\nThe dataset is included in the networkdata package.\n\ndata(\"polblogs\")\n\n## add a vertex attribute for the indegree\nV(polblogs)$deg &lt;- degree(polblogs, mode = \"in\")\n\nLet us start with a simple plot without any styling.\n\nlay &lt;- create_layout(polblogs, \"stress\")\n\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, edge_colour = \"grey66\",\n        arrow = arrow(\n            angle = 15, length = unit(0.15, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        )\n    ) +\n    geom_node_point()\n\n\n\n\n\n\n\n\nThere is obviously a lot missing. First, we delete all isolates and plot again.\n\npolblogs &lt;- delete.vertices(polblogs, which(degree(polblogs) == 0))\nlay &lt;- create_layout(polblogs, \"stress\")\n\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, edge_colour = \"grey66\",\n        arrow = arrow(\n            angle = 15, length = unit(0.1, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        )\n    ) +\n    geom_node_point()\n\n\n\n\n\n\n\n\nThe original does feature a small disconnected component, but we remove this here.\n\ncomps &lt;- components(polblogs)\npolblogs &lt;- delete.vertices(polblogs, which(comps$membership == which.min(comps$csize)))\n\nlay &lt;- create_layout(polblogs, \"stress\")\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, edge_colour = \"grey66\",\n        arrow = arrow(\n            angle = 15, length = unit(0.15, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        )\n    ) +\n    geom_node_point()\n\n\n\n\n\n\n\n\nBetter, let’s start with some styling of the nodes.\n\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, edge_colour = \"grey66\",\n        arrow = arrow(\n            angle = 15, length = unit(0.15, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        )\n    ) +\n    geom_node_point(shape = 21, aes(fill = pol))\n\n\n\n\n\n\n\n\nThe colors are obviously wrong, so we fix this with a scale_fill_manual(). Additionally, we map the degree to node size.\n\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, edge_colour = \"grey66\",\n        arrow = arrow(\n            angle = 15, length = unit(0.15, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        )\n    ) +\n    geom_node_point(shape = 21, aes(fill = pol, size = deg), show.legend = FALSE) +\n    scale_fill_manual(values = c(\"left\" = \"#104E8B\", \"right\" = \"firebrick3\"))\n\n\n\n\n\n\n\n\nThe node sizes are also not that satisfactory, so we fix the range with scale_size().\n\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, edge_colour = \"grey66\",\n        arrow = arrow(\n            angle = 10, length = unit(0.1, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        )\n    ) +\n    geom_node_point(shape = 21, aes(fill = pol, size = deg), show.legend = FALSE) +\n    scale_fill_manual(values = c(\"left\" = \"#104E8B\", \"right\" = \"firebrick3\")) +\n    scale_size(range = c(0.5, 7))\n\n\n\n\n\n\n\n\nNow we move on to the edges. This is a bit more complicated since we have to create an edge variable first which indicates if an edge is within or between political orientations. This new variable is mapped to the edge color.\n\nel &lt;- get.edgelist(polblogs, names = FALSE)\nel_pol &lt;- cbind(V(polblogs)$pol[el[, 1]], V(polblogs)$pol[el[, 2]])\nE(polblogs)$col &lt;- ifelse(el_pol[, 1] == el_pol[, 2], el_pol[, 1], \"mixed\")\n\n\nlay &lt;- create_layout(polblogs, \"stress\")\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, aes(edge_colour = col),\n        arrow = arrow(\n            angle = 10, length = unit(0.1, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        )\n    ) +\n    geom_node_point(shape = 21, aes(fill = pol, size = deg), show.legend = FALSE) +\n    scale_fill_manual(values = c(\"left\" = \"#104E8B\", \"right\" = \"firebrick3\")) +\n    scale_size(range = c(0.5, 7))\n\n\n\n\n\n\n\n\nSimilar to the node colors, we add a scale_edge_colour_manual() to adjust the edge colors.\n\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, aes(edge_colour = col),\n        arrow = arrow(\n            angle = 10, length = unit(0.1, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        ), show.legend = FALSE\n    ) +\n    geom_node_point(shape = 21, aes(fill = pol, size = deg), show.legend = FALSE) +\n    scale_fill_manual(values = c(\"left\" = \"#104E8B\", \"right\" = \"firebrick3\")) +\n    scale_edge_colour_manual(values = c(\"left\" = \"#104E8B\", \"mixed\" = \"goldenrod\", \"right\" = \"firebrick3\")) +\n    scale_size(range = c(0.5, 7))\n\n\n\n\n\n\n\n\nAlmost, but it seems there are a lot of yellow edges which run over blue edges. It looks as if these should run below according to the original viz. To achieve this, we use a filter trick. We add two geom_edge_link0() layers: First, for the mixed edges and then for the remaining edges. In that way, the mixed edges are getting plotted below.\n\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, aes(filter = (col == \"mixed\"), edge_colour = col),\n        arrow = arrow(\n            angle = 10, length = unit(0.1, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        ), show.legend = FALSE\n    ) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, aes(filter = (col != \"mixed\"), edge_colour = col),\n        arrow = arrow(\n            angle = 10, length = unit(0.1, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        ), show.legend = FALSE\n    ) +\n    geom_node_point(shape = 21, aes(fill = pol, size = deg), show.legend = FALSE) +\n    scale_fill_manual(values = c(\"left\" = \"#104E8B\", \"right\" = \"firebrick3\")) +\n    scale_edge_colour_manual(values = c(\"left\" = \"#104E8B\", \"mixed\" = \"goldenrod\", \"right\" = \"firebrick3\")) +\n    scale_size(range = c(0.5, 7))\n\n\n\n\n\n\n\n\nNow lets just add the theme_graph().\n\nggraph(lay) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, aes(filter = (col == \"mixed\"), edge_colour = col),\n        arrow = arrow(\n            angle = 10, length = unit(0.1, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        ), show.legend = FALSE\n    ) +\n    geom_edge_link0(\n        edge_linewidth = 0.2, aes(filter = (col != \"mixed\"), edge_colour = col),\n        arrow = arrow(\n            angle = 10, length = unit(0.1, \"inches\"),\n            ends = \"last\", type = \"closed\"\n        ), show.legend = FALSE\n    ) +\n    geom_node_point(shape = 21, aes(fill = pol, size = deg), show.legend = FALSE) +\n    scale_fill_manual(values = c(\"left\" = \"#104E8B\", \"right\" = \"firebrick3\")) +\n    scale_edge_colour_manual(values = c(\"left\" = \"#104E8B\", \"mixed\" = \"goldenrod\", \"right\" = \"firebrick3\")) +\n    scale_size(range = c(0.5, 7)) +\n    theme_graph()",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Basics of ggraph</span>"
    ]
  },
  {
    "objectID": "ggraph-advanced.html",
    "href": "ggraph-advanced.html",
    "title": "9  Advanced Layouts",
    "section": "",
    "text": "9.1 Large Networks\nThe stress layout also works well with medium to large graphs.\nThe network shows the biggest componentn of the co-authorship network of R package developers on CRAN (~12k nodes)\nIf you want to go beyond ~20k nodes, then you may want to switch to layout_with_pmds() or layout_with_sparse_stress() which are optimized to work with large graphs.\nThese are capable to deal with networks with several 100,000 nodes.",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Advanced Layouts</span>"
    ]
  },
  {
    "objectID": "ggraph-advanced.html#concentric-layouts",
    "href": "ggraph-advanced.html#concentric-layouts",
    "title": "9  Advanced Layouts",
    "section": "9.2 Concentric Layouts",
    "text": "9.2 Concentric Layouts\nCircular layouts are generally not advisable. Concentric circles, on the other hand, help to emphasize the position of certain nodes in the network. The graphlayouts package has two function to create concentric layouts, layout_with_focus() and layout_with_centrality().\nThe first one allows to focus the network on a specific node and arrange all other nodes in concentric circles (depending on the geodesic distance) around it. Below we focus on the character Ned Stark.\n\nggraph(gotS1, layout = \"focus\", focus = 1) +\n    geom_edge_link0(aes(edge_linewidth = weight), edge_colour = \"grey66\") +\n    geom_node_point(aes(fill = clu, size = size), shape = 21) +\n    geom_node_text(aes(filter = (name == \"Ned\"), size = size, label = name),\n        family = \"serif\"\n    ) +\n    scale_edge_width_continuous(range = c(0.2, 1.2)) +\n    scale_size_continuous(range = c(1, 5)) +\n    scale_fill_manual(values = got_palette) +\n    coord_fixed() +\n    theme_graph() +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe parameter focus in the first line is used to choose the node id of the focal node. The function coord_fixed() is used to always keep the aspect ratio at one (i.e. the circles are always displayed as a circle and not an ellipse).\nThe function draw_circle() can be used to add the circles explicitly.\n\nggraph(gotS1, layout = \"focus\", focus = 1) +\n    draw_circle(col = \"#00BFFF\", use = \"focus\", max.circle = 3) +\n    geom_edge_link0(aes(width = weight), edge_colour = \"grey66\") +\n    geom_node_point(aes(fill = clu, size = size), shape = 21) +\n    geom_node_text(aes(filter = (name == \"Ned\"), size = size, label = name),\n        family = \"serif\"\n    ) +\n    scale_edge_width_continuous(range = c(0.2, 1.2)) +\n    scale_size_continuous(range = c(1, 5)) +\n    scale_fill_manual(values = got_palette) +\n    coord_fixed() +\n    theme_graph() +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nlayout_with_centrality() works in a similar way. You can specify any centrality index (or any numeric vector for that matter), and create a concentric layout where the most central nodes are put in the center and the most peripheral nodes in the biggest circle. The numeric attribute used for the layout is specified with the cent parameter. Here, we use the weighted degree of the characters.\n\nggraph(gotS1, layout = \"centrality\", cent = graph.strength(gotS1)) +\n    geom_edge_link0(aes(edge_linewidth = weight), edge_colour = \"grey66\") +\n    geom_node_point(aes(fill = clu, size = size), shape = 21) +\n    geom_node_text(aes(size = size, label = name), family = \"serif\") +\n    scale_edge_width_continuous(range = c(0.2, 0.9)) +\n    scale_size_continuous(range = c(1, 8)) +\n    scale_fill_manual(values = got_palette) +\n    coord_fixed() +\n    theme_graph() +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n(Concentric layouts are not only helpful to focus on specific nodes, but also make for a good tool to visualize ego networks.)",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Advanced Layouts</span>"
    ]
  },
  {
    "objectID": "ggraph-advanced.html#backbone-layout",
    "href": "ggraph-advanced.html#backbone-layout",
    "title": "9  Advanced Layouts",
    "section": "9.3 Backbone Layout",
    "text": "9.3 Backbone Layout\nlayout_as_backbone() is a layout algorithm that can help emphasize hidden group structures. To illustrate the performance of the algorithm, we create an artificial network with a subtle group structure using sample_islands() from igraph.\n\ng &lt;- sample_islands(9, 40, 0.4, 15)\ng &lt;- simplify(g)\nV(g)$grp &lt;- as.character(rep(1:9, each = 40))\n\nThe network consists of 9 groups with 40 vertices each. The density within each group is 0.4 and there are 15 edges running between each pair of groups. Let us try to visualize the network with what we have learned so far.\n\nggraph(g, layout = \"stress\") +\n    geom_edge_link0(edge_colour = \"black\", edge_linewidth = 0.1, edge_alpha = 0.5) +\n    geom_node_point(aes(fill = grp), shape = 21) +\n    scale_fill_brewer(palette = \"Set1\") +\n    theme_graph() +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nAs you can see, the graph seems to be a proper “hairball” without any special structural features standing out. In this case, though, we know that there should be 9 groups of vertices that are internally more densely connected than externally. To uncover this group structure, we turn to the “backbone layout”.\n\nbb &lt;- layout_as_backbone(g, keep = 0.4)\nE(g)$col &lt;- FALSE\nE(g)$col[bb$backbone] &lt;- TRUE\n\nThe idea of the algorithm is as follows. For each edge, an embeddedness score is calculated which serves as an edge weight attribute. These weights are then ordered and only the edges with the highest score are kept. The number of edges to keep is controlled with the keep parameter. In our example, we keep the top 40%. The parameter usually requires some experimenting to find out what works best. Since this may result in an unconnected network, we add all edges of the union of all maximum spanning trees. The resulting network is the “backbone” of the original network and the “stress” layout algorithm is applied to this network. Once the layout is calculated, all edges are added back to the network.\nThe output of the function are the x and y coordinates for nodes and a vector that gives the ids of the edges in the backbone network. In the code above, we use this vector to create a binary edge attribute that indicates if an edge is part of the backbone or not.\n\nggraph(g, layout = \"backbone\", keep = 0.4) +\n    geom_edge_link0(aes(edge_colour = backbone), edge_linewidth = 0.1) +\n    geom_node_point(aes(fill = grp), shape = 21) +\n    scale_fill_brewer(palette = \"Set1\") +\n    scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +\n    theme_graph() +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe groups are now clearly visible! Of course the network used in the example is specifically tailored to illustrate the power of the algorithm. Using the backbone layout in real world networks may not always result in such a clear division of groups. It should thus not be seen as a universal remedy for drawing hairball networks. Keep in mind: It can only emphasize a hidden group structure if it exists.\nThe plot below shows an empirical example where the algorithm was able to uncover a hidden group structure. The network shows facebook friendships of a university in the US. Node colour corresponds to dormitory of students. Left is the ordinary stress layout and right the backbone layout.",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Advanced Layouts</span>"
    ]
  },
  {
    "objectID": "ggraph-advanced.html#longitudinal-networks",
    "href": "ggraph-advanced.html#longitudinal-networks",
    "title": "9  Advanced Layouts",
    "section": "9.4 Longitudinal Networks",
    "text": "9.4 Longitudinal Networks\nLongitudinal network data usually comes in the form of panel data, gathered at different points in time. We thus have a series of snapshots that need to be visualized in a way that individual nodes are easy to trace without the layout becoming to awkward.\nFor this part of the tutorial, you will need two additional packages.\n\nlibrary(gganimate)\nlibrary(ggplot2)\nlibrary(patchwork)\n\nWe will be using the 50 actor excerpt from the Teenage Friends and Lifestyle Study from the RSiena data repository as an example. The data is part of the networkdata package.\n\ndata(\"s50\")\n\nThe dataset consists of three networks with 50 actors each and a vertex attribute for the smoking behavior of students. The function layout_as_dynamic() from graphlayouts can be used to visualize the three networks. The implemented algorithm calculates a reference layout which is a layout of the union of all networks and individual layouts based on stress minimization and combines those in a linear combination which is controlled by the alpha parameter. For alpha=1, only the reference layout is used and all graphs have the same layout. For alpha=0, the stress layout of each individual graph is used. Values in-between interpolate between the two layouts.\n\nxy &lt;- layout_as_dynamic(s50, alpha = 0.2)\n\nNow you could use ggraph in conjunction with patchwork to produce a static plot with all networks side-by-side.\n\npList &lt;- vector(\"list\", length(s50))\n\nfor (i in 1:length(s50)) {\n    pList[[i]] &lt;- ggraph(s50[[i]], layout = \"manual\", x = xy[[i]][, 1], y = xy[[i]][, 2]) +\n        geom_edge_link0(edge_linewidth = 0.6, edge_colour = \"grey66\") +\n        geom_node_point(shape = 21, aes(fill = as.factor(smoke)), size = 6) +\n        geom_node_text(label = 1:50, repel = FALSE, color = \"white\", size = 4) +\n        scale_fill_manual(\n            values = c(\"forestgreen\", \"grey25\", \"firebrick\"),\n            guide = ifelse(i != 2, \"none\", \"legend\"),\n            name = \"smoking\",\n            labels = c(\"never\", \"occasionally\", \"regularly\")\n        ) +\n        theme_graph() +\n        theme(legend.position = \"bottom\") +\n        labs(title = paste0(\"Wave \", i))\n}\n\nwrap_plots(pList)\n\n\n\n\n\n\n\n\nThis is nice but of course we want to animate the changes. This is where we have to get inventive, because ggraph does not (yet) work with gganimate out of the box. For the time being, the function below provides a hacky workaround to produce a data structure that can be passed to gganimate.\n\naninet_data &lt;- function(gList, alpha = 0.2, nodes = NULL) {\n    # check for absent nodes and add them\n    if (is.null(nodes)) {\n        all_nodes &lt;- unique(unlist(sapply(gList, function(x) vertex_attr(x, \"name\"))))\n        for (i in 1:length(gList)) {\n            idx &lt;- which(!all_nodes %in% V(gList[[i]])$name)\n            if (length(idx) &gt; 0) {\n                gList[[i]] &lt;- add_vertices(gList[[i]], length(idx), attr = list(name = all_nodes[idx]))\n            }\n        }\n    } else if (nodes &gt;= 0) {\n        all_nodes &lt;- unlist(sapply(gList, function(x) vertex_attr(x, \"name\")))\n        all_nodes &lt;- names(which(table(all_nodes) &gt;= nodes * length(gList)))\n\n        for (i in 1:length(gList)) {\n            idx &lt;- which(!all_nodes %in% V(gList[[i]])$name)\n            if (length(idx) &gt; 0) {\n                gList[[i]] &lt;- add_vertices(gList[[i]], length(idx), attr = list(name = all_nodes[idx]))\n            }\n        }\n\n        for (i in 1:length(gList)) {\n            idx &lt;- which(!V(gList[[i]])$name %in% all_nodes)\n            if (length(idx) &gt; 0) {\n                gList[[i]] &lt;- delete_vertices(gList[[i]], idx)\n            }\n        }\n    }\n\n    xy &lt;- graphlayouts::layout_as_dynamic(gList, alpha = alpha)\n    nodes_lst &lt;- lapply(1:length(gList), function(i) {\n        cbind(igraph::as_data_frame(gList[[i]], \"vertices\"),\n            x = xy[[i]][, 1], y = xy[[i]][, 2], frame = i\n        )\n    })\n\n    edges_lst &lt;- lapply(1:length(gList), function(i) cbind(igraph::as_data_frame(gList[[i]], \"edges\"), frame = i))\n\n    edges_lst &lt;- lapply(1:length(gList), function(i) {\n        edges_lst[[i]]$x &lt;- nodes_lst[[i]]$x[match(edges_lst[[i]]$from, nodes_lst[[i]]$name)]\n        edges_lst[[i]]$y &lt;- nodes_lst[[i]]$y[match(edges_lst[[i]]$from, nodes_lst[[i]]$name)]\n        edges_lst[[i]]$xend &lt;- nodes_lst[[i]]$x[match(edges_lst[[i]]$to, nodes_lst[[i]]$name)]\n        edges_lst[[i]]$yend &lt;- nodes_lst[[i]]$y[match(edges_lst[[i]]$to, nodes_lst[[i]]$name)]\n        edges_lst[[i]]$id &lt;- paste0(edges_lst[[i]]$from, \"-\", edges_lst[[i]]$to)\n        edges_lst[[i]]$status &lt;- TRUE\n        edges_lst[[i]]\n    })\n\n    all_edges &lt;- do.call(\"rbind\", lapply(gList, get.edgelist))\n    all_edges &lt;- all_edges[!duplicated(all_edges), ]\n    all_edges &lt;- cbind(all_edges, paste0(all_edges[, 1], \"-\", all_edges[, 2]))\n\n    edges_lst &lt;- lapply(1:length(gList), function(i) {\n        idx &lt;- which(!all_edges[, 3] %in% edges_lst[[i]]$id)\n        if (length(idx != 0)) {\n            tmp &lt;- data.frame(from = all_edges[idx, 1], to = all_edges[idx, 2], id = all_edges[idx, 3])\n            tmp$x &lt;- nodes_lst[[i]]$x[match(tmp$from, nodes_lst[[i]]$name)]\n            tmp$y &lt;- nodes_lst[[i]]$y[match(tmp$from, nodes_lst[[i]]$name)]\n            tmp$xend &lt;- nodes_lst[[i]]$x[match(tmp$to, nodes_lst[[i]]$name)]\n            tmp$yend &lt;- nodes_lst[[i]]$y[match(tmp$to, nodes_lst[[i]]$name)]\n            tmp$frame &lt;- i\n            tmp$status &lt;- FALSE\n            idy &lt;- which(!names(edges_lst[[i]]) %in% names(tmp))\n            if (length(idy) &gt; 0) {\n                tmp[names(edges_lst[[i]])[idy]] &lt;- NA\n            }\n            edges_lst[[i]] &lt;- rbind(edges_lst[[i]], tmp)\n        }\n        edges_lst[[i]]\n    })\n\n    edges_df &lt;- do.call(\"rbind\", edges_lst)\n    nodes_df &lt;- do.call(\"rbind\", nodes_lst)\n    list(nodes = nodes_df, edges = edges_df)\n}\n\n#| label: build\nedges_df &lt;- do.call(\"rbind\", edges_lst)\nnodes_df &lt;- do.call(\"rbind\", nodes_lst)\n\ndat &lt;- aninet(s50)\nAnd that’s it in terms of data wrangling. All that is left is to plot/animate the data.\nggplot() +\n  geom_segment(\n    data = dat$edges_df,\n    aes(x = x, xend = xend, y = y, yend = yend, group = id, alpha = status),\n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = dat$nodes_df, aes(x, y, group = name, fill = as.factor(smoke)),\n    shape = 21, size = 4, show.legend = FALSE\n  ) +\n  scale_fill_manual(values = c(\"forestgreen\", \"grey25\", \"firebrick\")) +\n  scale_alpha_manual(values = c(0, 1)) +\n  ease_aes(\"quadratic-in-out\") +\n  transition_states(frame, state_length = 0.5, wrap = FALSE) +\n  labs(title = \"Wave {closest_state}\") +\n  theme_void()",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Advanced Layouts</span>"
    ]
  },
  {
    "objectID": "ggraph-advanced.html#multilevel-networks",
    "href": "ggraph-advanced.html#multilevel-networks",
    "title": "9  Advanced Layouts",
    "section": "9.5 Multilevel networks",
    "text": "9.5 Multilevel networks\nIn this section, you will get to know layout_as_multilevel(), a layout algorithm in the raphlayouts package which can be use to visualize multilevel networks.\nA multilevel network consists of two (or more) levels with different node sets and intra-level ties. For instance, one level could be scientists and their collaborative ties and the second level are labs and ties among them, and inter-level edges are the affiliations of scientists and labs.\nThe graphlayouts package contains an artificial multilevel network which will be used to illustrate the algorithm.\n\ndata(\"multilvl_ex\")\n\nThe package assumes that a multilevel network has a vertex attribute called lvl which holds the level information (1 or 2).\nThe underlying algorithm of layout_as_multilevel() has three different versions, which can be used to emphasize different structural features of a multilevel network.\nIndependent of which option is chosen, the algorithm internally produces a 3D layout, where each level is positioned on a different y-plane. The 3D layout is then mapped to 2D with an isometric projection. The parameters alpha and beta control the perspective of the projection. The default values seem to work for many instances, but may not always be optimal. As a rough guideline: beta rotates the plot around the y axis (in 3D) and alpha moves the POV up or down.\n\n9.5.1 Complete layout\nA layout for the complete network can be computed via layout_as_multilevel() setting type = \"all\". Internally, the algorithm produces a constrained 3D stress layout (each level on a different y plane) which is then projected to 2D. This layout ignores potential differences in each level and optimizes only the overall layout.\n\nxy &lt;- layout_as_multilevel(multilvl_ex, type = \"all\", alpha = 25, beta = 45)\n\nTo visualize the network with ggraph, you may want to draw the edges for each level (and inter level edges) with a different edge geom. This gives you more flexibility to control aesthetics and can easily be achieved with a filter.\n\nggraph(multilvl_ex, \"manual\", x = xy[, 1], y = xy[, 2]) +\n    geom_edge_link0(\n        aes(filter = (node1.lvl == 1 & node2.lvl == 1)),\n        edge_colour = \"firebrick3\",\n        alpha = 0.5,\n        edge_linewidth = 0.3\n    ) +\n    geom_edge_link0(\n        aes(filter = (node1.lvl != node2.lvl)),\n        alpha = 0.3,\n        edge_linewidth = 0.1,\n        edge_colour = \"black\"\n    ) +\n    geom_edge_link0(\n        aes(filter = (node1.lvl == 2 &\n            node2.lvl == 2)),\n        edge_colour = \"goldenrod3\",\n        edge_linewidth = 0.3,\n        alpha = 0.5\n    ) +\n    geom_node_point(aes(shape = as.factor(lvl)), fill = \"grey25\", size = 3) +\n    scale_shape_manual(values = c(21, 22)) +\n    theme_graph() +\n    coord_cartesian(clip = \"off\", expand = TRUE) +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n9.5.2 Separate layouts for both levels\nIn many instances, there may be different structural properties inherent to the levels of the network. In that case, two layout functions can be passed to layout_as_multilevel() to deal with these differences. In our artificial network, level 1 has a hidden group structure and level 2 has a core-periphery structure.\nTo use this layout option, set type = \"separate\" and specify two layout functions with FUN1 and FUN2. You can change internal parameters of these layout functions with named lists in the params1 and params2 argument. Note that this version optimizes inter-level edges only minimally. The emphasis is on the intra-level structures.\n\nxy &lt;- layout_as_multilevel(multilvl_ex,\n    type = \"separate\",\n    FUN1 = layout_as_backbone,\n    FUN2 = layout_with_stress,\n    alpha = 25, beta = 45\n)\n\nAgain, try to include an edge geom for each level.\n\ncols2 &lt;- c(\n    \"#3A5FCD\", \"#CD00CD\", \"#EE30A7\", \"#EE6363\",\n    \"#CD2626\", \"#458B00\", \"#EEB422\", \"#EE7600\"\n)\n\nggraph(multilvl_ex, \"manual\", x = xy[, 1], y = xy[, 2]) +\n    geom_edge_link0(\n        aes(\n            filter = (node1.lvl == 1 & node2.lvl == 1),\n            edge_colour = col\n        ),\n        alpha = 0.5, edge_linewidth = 0.3\n    ) +\n    geom_edge_link0(\n        aes(filter = (node1.lvl != node2.lvl)),\n        alpha = 0.3,\n        edge_linewidth = 0.1,\n        edge_colour = \"black\"\n    ) +\n    geom_edge_link0(\n        aes(\n            filter = (node1.lvl == 2 & node2.lvl == 2),\n            edge_colour = col\n        ),\n        edge_linewidth = 0.3, alpha = 0.5\n    ) +\n    geom_node_point(aes(\n        fill = as.factor(grp),\n        shape = as.factor(lvl),\n        size = nsize\n    )) +\n    scale_shape_manual(values = c(21, 22)) +\n    scale_size_continuous(range = c(1.5, 4.5)) +\n    scale_fill_manual(values = cols2) +\n    scale_edge_color_manual(values = cols2, na.value = \"grey12\") +\n    scale_edge_alpha_manual(values = c(0.1, 0.7)) +\n    theme_graph() +\n    coord_cartesian(clip = \"off\", expand = TRUE) +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n9.5.3 Fix only one level\nThis layout can be used to emphasize one intra-level structure. The layout of the second level is calculated in a way that optimizes inter-level edge placement. Set type = \"fix1\" and specify FUN1 and possibly params1 to fix level 1 or set type = \"fix2\" and specify FUN2 and possibly params2 to fix level 2.\n\nxy &lt;- layout_as_multilevel(multilvl_ex,\n    type = \"fix2\",\n    FUN2 = layout_with_stress,\n    alpha = 25, beta = 45\n)\n\nggraph(multilvl_ex, \"manual\", x = xy[, 1], y = xy[, 2]) +\n    geom_edge_link0(\n        aes(\n            filter = (node1.lvl == 1 & node2.lvl == 1),\n            edge_colour = col\n        ),\n        alpha = 0.5, edge_linewidth = 0.3\n    ) +\n    geom_edge_link0(\n        aes(filter = (node1.lvl != node2.lvl)),\n        alpha = 0.3,\n        edge_linewidth = 0.1,\n        edge_colour = \"black\"\n    ) +\n    geom_edge_link0(\n        aes(\n            filter = (node1.lvl == 2 & node2.lvl == 2),\n            edge_colour = col\n        ),\n        edge_linewidth = 0.3, alpha = 0.5\n    ) +\n    geom_node_point(aes(\n        fill = as.factor(grp),\n        shape = as.factor(lvl),\n        size = nsize\n    )) +\n    scale_shape_manual(values = c(21, 22)) +\n    scale_size_continuous(range = c(1.5, 4.5)) +\n    scale_fill_manual(values = cols2) +\n    scale_edge_color_manual(values = cols2, na.value = \"grey12\") +\n    scale_edge_alpha_manual(values = c(0.1, 0.7)) +\n    theme_graph() +\n    coord_cartesian(clip = \"off\", expand = TRUE) +\n    theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n9.5.4 3D with threejs\nInstead of the default 2D projection, layout_as_multilevel() can also return the 3D layout by setting project2d = FALSE. The 3D layout can then be used with e.g. threejs to produce an interactive 3D visualization.\n\nlibrary(threejs)\nxyz &lt;- layout_as_multilevel(multilvl_ex,\n    type = \"separate\",\n    FUN1 = layout_as_backbone,\n    FUN2 = layout_with_stress,\n    project2D = FALSE\n)\nmultilvl_ex$layout &lt;- xyz\nV(multilvl_ex)$color &lt;- c(\"#00BFFF\", \"#FF69B4\")[V(multilvl_ex)$lvl]\nV(multilvl_ex)$vertex.label &lt;- V(multilvl_ex)$name\n\ngraphjs(multilvl_ex, bg = \"black\", vertex.shape = \"sphere\")",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Advanced Layouts</span>"
    ]
  },
  {
    "objectID": "enhance-viz.html",
    "href": "enhance-viz.html",
    "title": "10  Enhancing Visualizations",
    "section": "",
    "text": "10.1 use the ggforce\nThe ggforce package works pretty nicely with ggraph. You can, for instance, use the geom_mark_*() functions to highlight clusters.\nset.seed(665)\n\n## create network with a group structure\ng &lt;- sample_islands(9, 40, 0.4, 15)\ng &lt;- igraph::simplify(g)\nV(g)$grp &lt;- as.character(rep(1:9, each = 40))\n\nbb &lt;- layout_as_backbone(g, keep = 0.4)\nE(g)$col &lt;- F\nE(g)$col[bb$backbone] &lt;- T\nggraph(g, #|\n    layout = \"manual\",\n    x = bb$xy[, 1],\n    y = bb$xy[, 2]\n) +\n    geom_edge_link0(aes(col = col), width = 0.2) +\n    geom_node_point(aes(fill = grp), shape = 21, size = 3) +\n    geom_mark_hull(\n        aes(x, y, group = grp, fill = grp),\n        concavity = 4,\n        expand = unit(2, \"mm\"),\n        alpha = 0.25\n    ) +\n    scale_color_brewer(palette = \"Set1\") +\n    scale_fill_brewer(palette = \"Set1\") +\n    scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +\n    theme_graph() +\n    theme(legend.position = \"none\")\nOf course you can also add a label to your clusters.\nggraph(g, #|\n    layout = \"manual\",\n    x = bb$xy[, 1],\n    y = bb$xy[, 2]\n) +\n    geom_edge_link0(aes(col = col), width = 0.2) +\n    geom_node_point(aes(fill = grp), shape = 21, size = 3) +\n    geom_mark_hull(\n        aes(x, y, group = grp, fill = grp, label = grp),\n        concavity = 4,\n        expand = unit(2, \"mm\"),\n        alpha = 0.25\n    ) +\n    scale_color_brewer(palette = \"Set1\") +\n    scale_fill_brewer(palette = \"Set1\") +\n    scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +\n    theme_graph() +\n    theme(legend.position = \"none\")\nIf you want to avoid node overlaps, you can use geom_node_voronoi(). So this is actually already implemented in ggraph, but originates from geom_voronoi_tile().\nggraph(g,\n    layout = \"manual\",\n    x = bb$xy[, 1],\n    y = bb$xy[, 2]\n) +\n    geom_edge_link0(aes(filter = !col, col = col), width = 0.2) +\n    geom_node_voronoi(\n        aes(x, y, fill = grp),\n        max.radius = 0.4,\n        expand = unit(-0.5, \"mm\"),\n        colour = \"black\"\n    ) +\n    scale_color_brewer(palette = \"Set1\") +\n    scale_fill_brewer(palette = \"Set1\") +\n    scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +\n    theme(\n        legend.position = \"none\",\n        panel.grid = element_blank(),\n        axis.ticks = element_blank(),\n        axis.text = element_blank()\n    ) +\n    theme_graph() +\n    theme(legend.position = \"none\")",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Enhancing Visualizations</span>"
    ]
  },
  {
    "objectID": "enhance-viz.html#small-tricks-for-common-problems",
    "href": "enhance-viz.html#small-tricks-for-common-problems",
    "title": "10  Enhancing Visualizations",
    "section": "10.2 Small tricks for common problems",
    "text": "10.2 Small tricks for common problems\n\n“How can I achieve that my directed edges stop at the node border, independent from the node size?”\n\nThis one has given me headaches for the longest time. No matter what I tried, I always ended up with something like the below plot.\n\n## create a random network\nset.seed(1071)\ng &lt;- sample_pa(30, 1)\nV(g)$degree &lt;- degree(g, mode = \"in\")\n\nggraph(g, \"stress\") +\n    geom_edge_link(\n        aes(end_cap = circle(node2.degree + 2, \"pt\")),\n        edge_colour = \"black\",\n        arrow = arrow(\n            angle = 10,\n            length = unit(0.15, \"inches\"),\n            ends = \"last\",\n            type = \"closed\"\n        )\n    ) +\n    geom_node_point(aes(size = degree), col = \"grey66\", show.legend = FALSE) +\n    scale_size(range = c(3, 11)) +\n    theme_graph()\n\n\n\n\n\n\n\n\nThe overlap can be avoided by using the I() function from base R, which treats the entries of a vector “as is”. So we know that if a node has degree 5, it will be mapped to a circle with radius (or diameter?) “5pt”. Since this means, that you have no control over the scaling, you need to do that beforehand.\n\n## this function is borrowed from the ambient package\nnormalise &lt;- function(x, from = range(x), to = c(0, 1)) {\n    x &lt;- (x - from[1]) / (from[2] - from[1])\n    if (!identical(to, c(0, 1))) {\n        x &lt;- x * (to[2] - to[1]) + to[1]\n    }\n    x\n}\n\n## map to the range you want\nV(g)$degree &lt;- normalise(V(g)$degree, to = c(3, 11))\n\nggraph(g, \"stress\") +\n    geom_edge_link(\n        aes(end_cap = circle(node2.degree + 2, \"pt\")),\n        edge_colour = \"grey25\",\n        arrow = arrow(\n            angle = 10,\n            length = unit(0.15, \"inches\"),\n            ends = \"last\",\n            type = \"closed\"\n        )\n    ) +\n    geom_node_point(aes(size = I(degree)), col = \"grey66\") +\n    theme_graph()\n\n\n\n\n\n\n\n\nI would not be surprised though if there is an even easier fix for this problem.\n\n“How can I lower the opacity of nodes without making edges visible underneath?”\n\nOne of the rules I try to follow is that edges should not be visible on top of nodes. Usually that is easy to achieve by drawing the edges before the nodes. But if you want to lower the opacity of nodes, they do become visible again.\n\ng &lt;- sample_gnp(20, 0.5)\nV(g)$degree &lt;- degree(g)\n\nggraph(g, \"stress\") +\n    geom_edge_link(edge_colour = \"grey66\") +\n    geom_node_point(\n        size = 8,\n        aes(alpha = degree),\n        col = \"red\",\n        show.legend = FALSE\n    ) +\n    theme_graph()\n\n\n\n\n\n\n\n\nThe solution is rather simple. Just add a node layer with the same aesthetics below with alpha=1 (default) and color=\"white\" (or the background color of the plot).\n\nggraph(g, \"stress\") +\n    geom_edge_link(edge_colour = \"grey66\") +\n    geom_node_point(size = 8, col = \"white\") +\n    geom_node_point(\n        aes(alpha = degree),\n        size = 8,\n        col = \"red\",\n        show.legend = FALSE\n    ) +\n    theme_graph()\n\n\n\n\n\n\n\n\nOf course you could also use start_cap and end_cap here, but you may have to fiddle again as in the last example.\n\n“How can I enhance readability of node labels in hairball graphs?”\n\nSometimes it is really hard to make labels readable when the network is very cluttered\n\ng &lt;- sample_gnp(50, 0.7)\nV(g)$name &lt;- sapply(1:50, function(x) paste0(sample(LETTERS, 4), collapse = \"\"))\nE(g)$weight &lt;- runif(ecount(g))\n\nggraph(g) +\n    geom_edge_link0(aes(edge_color = weight, edge_linewidth = weight), show.legend = FALSE) +\n    geom_node_point(size = 8, color = \"#44a6c6\") +\n    geom_node_text(aes(label = name), fontface = \"bold\") +\n    scale_edge_color_continuous(low = \"grey66\", high = \"black\") +\n    scale_edge_width(range = c(0.1, 0.5)) +\n    theme_graph() +\n    coord_fixed()\n\nUsing \"stress\" as default layout\n\n\n\n\n\n\n\n\n\nHere you can make use of the fact that the layout of the nodes are stored in a “hidden” data frame when a ggraph object is constructed. That means you can use other geoms from other packages. In this case, the shadowtext package as shown below.\n\nggraph(g, \"stress\") +\n    geom_edge_link0(aes(edge_color = weight, edge_linewidth = weight), show.legend = FALSE) +\n    geom_node_point(size = 8, color = \"#44a6c6\") +\n    shadowtext::geom_shadowtext(aes(x, y, label = name), color = \"black\", size = 4, bg.colour = \"white\") +\n    scale_edge_color_continuous(low = \"grey66\", high = \"black\") +\n    scale_edge_width(range = c(0.1, 0.5)) +\n    theme_graph() +\n    coord_fixed()",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Enhancing Visualizations</span>"
    ]
  },
  {
    "objectID": "enhance-viz.html#edge-bundling",
    "href": "enhance-viz.html#edge-bundling",
    "title": "10  Enhancing Visualizations",
    "section": "10.3 Edge bundling",
    "text": "10.3 Edge bundling\n\ngr &lt;- edgebundle::us_flights\nstates &lt;- map_data(\"state\")\n\nggraph(gr, x = longitude, y = latitude) +\n    geom_polygon(aes(long, lat, group = group), states, color = \"white\", linewidth = 0.2) +\n    coord_sf(crs = \"NAD83\", default_crs = sf::st_crs(4326)) +\n    geom_edge_bundle_force(color = \"white\", width = 0.05)\n\n\n\n\n\n\n\nFigure 10.1\n\n\n\n\n\n\nggraph(gr, x = longitude, y = latitude) +\n    geom_polygon(aes(long, lat, group = group), states, color = \"white\", linewidth = 0.2) +\n    coord_sf(crs = \"NAD83\", default_crs = sf::st_crs(4326)) +\n    geom_edge_bundle_path(color = \"white\", width = 0.05)\n\n\n\n\n\n\n\nFigure 10.2",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Enhancing Visualizations</span>"
    ]
  },
  {
    "objectID": "enhance-viz.html#snahelper",
    "href": "enhance-viz.html#snahelper",
    "title": "10  Enhancing Visualizations",
    "section": "10.4 snahelper",
    "text": "10.4 snahelper\nEven with a lot of experience, it may still be a painful process to produce nice looking figures by writing ggraph code. Enter the snahelper.\ninstall.packages(\"snahelper\")\nThe snahelper is an RStudio addin which provides you with a GUI to plot networks. Instead of writing code, you simply use drop-down menus to assign attributes to aesthetics or change appearances globally. One great feature of the addin is that you can adjust the position of nodes individually if you are not satisfied with their location. Once you are done, you can either directly export the figure to png or automatically insert the code to produce the figure into your script. That way, you can review the code and hopefully learn something from it. Below if a demo that shows its functionality.\n\nTo use the addin, simply highlight the variable name of your network within an R script and choose the SNAhelper from the Addins drop-down menu within RStudio. You can find more about the Addin on its dedicated pkgdown page",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Enhancing Visualizations</span>"
    ]
  },
  {
    "objectID": "enhance-viz.html#misc",
    "href": "enhance-viz.html#misc",
    "title": "10  Enhancing Visualizations",
    "section": "10.5 Misc",
    "text": "10.5 Misc\nSome things that I frequently use are the following:\n\nchange the end_cap in geom_edge_link() to end edges before reaching the node. This is helpful for directed edges to not make the arrows disappear.\nlegend.position in theme() controls all legends at once. If you don’t want to show a specific legend, use guide = \"none\" in the respective scale_* function.\nuse scale_color_viridis_c() and scale_color_viridis_d(). The viridis colour palette makes plots easier to read by those with colorblindness and print well in grey scale.",
    "crumbs": [
      "Network Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Enhancing Visualizations</span>"
    ]
  },
  {
    "objectID": "tidygraph.html",
    "href": "tidygraph.html",
    "title": "Tidy Network Analysis",
    "section": "",
    "text": "Required libraries\nTo run all the code in this part, you need to install and load two packages.\ntidygraph implements the tidy approach for network analysis. networkdata contains a diverse set of network dataset.\nlibrary(tidygraph)\n\n\nAttaching package: 'tidygraph'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nlibrary(networkdata)\nMake sure you have at least the version given below. Some of the examples may not be backward compatible.\npackageVersion(\"tidygraph\")\n\n[1] '1.3.0'\n\npackageVersion(\"networkdata\")\n\n[1] '0.2.0'",
    "crumbs": [
      "Tidy Network Analysis"
    ]
  },
  {
    "objectID": "tidygraph.html#required-libraries",
    "href": "tidygraph.html#required-libraries",
    "title": "Tidy Network Analysis",
    "section": "",
    "text": "install.packages(\"tidygraph\")\ndevtools::install_github(\"schochastics/networkdata\")",
    "crumbs": [
      "Tidy Network Analysis"
    ]
  },
  {
    "objectID": "tidygraph.html#what-is-tidy-network-data",
    "href": "tidygraph.html#what-is-tidy-network-data",
    "title": "Tidy Network Analysis",
    "section": "What is tidy network data?",
    "text": "What is tidy network data?\nOn first glance, there is not much tidiness in networks or the ways it is usually encoded, like a graph, adjacency matrix, edgelist, etc. How should this fit into a single data frame? If you are an avid igraph user, then you may suspect the answer. It doesn’t fit, but it fits in two with graph_from_data_frame() which takes two data frames, one for nodes and one for edges, as input. In other words, we can represent a network as two separate data frames. One for the nodes and node attributes, and one for the edges and edge attributes. Working with these two data frames together is the premise for the tidygraph package. If you are interested in more technical details on how this is implemented under the hood, see the introductory blog post for the package.",
    "crumbs": [
      "Tidy Network Analysis"
    ]
  },
  {
    "objectID": "tidygraph.html#why-tidy-network-data",
    "href": "tidygraph.html#why-tidy-network-data",
    "title": "Tidy Network Analysis",
    "section": "Why tidy network data?",
    "text": "Why tidy network data?\nThis is a good question. If you aren’t a fan of the tidyverse, then you should probably move along and stick with established packages such as igraph or sna which offer the exact same functionalities (tidygraph actually imports most of igraph). If you appreciate the tidyverse, then there is no need for convincing you that this is a good idea. If you are indifferent, then I hope I can make a case for the tidy framework below. To start off with, the package does a great job to harmonize many network analytic tasks. For instance, you do not need to know all the different centrality indices that are implemented. You simply type centrality_ and press tab in the RStudio console and get all functions that allow the calculation of a centrality index. Other node level functions are accessible via node_*() and edge level measures via edge_*().",
    "crumbs": [
      "Tidy Network Analysis"
    ]
  },
  {
    "objectID": "tidygraph-basics.html",
    "href": "tidygraph-basics.html",
    "title": "12  Basics of tidygraph",
    "section": "",
    "text": "12.1 Graph structures\nWe’ll use the famous Florentine Family marriage dataset as a running example. The dataset is in igraph format but can be converted to a tbl_graph object with as_tbl_graph().\ndata(\"flo_marriage\")\nflo_tidy &lt;- as_tbl_graph(flo_marriage)\nflo_tidy\n\nThis graph was created by an old(er) igraph version.\n  Call upgrade_graph() on it to use with the current igraph version\n  For now we convert it on the fly...\n\n\n# A tbl_graph: 16 nodes and 20 edges\n#\n# An undirected simple graph with 2 components\n#\n# Node Data: 16 × 4 (active)\n   name         wealth `#priors` `#ties`\n   &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 Acciaiuoli       10        53       2\n 2 Albizzi          36        65       3\n 3 Barbadori        55         0      14\n 4 Bischeri         44        12       9\n 5 Castellani       20        22      18\n 6 Ginori           32         0       9\n 7 Guadagni          8        21      14\n 8 Lamberteschi     42         0      14\n 9 Medici          103        53      54\n10 Pazzi            48         0       7\n11 Peruzzi          49        42      32\n12 Pucci             3         0       1\n13 Ridolfi          27        38       4\n14 Salviati         10        35       5\n15 Strozzi         146        74      29\n16 Tornabuoni       48         0       7\n#\n# Edge Data: 20 × 2\n   from    to\n  &lt;int&gt; &lt;int&gt;\n1     1     9\n2     2     6\n3     2     7\n# ℹ 17 more rows\nThis new graph class just subclasses igraph and simply represents the network in a tidy fashion, printing two data frames, one for nodes and one for edges.\nclass(flo_tidy)\n\n[1] \"tbl_graph\" \"igraph\"\nAny function in R that expects an igraph object as input will also accept a tbl_graph.\nThe function tbl_graph() can be used to create a network from scratch with two data frames. It is basically equivalent to graph_from_data_frame().\nTo create random graphs with the usual generators, check out the create_*() and play_*() families of functions.",
    "crumbs": [
      "Tidy Network Analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Basics of tidygraph</span>"
    ]
  },
  {
    "objectID": "tidygraph-basics.html#standard-verbs",
    "href": "tidygraph-basics.html#standard-verbs",
    "title": "12  Basics of tidygraph",
    "section": "12.2 Standard verbs",
    "text": "12.2 Standard verbs\nThe tidy framework, specifically thinking about dplyr, is about providing verbs which help to solve common data manipulation tasks, such as mutate(), select(), filter(), and summarise(). The challange for the tbl_graph objects is that these verbs somehow need to work with two different data frames. The way tidygraph solves this is via a pointer to the data frame which is supposed to be manipulated. This pointer can be changed with the verb activate(). By default the nodes are activated, which can also be seen with the print function (see line 5 in the output of flo_tidy). To activate the edge data frame, simply use activate(\"edges\").\n\nflo_tidy %&gt;% activate(\"edges\")\n\n# A tbl_graph: 16 nodes and 20 edges\n#\n# An undirected simple graph with 2 components\n#\n# Edge Data: 20 × 2 (active)\n    from    to\n   &lt;int&gt; &lt;int&gt;\n 1     1     9\n 2     2     6\n 3     2     7\n 4     2     9\n 5     3     5\n 6     3     9\n 7     4     7\n 8     4    11\n 9     4    15\n10     5    11\n11     5    15\n12     7     8\n13     7    16\n14     9    13\n15     9    14\n16     9    16\n17    10    14\n18    11    15\n19    13    15\n20    13    16\n#\n# Node Data: 16 × 4\n  name       wealth `#priors` `#ties`\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 Acciaiuoli     10        53       2\n2 Albizzi        36        65       3\n3 Barbadori      55         0      14\n# ℹ 13 more rows\n\n\nAny data manipulation would now be done on the edge data frame.\nHaving “activated” a data frame, many of the known dplyr verbs can be used to manipulate the data frame. The activation process might indicate that edges and nodes can only be manipulated separately, which is certainly not desirable. It is, however, possible to gain access to the edge data frame when nodes are activated via the .E(). Similarly, nodes can be accessed via .N() when edges are activated. In the below example, we activate the edges and create a new edge attribute which indicates if a family is connected to the Medici or not.\n\nflo_tidy &lt;- flo_tidy %&gt;% \n  activate(\"edges\") %&gt;% \n  mutate(to_medici=(.N()$name[from]==\"Medici\" | .N()$name[to]==\"Medici\"))\n\nThis particular use case is helpful for visualizations.\n\nggraph(flo_tidy, \"stress\") +\n    geom_edge_link0(aes(edge_color = to_medici)) +\n    geom_node_point(shape = 21, size = 10, fill = \"grey66\") +\n    geom_node_text(aes(label = name)) +\n    theme_graph()\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\n\n\n\nThe dplyr verb filter() can be used to obtain a subgraph that satisfies given conditions on the nodes. Note that in the case that you filter on nodes, also edges will be effected. If a node does not satisfy the condition, then all edges connected to that node disappear. This is not the case for edges though.\n\nflo_tidy %&gt;%\n    activate(\"edges\") %&gt;%\n    filter(to_medici) %&gt;%\n    ggraph(\"stress\", bbox = 10) +\n    geom_edge_link0(edge_color = \"black\") +\n    geom_node_point(shape = 21, size = 10, fill = \"grey66\") +\n    geom_node_text(aes(label = name)) +\n    theme_graph()",
    "crumbs": [
      "Tidy Network Analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Basics of tidygraph</span>"
    ]
  },
  {
    "objectID": "tidygraph-basics.html#joins",
    "href": "tidygraph-basics.html#joins",
    "title": "12  Basics of tidygraph",
    "section": "12.3 Joins",
    "text": "12.3 Joins",
    "crumbs": [
      "Tidy Network Analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Basics of tidygraph</span>"
    ]
  },
  {
    "objectID": "tidygraph-basics.html#new-verbs",
    "href": "tidygraph-basics.html#new-verbs",
    "title": "12  Basics of tidygraph",
    "section": "12.4 New Verbs",
    "text": "12.4 New Verbs",
    "crumbs": [
      "Tidy Network Analysis",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Basics of tidygraph</span>"
    ]
  },
  {
    "objectID": "tidygraph-descriptive.html",
    "href": "tidygraph-descriptive.html",
    "title": "13  Descriptive Network Analysis",
    "section": "",
    "text": "13.1 Centrality\nThe package includes all centrality indices implemented in igraph and additionally all that are made available in the netrankr package. All indices can be found in the function group centrality_*().\nflo_tidy %&gt;%\n    activate(\"nodes\") %&gt;%\n    mutate(\n        degree = centrality_degree(),\n        betweenness = centrality_betweenness()\n    ) %&gt;%\n    ggraph(\"stress\", bbox = 10) +\n    geom_edge_link0(edge_color = \"black\") +\n    geom_node_point(shape = 21, aes(size = degree, fill = betweenness)) +\n    geom_node_text(aes(label = name)) +\n    scale_fill_gradient(low = \"#104E8B\", high = \"#CD2626\") +\n    scale_size(range = c(4, 10)) +\n    theme_graph()\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.",
    "crumbs": [
      "Tidy Network Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Descriptive Network Analysis</span>"
    ]
  },
  {
    "objectID": "tidygraph-descriptive.html#clustering",
    "href": "tidygraph-descriptive.html#clustering",
    "title": "13  Descriptive Network Analysis",
    "section": "13.2 Clustering",
    "text": "13.2 Clustering\nSimilar to centrality, all clustering algorithms from igraph are available via group_*()\n\n# create random graph with group structure (igraph equivalent is sample_islands())\nplay_islands(4, 12, 0.8, 4) %&gt;%\n    mutate(community = as.factor(group_louvain())) %&gt;%\n    ggraph(layout = \"stress\") +\n    geom_edge_link0() +\n    geom_node_point(aes(fill = community), shape = 21, size = 6) +\n    theme_graph()\n\n\n\n\n\n\n\n\nCoupling this with what we learned above, we can color the edges according to the cluster they belong to.\n\nplay_islands(4, 12, 0.8, 4) %&gt;%\n    mutate(community = as.factor(group_louvain())) %&gt;%\n    activate(\"edges\") %&gt;%\n    mutate(community = as.factor(ifelse(.N()$community[from] == .N()$community[to], .N()$community[from], 5))) %&gt;%\n    ggraph(layout = \"stress\") +\n    geom_edge_link0(aes(edge_colour = community), show.legend = FALSE) +\n    geom_node_point(aes(fill = community), shape = 21, size = 6) +\n    scale_fill_brewer(palette = \"Set3\") +\n    scale_edge_color_brewer(palette = \"Set3\") +\n    theme_graph(background = \"grey88\")",
    "crumbs": [
      "Tidy Network Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Descriptive Network Analysis</span>"
    ]
  },
  {
    "objectID": "tidygraph-descriptive.html#other-node-or-edge-level-functions",
    "href": "tidygraph-descriptive.html#other-node-or-edge-level-functions",
    "title": "13  Descriptive Network Analysis",
    "section": "13.3 Other node or edge level functions",
    "text": "13.3 Other node or edge level functions\ntidygraphs harmonizes many other available functions in igraph to make them easier accessible. The best way to check what is available is to look at the function groups node_*() and edge_*(). Some simple examples are shown below.\n\n# the node id of the Medici is 9\nflo_tidy %&gt;%\n    activate(\"nodes\") %&gt;%\n    mutate(dist2Medici = node_distance_to(nodes = 9)) %&gt;%\n    activate(\"edges\") %&gt;%\n    mutate(edge2Medici = edge_is_incident(9)) %&gt;%\n    ggraph(\"stress\") +\n    geom_edge_link0(aes(edge_color = edge2Medici)) +\n    geom_node_point(aes(fill = dist2Medici), size = 9, shape = 21) +\n    theme_graph()",
    "crumbs": [
      "Tidy Network Analysis",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Descriptive Network Analysis</span>"
    ]
  },
  {
    "objectID": "tidygraph-summary.html",
    "href": "tidygraph-summary.html",
    "title": "14  Summary",
    "section": "",
    "text": "The tidy framework works well in general but there are some shortcomings. So far, only basic network analytic methods are supported. This is enough for many tasks but as soon as more advanced techniques are needed, you are forced to switch to the “untidy” way again. A lot of coding but also conceptual work is needed to advance the framework further. For instance, how do ERGMs or SAOMs fit into this? Maybe there is a way to use tidymodels, but that is beyond the scope for now.",
    "crumbs": [
      "Tidy Network Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "15  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Summary</span>"
    ]
  }
]