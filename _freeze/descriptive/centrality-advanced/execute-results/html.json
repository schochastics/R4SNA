{
  "hash": "9db15ac8c1ef4268fcbda53369c5bee4",
  "result": {
    "engine": "knitr",
    "markdown": "# Advanced Centrality Concepts\n\nWhen looking at the vast amount of centrality indices, it may be reasonable to ask\nif there is any natural limit for what can be considered a centrality\nindex. Concretely, are there any theoretical properties that an index\nhas to have in order to be called a centrality index? There exist\nseveral axiomatic systems for centrality, which define some desirable\nproperties that a proper index should have. While these systems are able\nto shed some light on specific groups of indices, they are in most cases\nnot comprehensive. That is, it is often possible to construct\ncounterexamples for most indices such that they do not fulfill the\nproperties. Instead of the rather normative axiomatic approach, we\nexplore a more descriptive approach. We will address the following\nquestions:\n\n-   Are there any properties that are shared by all (or almost all)\n    indices?\n-   If so, can they be exploited for a different kind of centrality\n    analysis?\n\n\n## Packages Needed for this Chapter\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(igraph)\nlibrary(netrankr)\n```\n:::\n\n\n\n\n## Neighborhood-inclusion\n\nLet us start by looking at the following two small examples.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng1 <- readRDS(\"data/example_1.rds\")\ng2 <- readRDS(\"data/example_2.rds\")\n```\n:::\n\n\n\n\n[PLOT]\n\n[APPLY INDICES]\n\nIt turns out that there actually is a very intuitive structural property\nthat underlies many centrality indices. If a node has exactly the same\nneighbors as another and potentially some more, it will never be less\ncentral, independent of the choice of index. This property is called\n*neighborhood-inclusion*. \n\nAn illustration is given below.\n![](img/neighborhood_inclusion.png) \n\nWe can calculate all pairs of neighborhood-inclusion with the function\n`neighborhood_inclusion()` in the `netrankr` package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nP1 <- neighborhood_inclusion(g1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThis graph was created by an old(er) igraph version.\nℹ Call `igraph::upgrade_graph()` on it to use with the current igraph version.\nFor now we convert it on the fly...\n```\n\n\n:::\n\n```{.r .cell-code}\nP2 <- neighborhood_inclusion(g2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThis graph was created by an old(er) igraph version.\nℹ Call `igraph::upgrade_graph()` on it to use with the current igraph version.\nFor now we convert it on the fly...\n```\n\n\n:::\n:::\n\n\n\n\nAn entry `P[i,j]` is one if the neighborhood of `i` is included in the neighborhood of `j` and zero otherwise. With the function `comparable_pairs()`, we can check the\nfraction of comparable pairs. Let us start with the first network.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomparable_pairs(P1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1636364\n```\n\n\n:::\n:::\n\n\n\n\nOnly 16% of pairs are comparable with neighborhood-inclusion. For a\nbetter understanding of the dominance relations, we can also visualize\nthem as a graph.\n\n``` r\nd1 <- dominance_graph(P1)\n```\n\n![](exampledom1-1.png) \n\nAn edge `(i,j)` is\npresent, if `P[i,j]=1`. Centrality indices will always put\nthese comparable pairs in the same order. \n\n[ADD EXAMPLE WITH INDEX PRESERVATION]\n\nMoving on to the second network.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomparable_pairs(P2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n\n\n\nSo all pairs are comparable by neighborhood-inclusion. Hence, all\nindices will induce the same ranking (up to some potential tied ranks,\nbut no discordant pairs), as we already observed in the previous post.\n\n## Threshold graphs and correlation among indices\n\nThe second example network is part of the class of *threshold graphs*.\nOne of their defining features is that the partial ranking induced by\nneighborhood-inclusion is in fact a ranking. A random threshold graph\ncan be created with the `threshold_graph()` function. The function takes\ntwo parameters, one for the number of nodes, and one (approximately) for\nthe density. The class includes some well known graphs, such as the two\nbelow.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntg1 <- threshold_graph(n = 10, p = 1)\ntg2 <- threshold_graph(n = 10, p = 0)\n```\n:::\n\n\n\n\n![](img/threshold_exs_plot-1.png)\n\nWe know from the previous section that centrality indices will always\nproduce the same ranking on these graphs. This allows us to reason about\nanother topic that is frequently investigated: correlations among\nindices. Correlations are often attributed to the definitions of\nindices. Take closeness and betweenness. On first glance, they measure\nvery different things: Being close to all nodes and being “in between”\nall nodes. Hence, we would expect them to be only weakly correlated. But\nthreshold graphs give us a reason to believe, that correlations are not\nentirely dependent on the definitions but rather on structural features\nof the network. ([This\narticle](https://www.sciencedirect.com/science/article/pii/S0378873316303690)\ngives more details and references on that topic. Let me know if you\ncan’t access it).\n\nAs an illustration, we compare betweenness and closeness on a threshold\ngraph and a threshold graph with added noise from a random graph.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#threshold graph\ntg3 <- threshold_graph(100,0.2)\n#noise graph\ngnp <- sample_gnp(100,0.01)\nA1 <- as_adjacency_matrix(tg3, sparse = FALSE)\nA2 <- as_adjacency_matrix(gnp, sparse = FALSE)\n\n#construct a noise threshold graph\ntg3_noise <- graph_from_adjacency_matrix(xor(A1,A2),mode = \"undirected\")\n\n#calculate discordant pairs for betweenness and closeness in both networks\ndisc1 <- compare_ranks(betweenness(tg3),closeness(tg3))$discordant\ndisc2 <- compare_ranks(betweenness(tg3_noise),closeness(tg3_noise))$discordant\nc(disc1,disc2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]   0 549\n```\n\n\n:::\n:::\n\n\n\n\nOn the threshold graph we do not observe any discordant pairs for the\ntwo indices. However, the little noise we added to the threshold graph\nwas enough to introduce 549 pairs of nodes that are now ranked\ndifferently. In general, we can say that\n\n*The closer a network is to be a threshold graph, the higher we expect\nthe correlation of any pair of centrality indices to be, independent of\ntheir definition.*\n\nBut how to define *being close* to a threshold graph? One obvious choice\nis to use the function `comparable_pairs()`. The more pairs are\ncomparable, the less possibilities for indices to rank the nodes\ndifferently. Hence, we are close to a unique ranking obtained for\nthreshold graphs. A second option is to use an appropriate distance\nmeasure for graphs. `netrankr` implements the so called *majorization\ngap* which operates on the degree sequences of graphs. In its essence,\nit returns the number of edges that need to be rewired, in order to turn\nan arbitrary graph into a threshold graph.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmg1 <- majorization_gap(tg3)\nmg2 <- majorization_gap(tg3_noise)\nc(mg1,mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.00000000 0.02525651\n```\n\n\n:::\n:::\n\n\n\n\nThe result is given as a fraction of the total number of edges. So 12%\nof edges need to be rewired in the noisy graph to turn it into a\nthreshold graph. To get the raw count, set `norm=FALSE`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmajorization_gap(tg3_noise,norm = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 32\n```\n\n\n:::\n:::\n\n\n\n\n\n## Partial Centrality\n\nThe function `rank_intervals()` is used to calculate the maximal and minimal possible \nrank for each node in any ranking that is in accordance with a given partial ranking. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"dbces11\")\n\n#neighborhood inclusion \nP <- neighborhood_inclusion(dbces11, sparse = FALSE)\n\nrank_intervals(P)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n node:A rank interval: [1, 6]\n node:B rank interval: [1, 9]\n node:C rank interval: [2, 9]\n node:D rank interval: [2, 11]\n node:E rank interval: [3, 11]\n node:F rank interval: [2, 11]\n node:G rank interval: [2, 11]\n node:H rank interval: [2, 11]\n node:I rank interval: [1, 11]\n node:J rank interval: [1, 11]\n node:K rank interval: [3, 11]\n```\n\n\n:::\n:::\n\n\n\n\nThe package uses the convention, that higher numerical ranks correspond to top \nranked position. The lowest possible rank is thus 1. The column `mid_point` \nshould not be confused with the *expected rank* of nodes, which is calculated\nwith the function `exact_rank_prob()`.   \n\\\nRank intervals are useful to assess the ambiguity of ranking nodes. The bigger\nthe intervals are, the more freedom exists, e.g. for centrality indices, to rank \nnodes differently.  \n\\\nThe intervals can be visualized with its own `plot()` function. The function can take a data frame of centrality scores as an additional parameter `cent_scores`. The ranks of each node for each index are then plotted within each interval.\nAgain, the higher the numerical rank the higher ranked the node is according to the index.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncent_scores <- data.frame(\n   degree=degree(dbces11),\n   betweenness=round(betweenness(dbces11),4),\n   closeness=round(closeness(dbces11),4),\n   eigenvector=round(eigen_centrality(dbces11)$vector,4))\n\nrk_int <- rank_intervals(P)\nplot(rk_int,cent_scores = cent_scores)\n```\n\n::: {.cell-output-display}\n![](centrality-advanced_files/figure-html/vis_intervals_cent-1.png){width=672}\n:::\n:::\n\n\n\n\nA small jitter effect is added to the points to reduce over-plotting.  \n\\\nNote that you may encounter situations, where ranks of centralities may fall outside of interval. This can happen in cases of ties in rankings, especially for betweenness centrality. Betweenness is, so far, the only index that does not\n*strictly* preserve neighborhood-inclusion. That is, while\n$$\nN(u)\\subseteq N[v] \\text{ and } N(v)\\not\\subseteq N[u] \\implies c(u)<c(v)\n$$\nholds for most indices, betweenness fails to fulfill this property.  \n\\\nThe intervals reduce to single points for threshold graphs, \nsince all nodes are pairwise comparable by neighborhood-inclusion.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ntg <- threshold_graph(20,0.2)\n\n#neighborhood inclusion \nP <- tg %>% neighborhood_inclusion(sparse = FALSE)\n\n#without %>% operator:\n# P <- neighborhood_inclusion(tg,sparse = FALSE)\nplot(rank_intervals(P))\n```\n\n::: {.cell-output-display}\n![](centrality-advanced_files/figure-html/tg_ri-1.png){width=672}\n:::\n:::\n\n\n\n\nThe described betweenness inconsistancy is most evident for threshold graphs as shown in\nthe rank intervals below.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncent_scores <- data.frame(\n   degree=degree(tg),\n   betweenness=round(betweenness(tg),4),\n   closeness=round(closeness(tg),4),\n   eigenvector=round(eigen_centrality(tg)$vector,4))\n\n\nplot(rank_intervals(P),cent_scores = cent_scores)\n```\n\n::: {.cell-output-display}\n![](centrality-advanced_files/figure-html/tg_ri_cent,out-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Exact Probabilities\n\nBefore calculating any probabilities consider the following example graph and\nthe rankings induced by various centrality indices, shown as rank intervals.\n\n[MORE TEXT]\n\nBut first, let us briefly look at all the return values.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- exact_rank_prob(P)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in exact_rank_prob(P): P is already a ranking.\nExpected Ranks correspond to the only possible ranking.\n```\n\n\n:::\n\n```{.r .cell-code}\nres\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of possible centrality rankings:  1 \nEquivalence Classes (max. possible): 8 (20)\n- - - - - - - - - - \nRank Probabilities (rows:nodes/cols:ranks)\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\nV1  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV2  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV3  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV4  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV5  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV6  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  1  0  0  0\nV7  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV8  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV9  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV10 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV11 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV12 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV13 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV14 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV15 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  1  0  0\nV16 0 0 1 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV17 0 0 1 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV18 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  1  0\nV19 1 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV20 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  1\n- - - - - - - - - - \nRelative Rank Probabilities (row ranked lower than col)\n    V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20\nV1   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV2   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV3   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV4   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV5   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV6   0  0  0  0  0  0  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV7   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV8   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV9   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV10  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV11  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV12  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV13  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV14  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV15  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   1   0   1\nV16  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   0   0   1   0   1\nV17  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   0   0   1   0   1\nV18  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   1\nV19  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   1   1   1   0   1\nV20  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0\n- - - - - - - - - - \nExpected Ranks (higher values are better)\n V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 \n 16  16  16  16  16  17  11  11  11  11  11  11  11  11  18   3   3  19   1  20 \n- - - - - - - - - - \nSD of Rank Probabilities\n V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 \n  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n- - - - - - - - - - \n```\n\n\n:::\n:::\n\n\n\n\nThe function returns an object of type \\emph{netrankr_full} which contains the result of a full probabilistic rank analysis.\nThe specific list entries are discussed in the following subsections.\n\n### Rank Probabilities\n\nInstead of insisting on fixed ranks of nodes as given by indices, we can use *rank probabilities*\nto assess the likelihood of certain rank. Formally, rank probabilities are simply defined as\n$$\nP(rk(u)=k)=\\frac{\\lvert \\{rk \\in  \\mathcal{R}(\\leq) \\; : \\; rk(u)=k\\} \\rvert}{\\lvert \\mathcal{R}(\\leq) \\rvert}.\n$$\nRank probabilities are given by the return value `rank.prob` of the `exact_rank_prob()`\nfunction.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp <- round(res$rank.prob,2)\nrp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\nV1  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV2  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV3  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV4  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV5  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  1  0  0  0  0\nV6  0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  1  0  0  0\nV7  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV8  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV9  0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV10 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV11 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV12 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV13 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV14 0 0 0 0 0 0 0 0 0  0  1  0  0  0  0  0  0  0  0  0\nV15 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  1  0  0\nV16 0 0 1 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV17 0 0 1 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV18 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  1  0\nV19 1 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0\nV20 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  1\n```\n\n\n:::\n:::\n\n\n\n\nEntries `rp[u,k]` correspond to $P(rk(u)=k)$.  \n\\\nThe most interesting probabilities are certainly $P(rk(u)=n)$, that is how likely\nis it for a node to be the most central.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp[,11]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 \n  0   0   0   0   0   0   1   1   1   1   1   1   1   1   0   0   0   0   0   0 \n```\n\n\n:::\n:::\n\n\n\nRecall from the previous section that we found five indices that ranked $6,7,8,10$\nand $11$ on top. The probability tell us now, how likely it is to find an index that\nrank these nodes on top. In this case, node $11$ has the highest probability to be \nthe most central node.\n\n### Relative Rank Probabilities\nIn some cases, we might not necessarily be interested in a complete ranking of nodes, \nbut only in the relative position of a subset of nodes. This idea leads to \n*relative rank probabilities*, that is formally defined as\n$$\nP(rk(u)\\leq rk(v))=\\frac{\\lvert \\{rk \\in  \\mathcal{R}(\\leq) \\; : \\; rk(u)\\leq rk(v)\\} \\rvert}{\\lvert \\mathcal{R}(\\leq) \\rvert}.\n$$\nRelative rank probabilities are given by the return value `relative.rank` of the `exact_rank_prob()`\nfunction.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrrp <- round(res$relative.rank,2)\nrrp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20\nV1   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV2   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV3   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV4   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV5   0  0  0  0  0  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV6   0  0  0  0  0  0  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV7   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV8   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV9   1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV10  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV11  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV12  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV13  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV14  1  1  1  1  1  1  0  0  0   0   0   0   0   0   1   0   0   1   0   1\nV15  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   1   0   1\nV16  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   0   0   1   0   1\nV17  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   0   0   1   0   1\nV18  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   1\nV19  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   1   1   1   0   1\nV20  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0\n```\n\n\n:::\n:::\n\n\n\n\nEntries `rrp[u,v]` correspond to $P(rk(u)\\leq rk(v))$.  \n\\\nThe more a value `rrp[u,v]` deviates from $0.5$ towards $1$, the more confidence we gain\nthat a node $v$ is more central than a node $u$.\n\n###Expected Ranks\nThe *expected rank* of a node in centrality rankings is defined as the expected \nvalue of the rank probability distribution. That is,\n$$\n\\rho(u)=\\sum_{k=1}^n k\\cdot P(rk(u)=k).\n$$\nExpected ranks are given by the return value `expected.rank` of the `exact_rank_prob()`\nfunction.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nex_rk <- round(res$expected.rank,2)\nex_rk\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 \n 16  16  16  16  16  17  11  11  11  11  11  11  11  11  18   3   3  19   1  20 \n```\n\n\n:::\n:::\n\n\n\n\nAs a reminder, the higher the numeric rank, the more central a node is. In this case,\nnode $11$ has the highest expected rank in any centrality ranking.\n\n",
    "supporting": [
      "centrality-advanced_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}