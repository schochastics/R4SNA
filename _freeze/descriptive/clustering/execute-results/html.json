{
  "hash": "353f59da1da4b2391659d6c781e835c9",
  "result": {
    "engine": "knitr",
    "markdown": "# Cohesive Subgroups\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(igraph)\nlibrary(networkdata)\n```\n:::\n\n\n\n\n\n\n## Introduction\n\nIn this chapter, we explore cohesive subgroups within networks, focusing on cliques, community detection, blockmodeling, and core-periphery structures. Each concept offers a different way to examine how nodes cluster based on connectivity, from tightly-knit cliques, where every member is connected, to broader communities grouped by denser internal links. Blockmodeling abstracts these patterns into roles and relationships, while core-periphery structures reveal hierarchical organization with central and peripheral actors.\n\n## Cliques \n\nA *clique* in a network is a set of nodes that form a complete subnetwork within a network (called a complete **subgraph**). A **maximal clique** is a clique that cannot be extended to a bigger clique by addding more nodes to it. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"clique_graph\")\n```\n:::\n\n\n\n\nAll maximal cliques can be calculated with `max_cliques()` (only feasible for fairly small networks). The min parameter can be used to set a minimum size. Here, we want to ignore all cliques of size $2$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# only return cliques with three or more nodes\ncl <- max_cliques(clique_graph, min = 3)\ncl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n+ 3/30 vertices, from 0193e05:\n[1]  9 17 18\n\n[[2]]\n+ 3/30 vertices, from 0193e05:\n[1] 7 4 5\n\n[[3]]\n+ 3/30 vertices, from 0193e05:\n[1] 7 4 8\n\n[[4]]\n+ 3/30 vertices, from 0193e05:\n[1] 10  2 11\n\n[[5]]\n+ 3/30 vertices, from 0193e05:\n[1] 16 12 15\n\n[[6]]\n+ 3/30 vertices, from 0193e05:\n[1] 6 1 5\n\n[[7]]\n+ 4/30 vertices, from 0193e05:\n[1] 12 13 15 14\n\n[[8]]\n+ 3/30 vertices, from 0193e05:\n[1] 12  2  1\n\n[[9]]\n+ 5/30 vertices, from 0193e05:\n[1] 1 2 5 4 3\n```\n\n\n:::\n:::\n\n\n\n\nThe figure below shows the network and the found maximal cliques.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/plot-clique-graph-1.png){width=672}\n:::\n:::\n\n\n\n\nRelated to cliques is the **k-core decomposition** of a network. A k-core is a subgraph in which every node has at least k neighbors within the subgraph. A k-core is thus a relaxed version of a clique.  \nThe function `coreness()` can be used to calculate the k-core membership for each node.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkcore <- coreness(clique_graph)\nkcore\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 4 4 4 4 4 3 2 2 2 2 2 3 3 3 3 3 2 2 1 1 1 1 1 1 1 1 1 1 1 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/kcore_plot-1.png){width=672}\n:::\n:::\n\n\n\n\nCliques are the prototypical and most strict definition of a cohesive subgroup in a network. In empirical networks, however, we rarely encounter situations where we can partition the whole network into a set of \ncliques. The relaxed version of this problem is that of clustering, also referred to as **comunity detection**. \n\n## Comunity detection\n\nA cluster is loosely defined as a group of nodes which are internally densely and externally sparsely connected. The network below shows an example for a network with a visible and intuitive cluster structure.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# labeL; clustered-graph\n#| echo: FALSE\n\nn1 <- 5\nn2 <- 20\nset.seed(1234)\ng <- sample_islands(n1, n2, 0.9, 5)\ng <- simplify(g)\nV(g)$grp <- rep(LETTERS[1:n1], each = n2)\nggraph(g, \"stress\") +\n    geom_edge_link0(edge_linewidth = 0.2, edge_color = \"grey66\") +\n    geom_node_point(shape = 21, size = 5, aes(fill = grp), show.legend = FALSE) +\n    theme_void()\n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n\nIn contrast, the network below does not really seem to have any well defined cluster structure.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/random-graph-1.png){width=672}\n:::\n:::\n\n\n\n\nThe following algorithms for graph clustering are implemented in `igraph`.\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"cluster_edge_betweenness\"  \"cluster_fast_greedy\"      \n [3] \"cluster_fluid_communities\" \"cluster_infomap\"          \n [5] \"cluster_label_prop\"        \"cluster_leading_eigen\"    \n [7] \"cluster_leiden\"            \"cluster_louvain\"          \n [9] \"cluster_optimal\"           \"cluster_spinglass\"        \n[11] \"cluster_walktrap\"         \n```\n\n\n:::\n:::\n\n\n\n\nMost of these algorithms are based on \"modularity maximization\". Modularity is defined as the fraction of edges that fall within given groups minus the expected fraction if edges were distributed at random.\n\nThe workflow of a cluster analysis is always the same, independent from the chosen method. We illustrate the workflow using the infamous karate club network.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"karate\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/karate-plot-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute clustering\nclu <- cluster_louvain(karate)\n\n# cluster membership vector\nmem <- membership(clu)\nmem\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 2 2 2 1 1 1 2 3 2 1 1 2 2 3 3 1 2 3 2 3 2 3 3 4 4 3 3 4 3 3 4 3 3\n```\n\n\n:::\n\n```{.r .cell-code}\n# clusters as list\ncom <- communities(clu)\ncom\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`1`\n[1]  1  5  6  7 11 12 17\n\n$`2`\n [1]  2  3  4  8 10 13 14 18 20 22\n\n$`3`\n [1]  9 15 16 19 21 23 24 27 28 30 31 33 34\n\n$`4`\n[1] 25 26 29 32\n```\n\n\n:::\n:::\n\n\n\n\nTo compare the quality of clusterings, we can compute the modularity score for each output.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimc <- cluster_infomap(karate)\nlec <- cluster_leading_eigen(karate)\nloc <- cluster_louvain(karate)\nsgc <- cluster_spinglass(karate)\nwtc <- cluster_walktrap(karate)\nscores <- c(\n    infomap = modularity(karate, membership(imc)),\n    eigen = modularity(karate, membership(lec)),\n    louvain = modularity(karate, membership(loc)),\n    spinglass = modularity(karate, membership(sgc)),\n    walk = modularity(karate, membership(wtc))\n)\nscores\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  infomap     eigen   louvain spinglass      walk \n0.4020381 0.3934089 0.4151052 0.4197896 0.3532216 \n```\n\n\n:::\n:::\n\n\n\n\nFor the karate network, `cluster_spinglass()` produces the highest modularity score.\nThe corresponding clustering is shown below.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/karate-plot-clu-1.png){width=672}\n:::\n:::\n\n\n\n\nModularity maximization is still widely considered as the state-of-the-art clustering method\nfor networks. There are, however, some technical shortcomings that one should be aware of.\nOne of those is the so called \"resolution limit\". When modularity is being maximized, it can happen\nthat smaller clusters are merged together to form bigger clusters. The prime example is the graph that\nconsists of cliques connected in a ring.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nThe figure below shows such a graph, consisting of 50 cliques of size 5. \n\n\n\n\n::: {.cell width='8' height='8'}\n::: {.cell-output-display}\n![](clustering_files/figure-html/plot-K50-blank-1.png){width=672}\n:::\n:::\n\n\n\n\nIntuitively, any clustering method should return a cluster for each clique.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclu_louvain <- cluster_louvain(K50)\ntable(membership(clu_louvain))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \n15 10 10 10 10 15 10 10 10 10 10 15 10 10 10 10 10 10 10 10 15 10 10 \n```\n\n\n:::\n:::\n\n\n\n\nA clustering algorithm that fixes this issue is the leiden algorithm.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclu_leiden <- cluster_leiden(K50, objective_function = \"CPM\", resolution_parameter = 0.5)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `resolution_parameter` argument of `cluster_leiden()` is deprecated as of\nigraph 2.1.0.\nℹ Please use the `resolution` argument instead.\n```\n\n\n:::\n\n```{.r .cell-code}\ntable(membership(clu_leiden))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n 5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 \n27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n 5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 \n```\n\n\n:::\n:::\n\n\n\n\nThe figure below shows the clusters computed with the louvain method in grey and the leiden method in red.\n\n\n\n\n::: {.cell width='8' height='8'}\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nDon't know how to automatically pick scale for object of type <membership>.\nDefaulting to continuous.\nDon't know how to automatically pick scale for object of type <membership>.\nDefaulting to continuous.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/plot-K50-clu-1.png){width=672}\n:::\n:::\n\n\n\n\nIf you are interested in the technical details of the Leiden method, check out the [original paper](https://www.nature.com/articles/s41598-019-41695-z). \n\nThe `netUtils` package includes the function `sample_lfr()` which implements the well-known [Lancichinetti–Fortunato–Radicchi benchmark algorithm](https://en.wikipedia.org/wiki/Lancichinetti%E2%80%93Fortunato%E2%80%93Radicchi_benchmark) to generate artificial networks with a priori known communities and they can be used to compare different community detection methods.\n\n## Blockmodeling\n\nBlockmodeling is a more formal approach that aims to simplify the network's structure into blocks based on patterns of connections between nodes. Instead of focusing on the density of connections, it categorizes the relationships between different groups (or blocks) of nodes according to the roles they play in the network.\n\nThe goal is to reduce the complexity of the network by identifying roles and positions within the network, where nodes in the same block have similar patterns of connections to other blocks, rather than necessarily being densely connected to each other.\n\nBlockmodeling involves partitioning the network into blocks and then modeling the connections between these blocks. It can be done through conventional (deterministic) or stochastic approaches, including k-block modeling and stochastic blockmodeling.\n\nBlockmodeling is particularly useful in sociology for role analysis and in organizational studies, where it's important to understand how different groups (e.g., departments, hierarchies) interact, regardless of the density of the connections within each group.\n\nThere are several packages that implement different kinds of (stochastic) blockmodels. The most basic approaches are implemented in the package `blockmodeling`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(blockmodeling)\n```\n:::\n\n\n\n\nIn principle, blockmodels can also be used for clustering, as we will illustrate on this random network with 3 dense blocks of size 20.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/random-graph2-1.png){width=672}\n:::\n:::\n\n\n\n\nThe disadvantage is that we need to specify a lot more parameters than for community detection. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- as_adj(g)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: `as_adj()` was deprecated in igraph 2.1.0.\nℹ Please use `as_adjacency_matrix()` instead.\n```\n\n\n:::\n\n```{.r .cell-code}\nblk <- matrix(\n    c(\n        \"com\", \"nul\", \"nul\",\n        \"nul\", \"com\", \"nul\",\n        \"nul\", \"nul\", \"com\"\n    ),\n    nrow = 3\n)\nblk\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]  [,2]  [,3] \n[1,] \"com\" \"nul\" \"nul\"\n[2,] \"nul\" \"com\" \"nul\"\n[3,] \"nul\" \"nul\" \"com\"\n```\n\n\n:::\n\n```{.r .cell-code}\nres <- optRandomParC(\n    M = A, k = 3, approaches = \"bin\",\n    blocks = blk, rep = 5, mingr = 20, maxgr = 20\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\nStarting optimization of the partiton 1 of 5 partitions.\nStarting partition: 3 2 2 2 3 3 2 1 2 1 2 3 3 1 3 2 3 3 2 2 1 1 3 3 3 2 3 2 3 2 3 1 2 1 3 1 1 1 1 1 1 1 3 1 3 1 2 1 3 2 1 1 1 3 3 2 2 2 2 2 \nFinal error: 342 \nFinal partition:    3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 \n\n\nStarting optimization of the partiton 2 of 5 partitions.\nStarting partition: 1 1 2 1 3 1 1 1 1 2 3 2 1 1 3 1 3 2 1 3 2 2 3 1 3 3 2 2 2 3 1 1 2 3 1 3 1 3 2 2 3 1 2 1 3 1 3 3 2 2 3 2 3 2 2 2 1 3 2 3 \nFinal error: 342 \nFinal partition:    1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 \n\n\nStarting optimization of the partiton 3 of 5 partitions.\nStarting partition: 3 1 2 3 2 3 1 1 1 2 2 1 3 2 3 3 2 1 2 3 3 3 3 1 2 3 1 1 2 2 2 1 3 1 2 3 1 2 2 3 2 2 1 1 1 1 1 1 3 3 3 2 2 1 1 2 3 3 3 2 \nFinal error: 342 \nFinal partition:    1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 \n\n\nStarting optimization of the partiton 4 of 5 partitions.\nStarting partition: 1 3 3 1 3 3 3 2 1 2 1 3 2 3 3 1 2 3 1 1 2 3 2 2 1 2 1 1 2 1 3 2 2 1 2 2 3 3 2 3 1 3 3 2 3 1 3 1 1 2 1 1 3 2 1 3 2 2 1 2 \nFinal error: 342 \nFinal partition:    1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 \n\n\nStarting optimization of the partiton 5 of 5 partitions.\nStarting partition: 3 2 2 2 2 3 3 1 2 2 1 3 1 3 3 1 2 2 1 3 2 1 2 1 1 2 3 2 1 3 1 2 1 3 3 3 3 3 2 2 1 1 1 3 1 2 2 1 3 2 3 2 1 3 3 2 1 3 1 1 \nFinal error: 342 \nFinal partition:    2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 \n\n\nOptimization of all partitions completed\nAll 5 solutions have err 342 \n```\n\n\n:::\n:::\n\n\n\n\n- `k`: number of blocks needs to be specified beforehand\n- `approaches`: defines the type of blockmodel approach to be used. \"bin\" is for binary and \"val\" for valued blockmodeling. There are several more possibilities available in the help of the function\n- `blocks`: allowed block types. Basically, what defines a block in the network. In our example we give a strict patterning that corresponds to a clustering. The diagonal blocks should be complete (\"com\") and offdiagonals should be empty (\"nul\"). So in the best case, we have 3 disconnected cliques. Again, consult the help for more available block options.\n- `rep`: number of random starting partitions to start the iteration from\n- `mingr` and `maxgr`: min and max size of the blocks. \n\nthe result can be accessed with `clu`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclu(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[39] 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n```\n\n\n:::\n:::\n\n\n\n\nNote that this type of Blockmodeling is computationally expensive and best suited for small networks. \n\nLooking at a more realistic dataset, we load the `baker` dataset from the `blockmodeling` package. The dataset includes citation data between social work journals for 1985-86.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"baker\")\ndiag(baker) <- 0\n\nplotMat(baker,\n    main = \"Baker Network Data\",\n    mar = c(1, 1, 3, 1), title.line = 2\n)\n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/load-baker-1.png){width=672}\n:::\n:::\n\n\n\n\nFirst, we run a binary blockmodel. This time we increase the number of repetions to 1000 and instead of giving a lear block structure, we just specify, what type of blocks we want our result to include. How they are distributed, we do not care and let the algorithm decide. We run the optimization in parallel (`nCores = 0`), which requires the packages `doParallel` and `doRNG` to be installed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbaker_binary <- baker\nbaker_binary[baker_binary > 0] <- 1\n\nres_baker_binary <- optRandomParC(\n    M = baker_binary, k = 3, rep = 1000,\n    nCores = 0, blocks = c(\"nul\", \"com\"), approach = \"bin\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required namespace: doParallel\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required namespace: doRNG\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\nOptimization of all partitions completed\n1 solution(s) with minimal error = 47 found. \n```\n\n\n:::\n:::\n\n\n\n\nThe obtained optimal block structure can be accessed via `IM`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nIM(res_baker_binary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]  [,2]  [,3] \n[1,] \"nul\" \"nul\" \"com\"\n[2,] \"nul\" \"com\" \"com\"\n[3,] \"nul\" \"com\" \"com\"\n```\n\n\n:::\n:::\n\n\n\n\nThe resulting blocks can be visualized via the `plot` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(\n    res_baker_binary,\n    main = \"Baker Binary Network Data\",\n    mar = c(1, 2, 3, 1), title.line = 2\n)\n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/baker-bin-1.png){width=672}\n:::\n:::\n\n\n\n\nNow we run a valued blockmodel on the original data. The parameter `preSpecM` is set to the median of the non-zero entries and defines a kind of cutoff for when to consider a value high enough to be a block internal tie.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_baker_valued <- optRandomParC(\n    M = baker, k = 3, rep = 1000,\n    preSpecM = 13, approach = \"val\", blocks = c(\"nul\", \"com\"),\n    nCores = 0\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\nOptimization of all partitions completed\n1 solution(s) with minimal error = 626 found. \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nIM(res_baker_valued)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]  [,2]  [,3] \n[1,] \"com\" \"nul\" \"com\"\n[2,] \"nul\" \"nul\" \"nul\"\n[3,] \"com\" \"nul\" \"nul\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(\n    res_baker_valued,\n    main = \"Baker Valued Network Data\",\n    mar = c(1, 2, 3, 1), title.line = 2\n)\n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/baker-val-1.png){width=672}\n:::\n:::\n\n\n\n\n## Core-Periphery\n\nCommunity detection aims to find clusters or groups of nodes within the network that are more densely connected to each other than to nodes outside the group. The core-periphery structure, in contrast, posits that a network is organized into a densely connected core and a sparsely connected periphery. The core consists of central nodes that are highly connected to each other and also to peripheral nodes. Peripheral nodes, on the other hand, have fewer connections and are mostly connected to nodes in the core rather than to each other. \n\nthe `netutils` package includes a function `core_periphery()` which allows to fit a discrete core-periphery model to a network. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(netUtils)\n```\n:::\n\n\n\n\nTo illustrate the function, we construct a graph which has a perfect core-periphery structure, also known as a **split graph**.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nsg <- split_graph(n = 50, p = 0.35, core = 0.3)\n```\n:::\n\n\n\n\nThe created graph has 50 nodes and 30% of all nodes are in the core. The probability that a periphery node connects to a core node is 0.35.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/split-graph-img-1.png){width=672}\n:::\n:::\n\n\n\n\nRunning the `core_periphery()` function on this idealized graph should give the optimal result.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncore_periphery(sg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$vec\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 0 0 0 0 0 0 0\n\n$corr\n[1] 1\n```\n\n\n:::\n:::\n\n\n\n\nThe function returns a list with two entries. The first, `vec`, returns the membership of nodes. It is one if a node is in the core and 0 if not. The second entry `corr` is the correlation of the adjacency matrix with the ideal adjacency matrix given from the `vec` memberships. In this case, the correlation is one meaning that we have discovered the perfect core-periphery structure. In empirical applications, we rarely expect such a good fit. \n\nThe function also has an argument which allows to use different optimization techniques to find core-periphery structures (the problem of finding the optimal solution is too complex). For illustration, we rewire some edges of the  graph `sg` to destroy the idealized structure and use all implemented optimization methods.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(45)\nsg1 <- rewire(sg, each_edge(0.25))\ncore_periphery(sg1, method = \"rk1_dc\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$vec\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 0 0 0 0 0 0 0\n\n$corr\n[1] 0.6473649\n```\n\n\n:::\n\n```{.r .cell-code}\ncore_periphery(sg1, method = \"rk1_ec\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$vec\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 0 0 0 0 0 0 0\n\n$corr\n[1] 0.6473649\n```\n\n\n:::\n\n```{.r .cell-code}\ncore_periphery(sg1, method = \"GA\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$vec\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 0 0 0 0 0 0 0\n\n$corr\n[1] 0.6473649\n```\n\n\n:::\n:::\n\n\n\n\n`rk1_dc` and `rk1_ec` are so called rank-one matix approximation methods which infer an idealized structure via the degrees and eigenvectors of the adjacency matrix. These methods are extremely fast but might result in a lower quality of the result compared to `GA` which runs a genetic algorithm. \n\nThere are several extensions to this simple discrete core-periphery model. An extension for weighted networks is implemented in the package `ITNr`.\n\n## Scientific Reading\n\nClauset, A.; Newman, M. E. J. & Moore, C. Finding community structure in very large networks, Physical Review E 2004, 70, 066111\n\nVincent D. Blondel, Jean-Loup Guillaume, Renaud Lambiotte, Etienne Lefebvre: Fast unfolding of communities in large networks. J. Stat. Mech. (2008) P10008\n\nTraag, V. A., Waltman, L., & van Eck, N. J. (2019). From Louvain to Leiden: guaranteeing well-connected communities. Scientific reports, 9(1), 5233.\n\nŽiberna, A. (2007). Generalized Blockmodeling of Valued Networks. Social Networks, 29(1), 105-126. doi: 10.1016/j.socnet.2006.04.002\n\nŽiberna, A. (2008). Direct and indirect approaches to blockmodeling of valued networks in terms of regular equivalence. Journal of Mathematical Sociology, 32(1), 57-84. doi: 10.1080/00222500701790207\n\nŽiberna, A. (2014). Blockmodeling of multilevel networks. Social Networks, 39(1), 46-61. doi: 10.1016/j.socnet.2014.04.002\n\nBorgatti, Stephen P., and Martin G. Everett. \"Models of core/periphery structures.\" Social networks 21.4 (2000): 375-395.\n",
    "supporting": [
      "clustering_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}