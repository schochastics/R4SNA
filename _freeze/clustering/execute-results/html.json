{
  "hash": "e90b55676388597a222df68abb1fa3dd",
  "result": {
    "engine": "knitr",
    "markdown": "# Cohesive Subgroups\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(igraph)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'igraph'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:base':\n\n    union\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(networkdata)\n```\n:::\n\n\n\n\n\n## Cliques \n\nA *clique* in a network is a set of nodes that form a complete subnetwork within a network (called a complete **subgraph**). A **maximal clique** is a clique that cannot be extended to a bigger clique by addding more nodes to it. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"clique_graph\")\n```\n:::\n\n\nAll maximal cliques can be calculated with `max_cliques()` (only feasible for fairly small networks). The min parameter can be used to set a minimum size. Here, we want to ignore all cliques of size $2$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# only return cliques with three or more nodes\ncl <- max_cliques(clique_graph, min = 3)\ncl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n+ 3/30 vertices, from 0193e05:\n[1]  9 17 18\n\n[[2]]\n+ 3/30 vertices, from 0193e05:\n[1] 7 4 5\n\n[[3]]\n+ 3/30 vertices, from 0193e05:\n[1] 7 4 8\n\n[[4]]\n+ 3/30 vertices, from 0193e05:\n[1] 10  2 11\n\n[[5]]\n+ 3/30 vertices, from 0193e05:\n[1] 16 12 15\n\n[[6]]\n+ 3/30 vertices, from 0193e05:\n[1] 6 1 5\n\n[[7]]\n+ 4/30 vertices, from 0193e05:\n[1] 12 13 15 14\n\n[[8]]\n+ 3/30 vertices, from 0193e05:\n[1] 12  2  1\n\n[[9]]\n+ 5/30 vertices, from 0193e05:\n[1] 1 2 5 4 3\n```\n\n\n:::\n:::\n\n\nThe figure below shows the network and the found maximal cliques.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/plot-clique-graph-1.png){width=672}\n:::\n:::\n\n\nRelated to cliques is the **k-core decomposition** of a network. A k-core is a subgraph in which every node has at least k neighbors within the subgraph. A k-core is thus a relaxed version of a clique.  \nThe function `coreness()` can be used to calculate the k-core membership for each node.\n\n::: {.cell}\n\n```{.r .cell-code}\nkcore <- coreness(clique_graph)\nkcore\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 4 4 4 4 4 3 2 2 2 2 2 3 3 3 3 3 2 2 1 1 1 1 1 1 1 1 1 1 1 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/kcore_plot-1.png){width=672}\n:::\n:::\n\n\nCliques are the prototypical and most strict definition of a cohesive subgroup of a graph. In empirical networks, however, we rarely encounter situations where we can partition the whole network into a set of \ncliques. A relaxed version of this problem is that of clustering, also referred to as **comunity detection**. \n\n## Comunity detection\n\nA cluster is loosely defined as a group of nodes which are internally densely and externally sparsely connected. The network below shows an example for a network with a visible and intuitive cluster structure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# labeL; clustered-graph\n#| echo: FALSE\n\nn1 <- 5\nn2 <- 20\nset.seed(1234)\ng <- sample_islands(n1, n2, 0.9, 5)\ng <- simplify(g)\nV(g)$grp <- rep(LETTERS[1:n1], each = n2)\nggraph(g, \"stress\") +\n    geom_edge_link0(edge_linewidth =0.2, edge_color = \"grey66\") +\n    geom_node_point(shape = 21, size = 5, aes(fill = grp), show.legend = FALSE) +\n    theme_void()\n```\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nIn contrast, the network below does not really seem to have any well defined cluster structure.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/random-graph-1.png){width=672}\n:::\n:::\n\n\nThe following algorithms for graph clustering are implemented in `igraph`.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"cluster_edge_betweenness\"  \"cluster_fast_greedy\"      \n [3] \"cluster_fluid_communities\" \"cluster_infomap\"          \n [5] \"cluster_label_prop\"        \"cluster_leading_eigen\"    \n [7] \"cluster_leiden\"            \"cluster_louvain\"          \n [9] \"cluster_optimal\"           \"cluster_spinglass\"        \n[11] \"cluster_walktrap\"         \n```\n\n\n:::\n:::\n\n\nMost of these algorithms are based on \"modularity maximization\". Modularity is defined as the fraction of edges that fall within given groups minus the expected fraction if edges were distributed at random.\n\nThe workflow of a cluster analysis is always the same, independent from the chosen method. We illustrate the workflow using the infamous karate club network.\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"karate\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/karate-plot-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute clustering\nclu <- cluster_louvain(karate)\n\n# cluster membership vector\nmem <- membership(clu)\nmem\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 1 2 2 2 1 3 1 2 1 1 1 3 3 2 1 3 1 3 1 3 4 4 4 3 4 4 3 3 4 3 3\n```\n\n\n:::\n\n```{.r .cell-code}\n# clusters as list\ncom <- communities(clu)\ncom\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`1`\n [1]  1  2  3  4  8 10 12 13 14 18 20 22\n\n$`2`\n[1]  5  6  7 11 17\n\n$`3`\n [1]  9 15 16 19 21 23 27 30 31 33 34\n\n$`4`\n[1] 24 25 26 28 29 32\n```\n\n\n:::\n:::\n\n\nTo compare the quality of clusterings, we can compute the modularity score for each output.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimc <- cluster_infomap(karate)\nlec <- cluster_leading_eigen(karate)\nloc <- cluster_louvain(karate)\nsgc <- cluster_spinglass(karate)\nwtc <- cluster_walktrap(karate)\nscores <- c(\n    infomap = modularity(karate, membership(imc)),\n    eigen = modularity(karate, membership(lec)),\n    louvain = modularity(karate, membership(loc)),\n    spinglass = modularity(karate, membership(sgc)),\n    walk = modularity(karate, membership(wtc))\n)\nscores\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  infomap     eigen   louvain spinglass      walk \n 0.402038  0.393409  0.419790  0.419790  0.353222 \n```\n\n\n:::\n:::\n\n\nFor the karate network, `cluster_spinglass()` produces the highest modularity score.\nThe corresponding clustering is shown below.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/karate-plot-clu-1.png){width=672}\n:::\n:::\n\n\nModularity maximization is still widely considered as the state-of-the-art clustering method\nfor networks. There are, however, some technical shortcomings that one should be aware of.\nOne of those is the so called \"resolution limit\". When modularity is being maximized, it can happen\nthat smaller clusters are merged together to form bigger clusters. The prime example is the graph that\nconsists of cliques connected in a ring.\n\n\n::: {.cell}\n\n:::\n\n\nThe figure below shows such a graph, consisting of 50 cliques of size 5. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](clustering_files/figure-html/plot-K50-blank-1.png){width=768}\n:::\n:::\n\n\nIntuitively, any clustering method should return a cluster for each clique.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclu_louvain <- cluster_louvain(K50)\ntable(membership(clu_louvain))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n15 10 10 10 10 15 15 10 10 15 10 10 10 15 10 10 10 10 15 10 10 10 \n```\n\n\n:::\n:::\n\n\nA clustering algorithm that fixes this issue is the leiden algorithm.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclu_leiden <- cluster_leiden(K50, objective_function = \"CPM\", resolution_parameter = 0.5)\ntable(membership(clu_leiden))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n 5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 \n27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n 5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 \n```\n\n\n:::\n:::\n\n\nThe figure below shows the clusters computed with the louvain method in grey and the leiden method in red.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nDon't know how to automatically pick scale for object of type <membership>.\nDefaulting to continuous.\nDon't know how to automatically pick scale for object of type <membership>.\nDefaulting to continuous.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](clustering_files/figure-html/plot-K50-clu-1.png){width=768}\n:::\n:::\n\n\nIf you are interested in the technical details of the Leiden method, check out the [original paper](https://www.nature.com/articles/s41598-019-41695-z). \n\n---\n\n# Blockmodeling\n\nBlockmodeling is similar to \n\n(Stochastic) Blockmodels, for instance,\ncan also be used to find community structures. Several packages exist for this, such as `randnet` or `blockmodels`.\n\n---\n",
    "supporting": [
      "clustering_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}